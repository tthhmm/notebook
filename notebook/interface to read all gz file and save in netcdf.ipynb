{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MRMS_directory = '/home/htan/proj/TensorFlow/data/MRMS/'\n",
    "Data = '20160628/'\n",
    "temp_derectory = '/home/htan/proj/TensorFlow/notebook/temp/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information in each file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MRMS_data:\n",
    "       \n",
    "    def __init__(self, MRMS_Path, Tempfile_Path):\n",
    "        # TODO: add check statement for two paths\n",
    "        self.MRMS_Path = MRMS_Path\n",
    "        self.Tempfile_Path = Tempfile_Path\n",
    "        self.info_complete_flag = False\n",
    "        self.data_complete_flag = False\n",
    "        self._fillBasicInfo()\n",
    "        \n",
    "    def _fillBasicInfo(self):\n",
    "        Gauge_info = {'folderName':'MRMS_GaugeCoor',\n",
    "                      'tempFileName':'temp_gauge.nc'}\n",
    "        Gauge = {'info': Gauge_info}\n",
    "        \n",
    "        NLDN_info = {'folderName':'MRMS_NLDN_LightningDensity',\n",
    "                     'tempFileName':'temp_NLDN.nc'}\n",
    "        NLDN = {'info' : NLDN_info}\n",
    "        \n",
    "        Z_info = {'folderName':'MRMS_Reflectivity',\n",
    "                  'tempFileName':'temp_Reflectivity.nc'}\n",
    "        Z = {'info' : Z_info}\n",
    "        \n",
    "        ZL_info = {'folderName':'MRMS_ReflectivityAtLowestAltitude',\n",
    "                   'tempFileName':'temp_ReflectivityAtLowestAltitude.nc'}\n",
    "        ZL = {'info' : ZL_info}\n",
    "        \n",
    "        HSR_info = {'folderName':'MRMS_SeamlessHSR',\n",
    "                    'tempFileName':'temp_HSR.nc'}\n",
    "        HSR = {'info' : HSR_info}\n",
    "        \n",
    "        VII_info = {'folderName':'MRMS_VII',\n",
    "                    'tempFileName':'temp_VII.nc'}\n",
    "        VII = {'info' : VII_info}\n",
    "        data =  collections.OrderedDict()\n",
    "        data['GaugeCoor'] = Gauge\n",
    "        data['NLDN_LightningDensity'] = NLDN\n",
    "        data['Reflectivity'] = Z\n",
    "        data['ReflectivityAtLowestAltitude'] = ZL\n",
    "        data['SeamlessHSR'] = HSR\n",
    "        data['VII'] = VII\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def readDataInTime(self, date, time):\n",
    "        '''search function that create a datalist for certain time, the return value has shape(lat, lon, features)'''\n",
    "        MRMS_file_list = []\n",
    "        for key in self.data:\n",
    "            self.data[key]['info']['date'] = date\n",
    "            path = self.MRMS_Path + self.data[key]['info']['folderName'] + '/' + str(date) + '/'\n",
    "            filenames = _search_file(path, time)\n",
    "            MRMS_file_list.append(sorted(filenames))\n",
    "\n",
    "        #print(MRMS_file_list)\n",
    "        # TODO: implement the search function to find the filenames in each type of dataset\n",
    "        self.data['GaugeCoor']['info']['inputFileName'] = MRMS_file_list[0]\n",
    "        self.data['NLDN_LightningDensity']['info']['inputFileName'] = MRMS_file_list[1]\n",
    "        self.data['Reflectivity']['info']['inputFileName'] = MRMS_file_list[2]\n",
    "        self.data['ReflectivityAtLowestAltitude']['info']['inputFileName'] = MRMS_file_list[3]\n",
    "        self.data['SeamlessHSR']['info']['inputFileName'] = MRMS_file_list[4]\n",
    "        self.data['VII']['info']['inputFileName'] = MRMS_file_list[5]\n",
    "        self.info_complete_flag = True        \n",
    "        self._read()\n",
    "    \n",
    "    def readDataDuringTime(self, start, end):\n",
    "        '''create a data list from start time to end time, the return value has shape (time, lat, lon, features)'''\n",
    "        pass\n",
    "        # TODO implementation duration fucntion\n",
    "        def duration(start, end):\n",
    "            pass\n",
    "        dur = duration(start, end)\n",
    "        time_list = []\n",
    "        for date, time in dur:\n",
    "            self.readDataInTime(date, time)\n",
    "            timeSliceData = self.getFeatures().reshape(1, 3500, 7000, 6)\n",
    "            time_list.append(timeSliceData)\n",
    "        return np.vstack(time_list)\n",
    "            \n",
    "    \n",
    "    def _read(self):\n",
    "        '''read the MRMS data information into a '''\n",
    "        if self.info_complete_flag == False:\n",
    "            raise ValueError('The MRMS data infomation is note completed for reading')\n",
    "        for key in self.data:\n",
    "            data_info = self.data[key]['info']\n",
    "            self.data[key]['data'] = collections.OrderedDict()\n",
    "            for name in data_info['inputFileName']:\n",
    "                gz_file_path = self.MRMS_Path + '/' + data_info['folderName'] + '/' + str(data_info['date']) + '/' + name\n",
    "                nc_file_path = self.Tempfile_Path + '/' + data_info['tempFileName']\n",
    "                self._uncompressData(gz_file_path, nc_file_path)\n",
    "                type_name = name.split(str(data_info['date']))[0][:-1]\n",
    "                self.data[key]['data'][type_name] = self._readNcFile(nc_file_path)\n",
    "            print()\n",
    "            \n",
    "        \n",
    "    \n",
    "    def searchDemo(self):\n",
    "        '''The simple demo, do not use it in real application'''\n",
    "        if self.info_complete_flag == True:\n",
    "            return\n",
    "        for key in self.data:\n",
    "            self.data[key]['info']['date'] = 20160628\n",
    "        self.data['GaugeCoor']['info']['inputFileName'] = 'MRMS_GaugeCorr_QPE_01H_00.00_20160628-170000.nc.gz'\n",
    "        self.data['NLDN_LightningDensity']['info']['inputFileName'] = 'MRMS_NLDN_LightningDensity_015_min_20160628-170113.nc.gz'\n",
    "        self.data['Reflectivity']['info']['inputFileName'] = 'MRMS_Reflectivity_-5C_00.50_20160628-170040.nc.gz'\n",
    "        self.data['ReflectivityAtLowestAltitude']['info']['inputFileName'] = 'MRMS_ReflectivityAtLowestAltitude_00.50_20160628-170040.nc.gz'\n",
    "        self.data['SeamlessHSR']['info']['inputFileName'] = 'MRMS_SeamlessHSR_00.00_20160628-170000.nc.gz'\n",
    "        self.data['VII']['info']['inputFileName'] = 'MRMS_VII_00.50_20160628-170040.nc.gz'\n",
    "        self.info_complete_flag = True\n",
    "        self._read()\n",
    "        \n",
    "    def getRawData(self):\n",
    "        return self.data\n",
    "    \n",
    "    def preprocess(features):\n",
    "        '''preprocess the features which must has the shape as (time, lat, lon, features)'''\n",
    "        # TODO: add check function to check the shape\n",
    "        # remove the invalid value with nan\n",
    "        f0 = features[:,:,:,0]\n",
    "        f0[f0 <= -2]=np.nan\n",
    "        f2 = features[:,:,:,2]\n",
    "        f2[f0 <= -999]=np.nan\n",
    "        f3 = features[:,:,:,3]\n",
    "        f3[f3 <= -999]=np.nan\n",
    "        f4 = features[:,:,:,4]\n",
    "        f4[f4 <= -999]=np.nan\n",
    "        \n",
    "        # standardize the dataset\n",
    "        # TODO: check self.mean and self.std exsit or not. If exsit, directly use them to standardize the dataset\n",
    "        self.mean = np.nanmean(features, axis = (0, 1, 2))\n",
    "        self.std = np.nanstd(features, axis = (0, 1, 2))\n",
    "        return (features - self.mean)/self.std\n",
    "        \n",
    "    \n",
    "    def getFeatures(self):\n",
    "        '''combine six dataset into one feature database'''\n",
    "        feature_name_list = []\n",
    "        feature_list = []\n",
    "        for key in self.data:\n",
    "            for data_name in self.data[key]['data']:\n",
    "                feature_name_list.append(data_name)\n",
    "                d = self.data[key]['data'][data_name]['var']\n",
    "                feature_list.append(d.reshape(3500, 7000, 1))\n",
    "        return feature_name_list, np.dstack(feature_list)\n",
    "            \n",
    "    def _uncompressData(self, gz_file_path, nc_file_path):\n",
    "        print('Uncompressing gzip file %s ...' % (gz_file_path))\n",
    "        inF = gzip.open(gz_file_path, 'rb')\n",
    "        outF = open(nc_file_path, 'wb')\n",
    "        outF.write( inF.read() )\n",
    "        inF.close()\n",
    "        outF.close()\n",
    "        print('Create temp file %s' % (nc_file_path))\n",
    "        \n",
    "    def _readNcFile(self, nc_file_path):\n",
    "        print('Read Netcdf file %s ...' % (nc_file_path))\n",
    "        ncF = Dataset(nc_file_path, mode = 'r')\n",
    "        var = []\n",
    "        for key in ncF.variables:\n",
    "            var.append(key)\n",
    "        data = {'var' : ncF.variables[var[0]][:],\n",
    "                'lat' : ncF.variables[var[1]][:],\n",
    "                'lon' : ncF.variables[var[2]][:],}\n",
    "        print('Finish reading data')\n",
    "        return data\n",
    "    \n",
    "def _search_file(path, time):\n",
    "    file_list = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    seconds = [_timeToSec(f.split('20160628-')[1][:6]) for f in file_list]\n",
    "    target = _timeToSec(time)\n",
    "    abs_value= np.abs(np.array(seconds) - target)\n",
    "    index = np.where(abs_value == abs_value.min())\n",
    "    return [file_list[i] for i in index[0]]\n",
    "        \n",
    "    \n",
    "def _timeToSec(time):\n",
    "    if len(str(time)) != 6:\n",
    "        raise ValueError('The time formate is not correct at HHMMSS')\n",
    "    hour = int(time[:2])\n",
    "    minute = int(time[2:4])\n",
    "    second = int(time[4:])\n",
    "    return second + minute*60 + hour*3600\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = MRMS_data(MRMS_directory, temp_derectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_GaugeCoor/20160628/MRMS_GaugeCorr_QPE_01H_00.00_20160628-170000.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_gauge.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_gauge.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_GaugeCoor/20160628/MRMS_GaugeCorr_QPE_03H_00.00_20160628-170000.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_gauge.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_gauge.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_001_min_20160628-172243.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_005_min_20160628-172243.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_015_min_20160628-172243.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-10C_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-15C_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-20C_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-5C_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_Reflectivity/20160628/MRMS_Reflectivity_0C_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_ReflectivityAtLowestAltitude/20160628/MRMS_ReflectivityAtLowestAltitude_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_ReflectivityAtLowestAltitude.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_ReflectivityAtLowestAltitude.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_SeamlessHSR/20160628/MRMS_SeamlessHSR_00.00_20160628-172200.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_HSR.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_HSR.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/htan/proj/TensorFlow/data/MRMS//MRMS_VII/20160628/MRMS_VII_00.50_20160628-172235.nc.gz ...\n",
      "Create temp file /home/htan/proj/TensorFlow/notebook/temp//temp_VII.nc\n",
      "Read Netcdf file /home/htan/proj/TensorFlow/notebook/temp//temp_VII.nc ...\n",
      "Finish reading data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.readDataInTime('20160628', '172245')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 7000, 13)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn, feature = test.getFeatures()\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/MRMS/' +  '1timeslice.pickle'\n",
    "\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(feature, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -3.,   -3.,    0.,    0.,    0., -999., -999., -999., -999.,\n",
       "       -999., -999., -999.,   -1.], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f0 = f[:, :, 0]\n",
    "f0[f0 <= -2]=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(f0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = f[:, :, 1]\n",
    "f1[f1 <= 0] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = f[:, :, 2]\n",
    "f2[f2 <= -999] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f3 = f[:, :, 3]\n",
    "f3[f3 <= -999] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f3)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f4 = f[:, :, 4]\n",
    "f4[f4 <= -999] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f4)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f5 = f[:, :, 5]\n",
    "f5[f5 <= -1] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f[0,0,0]/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
