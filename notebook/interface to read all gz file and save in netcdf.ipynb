{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MRMS_directory = '/home/ldm/var/data/'\n",
    "\n",
    "temp_derectory = '/home/ldm/proj/TensorFlow/temp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information in each file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MRMS_data:\n",
    "       \n",
    "    def __init__(self, MRMS_Path, Tempfile_Path):\n",
    "        # TODO: add check statement for two paths\n",
    "        self.MRMS_Path = MRMS_Path\n",
    "        self.Tempfile_Path = Tempfile_Path\n",
    "        self.info_complete_flag = False\n",
    "        self.data_complete_flag = False\n",
    "        self._fillBasicInfo()\n",
    "        \n",
    "    def _fillBasicInfo(self):\n",
    "        Gauge_info = {'folderName':'MRMS_GaugeCoor',\n",
    "                      'tempFileName':'temp_gauge.nc'}\n",
    "        Gauge = {'info': Gauge_info}\n",
    "        \n",
    "        NLDN_info = {'folderName':'MRMS_NLDN_LightningDensity',\n",
    "                     'tempFileName':'temp_NLDN.nc'}\n",
    "        NLDN = {'info' : NLDN_info}\n",
    "        \n",
    "        Z_info = {'folderName':'MRMS_Reflectivity',\n",
    "                  'tempFileName':'temp_Reflectivity.nc'}\n",
    "        Z = {'info' : Z_info}\n",
    "        \n",
    "        ZL_info = {'folderName':'MRMS_ReflectivityAtLowestAltitude',\n",
    "                   'tempFileName':'temp_ReflectivityAtLowestAltitude.nc'}\n",
    "        ZL = {'info' : ZL_info}\n",
    "        \n",
    "        HSR_info = {'folderName':'MRMS_SeamlessHSR',\n",
    "                    'tempFileName':'temp_HSR.nc'}\n",
    "        HSR = {'info' : HSR_info}\n",
    "        \n",
    "        VII_info = {'folderName':'MRMS_VII',\n",
    "                    'tempFileName':'temp_VII.nc'}\n",
    "        VII = {'info' : VII_info}\n",
    "        data =  collections.OrderedDict()\n",
    "        data['GaugeCoor'] = Gauge\n",
    "        data['NLDN_LightningDensity'] = NLDN\n",
    "        data['Reflectivity'] = Z\n",
    "        data['ReflectivityAtLowestAltitude'] = ZL\n",
    "        data['SeamlessHSR'] = HSR\n",
    "        data['VII'] = VII\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def readDataInTime(self, date, time):\n",
    "        '''search function that create a datalist for certain time, the return value has shape(lat, lon, features)'''\n",
    "        if self.info_complete_flag == True:\n",
    "            del self.data\n",
    "            self._fillBasicInfo()\n",
    "            self.info_complete_flag = False\n",
    "            \n",
    "        MRMS_file_list = []\n",
    "        for key in self.data:\n",
    "            self.data[key]['info']['date'] = date\n",
    "            path = self.MRMS_Path + self.data[key]['info']['folderName'] + '/' + str(date) + '/'\n",
    "            filenames = _search_file(path, date, time)\n",
    "            MRMS_file_list.append(sorted(filenames))\n",
    "\n",
    "        #print(MRMS_file_list)\n",
    "        # TODO: implement the search function to find the filenames in each type of dataset\n",
    "        self.data['GaugeCoor']['info']['inputFileName'] = MRMS_file_list[0]\n",
    "        self.data['NLDN_LightningDensity']['info']['inputFileName'] = MRMS_file_list[1]\n",
    "        self.data['Reflectivity']['info']['inputFileName'] = MRMS_file_list[2]\n",
    "        self.data['ReflectivityAtLowestAltitude']['info']['inputFileName'] = MRMS_file_list[3]\n",
    "        self.data['SeamlessHSR']['info']['inputFileName'] = MRMS_file_list[4]\n",
    "        self.data['VII']['info']['inputFileName'] = MRMS_file_list[5]\n",
    "        self.info_complete_flag = True        \n",
    "        self._read()\n",
    "    \n",
    "    def readDataDuringTime(self, start, end):\n",
    "        '''create a data list from start time to end time, the return value has shape (time, lat, lon, features)'''\n",
    "        pass\n",
    "        # TODO implementation duration fucntion\n",
    "        def duration(start, end):\n",
    "            pass\n",
    "        dur = duration(start, end)\n",
    "        time_list = []\n",
    "        for date, time in dur:\n",
    "            self.readDataInTime(date, time)\n",
    "            timeSliceData = self.getFeatures().reshape(1, 3500, 7000, 6)\n",
    "            time_list.append(timeSliceData)\n",
    "        return np.vstack(time_list)\n",
    "            \n",
    "    \n",
    "    def _read(self):\n",
    "        '''read the MRMS data information into a '''\n",
    "        if self.info_complete_flag == False:\n",
    "            raise ValueError('The MRMS data infomation is note completed for reading')\n",
    "        for key in self.data:\n",
    "            data_info = self.data[key]['info']\n",
    "            self.data[key]['data'] = collections.OrderedDict()\n",
    "            for name in data_info['inputFileName']:\n",
    "                gz_file_path = self.MRMS_Path + '/' + data_info['folderName'] + '/' + str(data_info['date']) + '/' + name\n",
    "                nc_file_path = self.Tempfile_Path + '/' + data_info['tempFileName']\n",
    "                self._uncompressData(gz_file_path, nc_file_path)\n",
    "                type_name = name.split(str(data_info['date']))[0][:-1]\n",
    "                self.data[key]['data'][type_name] = self._readNcFile(nc_file_path)\n",
    "            print()\n",
    "            \n",
    "        \n",
    "    \n",
    "    def searchDemo(self):\n",
    "        '''The simple demo, do not use it in real application'''\n",
    "        if self.info_complete_flag == True:\n",
    "            return\n",
    "        for key in self.data:\n",
    "            self.data[key]['info']['date'] = 20160628\n",
    "        self.data['GaugeCoor']['info']['inputFileName'] = 'MRMS_GaugeCorr_QPE_01H_00.00_20160628-170000.nc.gz'\n",
    "        self.data['NLDN_LightningDensity']['info']['inputFileName'] = 'MRMS_NLDN_LightningDensity_015_min_20160628-170113.nc.gz'\n",
    "        self.data['Reflectivity']['info']['inputFileName'] = 'MRMS_Reflectivity_-5C_00.50_20160628-170040.nc.gz'\n",
    "        self.data['ReflectivityAtLowestAltitude']['info']['inputFileName'] = 'MRMS_ReflectivityAtLowestAltitude_00.50_20160628-170040.nc.gz'\n",
    "        self.data['SeamlessHSR']['info']['inputFileName'] = 'MRMS_SeamlessHSR_00.00_20160628-170000.nc.gz'\n",
    "        self.data['VII']['info']['inputFileName'] = 'MRMS_VII_00.50_20160628-170040.nc.gz'\n",
    "        self.info_complete_flag = True\n",
    "        self._read()\n",
    "        \n",
    "    def getRawData(self):\n",
    "        return self.data\n",
    "    \n",
    "    def preprocess(features):\n",
    "        '''preprocess the features which must has the shape as (time, lat, lon, features)'''\n",
    "        # TODO: add check function to check the shape\n",
    "        # remove the invalid value with nan\n",
    "        f0 = features[:,:,:,0]\n",
    "        f0[f0 <= -2]=np.nan\n",
    "        f2 = features[:,:,:,2]\n",
    "        f2[f0 <= -999]=np.nan\n",
    "        f3 = features[:,:,:,3]\n",
    "        f3[f3 <= -999]=np.nan\n",
    "        f4 = features[:,:,:,4]\n",
    "        f4[f4 <= -999]=np.nan\n",
    "        \n",
    "        # standardize the dataset\n",
    "        # TODO: check self.mean and self.std exsit or not. If exsit, directly use them to standardize the dataset\n",
    "        self.mean = np.nanmean(features, axis = (0, 1, 2))\n",
    "        self.std = np.nanstd(features, axis = (0, 1, 2))\n",
    "        return (features - self.mean)/self.std\n",
    "        \n",
    "    \n",
    "    def getFeatures(self):\n",
    "        '''combine six dataset into one feature database'''\n",
    "        feature_name_list = []\n",
    "        feature_list = []\n",
    "        for key in self.data:\n",
    "            for data_name in self.data[key]['data']:\n",
    "                feature_name_list.append(data_name)\n",
    "                d = self.data[key]['data'][data_name]['var']\n",
    "                feature_list.append(d.reshape(3500, 7000, 1))\n",
    "        return feature_name_list, np.dstack(feature_list)\n",
    "    \n",
    "    def getLatLon(self):\n",
    "        lat = self.data['GaugeCoor']['data']['MRMS_GaugeCorr_QPE_01H_00.00']['lat']\n",
    "        lon = self.data['GaugeCoor']['data']['MRMS_GaugeCorr_QPE_01H_00.00']['lon']\n",
    "        return lat, lon\n",
    "            \n",
    "    def _uncompressData(self, gz_file_path, nc_file_path):\n",
    "        print('Uncompressing gzip file %s ...' % (gz_file_path))\n",
    "        inF = gzip.open(gz_file_path, 'rb')\n",
    "        outF = open(nc_file_path, 'wb')\n",
    "        outF.write( inF.read() )\n",
    "        inF.close()\n",
    "        outF.close()\n",
    "        print('Create temp file %s' % (nc_file_path))\n",
    "        \n",
    "    def _readNcFile(self, nc_file_path):\n",
    "        print('Read Netcdf file %s ...' % (nc_file_path))\n",
    "        ncF = Dataset(nc_file_path, mode = 'r')\n",
    "        var = []\n",
    "        for key in ncF.variables:\n",
    "            var.append(key)\n",
    "        data = {'var' : ncF.variables[var[0]][:],\n",
    "                'lat' : ncF.variables[var[1]][:],\n",
    "                'lon' : ncF.variables[var[2]][:],}\n",
    "        print('Finish reading data')\n",
    "        return data\n",
    "    \n",
    "def _search_file(path, date, time):\n",
    "    file_list = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f[-5:] == 'nc.gz']\n",
    "    seconds = [_timeToSec(f.split(date + '-')[1][:6]) for f in file_list]\n",
    "    target = _timeToSec(time)\n",
    "    abs_value= np.abs(np.array(seconds) - target)\n",
    "    index = np.where(abs_value == abs_value.min())\n",
    "    return [file_list[i] for i in index[0]]\n",
    "        \n",
    "    \n",
    "def _timeToSec(time):\n",
    "    if len(str(time)) != 6:\n",
    "        raise ValueError('The time formate is not correct at HHMMSS')\n",
    "    hour = int(time[:2])\n",
    "    minute = int(time[2:4])\n",
    "    second = int(time[4:])\n",
    "    return second + minute*60 + hour*3600\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = MRMS_data(MRMS_directory, temp_derectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160628/MRMS_GaugeCorr_QPE_01H_00.00_20160628-170000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160628/MRMS_GaugeCorr_QPE_03H_00.00_20160628-170000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_001_min_20160628-170113.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_005_min_20160628-170113.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160628/MRMS_NLDN_LightningDensity_015_min_20160628-170113.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-10C_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-15C_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-20C_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160628/MRMS_Reflectivity_-5C_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160628/MRMS_Reflectivity_0C_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_ReflectivityAtLowestAltitude/20160628/MRMS_ReflectivityAtLowestAltitude_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_ReflectivityAtLowestAltitude.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_ReflectivityAtLowestAltitude.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_SeamlessHSR/20160628/MRMS_SeamlessHSR_00.00_20160628-170000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_HSR.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_HSR.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_VII/20160628/MRMS_VII_00.50_20160628-170040.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_VII.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_VII.nc ...\n",
      "Finish reading data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test.readDataInTime('20160628', '170045')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500,), (7000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat, lon = test.getLatLon()\n",
    "lat.shape, lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KFWS_lat = 32.5627\n",
    "KFWS_lon = 97.3130\n",
    "KFWS_lon_m = KFWS_lon + 180\n",
    "KFWS_region = [KFWS_lat - 0.01 * 5, KFWS_lat + 0.01 * 5, KFWS_lon_m - 0.01 * 5, KFWS_lon_m + 0.01 * 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.5127, 32.6127, 277.263, 277.363]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFWS_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_index(array, value):\n",
    "    abs_value= np.abs(np.array(array) - value)\n",
    "    index = np.where(abs_value == abs_value.min())\n",
    "    return index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_lat, index_lon = find_index(lat, KFWS_lat), find_index(lon, KFWS_lon_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_time_list(date, time, step_length = 15, step_num = 8):\n",
    "    base = datetime.datetime.strptime(date+time, \"%Y%m%d%H%M%S\")\n",
    "    return [(base - datetime.timedelta(minutes = step_length * i)).strftime(\"%Y%m%d %H%M%S\") for i in range(0, step_num)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20160710 235959',\n",
       " '20160710 234459',\n",
       " '20160710 232959',\n",
       " '20160710 231459',\n",
       " '20160710 225959',\n",
       " '20160710 224459',\n",
       " '20160710 222959',\n",
       " '20160710 221459',\n",
       " '20160710 215959',\n",
       " '20160710 214459',\n",
       " '20160710 212959',\n",
       " '20160710 211459',\n",
       " '20160710 205959',\n",
       " '20160710 204459',\n",
       " '20160710 202959',\n",
       " '20160710 201459',\n",
       " '20160710 195959',\n",
       " '20160710 194459',\n",
       " '20160710 192959',\n",
       " '20160710 191459',\n",
       " '20160710 185959',\n",
       " '20160710 184459',\n",
       " '20160710 182959',\n",
       " '20160710 181459',\n",
       " '20160710 175959',\n",
       " '20160710 174459',\n",
       " '20160710 172959',\n",
       " '20160710 171459',\n",
       " '20160710 165959',\n",
       " '20160710 164459',\n",
       " '20160710 162959',\n",
       " '20160710 161459',\n",
       " '20160710 155959',\n",
       " '20160710 154459',\n",
       " '20160710 152959',\n",
       " '20160710 151459',\n",
       " '20160710 145959',\n",
       " '20160710 144459',\n",
       " '20160710 142959',\n",
       " '20160710 141459',\n",
       " '20160710 135959',\n",
       " '20160710 134459',\n",
       " '20160710 132959',\n",
       " '20160710 131459',\n",
       " '20160710 125959',\n",
       " '20160710 124459',\n",
       " '20160710 122959',\n",
       " '20160710 121459',\n",
       " '20160710 115959',\n",
       " '20160710 114459',\n",
       " '20160710 112959',\n",
       " '20160710 111459',\n",
       " '20160710 105959',\n",
       " '20160710 104459',\n",
       " '20160710 102959',\n",
       " '20160710 101459',\n",
       " '20160710 095959',\n",
       " '20160710 094459',\n",
       " '20160710 092959',\n",
       " '20160710 091459',\n",
       " '20160710 085959',\n",
       " '20160710 084459',\n",
       " '20160710 082959',\n",
       " '20160710 081459',\n",
       " '20160710 075959',\n",
       " '20160710 074459',\n",
       " '20160710 072959',\n",
       " '20160710 071459',\n",
       " '20160710 065959',\n",
       " '20160710 064459',\n",
       " '20160710 062959',\n",
       " '20160710 061459',\n",
       " '20160710 055959',\n",
       " '20160710 054459',\n",
       " '20160710 052959',\n",
       " '20160710 051459',\n",
       " '20160710 045959',\n",
       " '20160710 044459',\n",
       " '20160710 042959',\n",
       " '20160710 041459',\n",
       " '20160710 035959',\n",
       " '20160710 034459',\n",
       " '20160710 032959',\n",
       " '20160710 031459',\n",
       " '20160710 025959',\n",
       " '20160710 024459',\n",
       " '20160710 022959',\n",
       " '20160710 021459',\n",
       " '20160710 015959',\n",
       " '20160710 014459',\n",
       " '20160710 012959',\n",
       " '20160710 011459',\n",
       " '20160710 005959',\n",
       " '20160710 004459',\n",
       " '20160710 002959',\n",
       " '20160710 001459',\n",
       " '20160709 235959']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_time_list('20160710', '235959', step_num = 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160705/MRMS_GaugeCorr_QPE_01H_00.00_20160705-230000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160705/MRMS_GaugeCorr_QPE_03H_00.00_20160705-230000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_001_min_20160705-235900.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_005_min_20160705-235900.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_015_min_20160705-235900.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_-10C_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_-15C_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_-20C_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_-5C_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_0C_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_Reflectivity.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_ReflectivityAtLowestAltitude/20160705/MRMS_ReflectivityAtLowestAltitude_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_ReflectivityAtLowestAltitude.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_ReflectivityAtLowestAltitude.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_SeamlessHSR/20160705/MRMS_SeamlessHSR_00.00_20160705-235800.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_HSR.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_HSR.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_VII/20160705/MRMS_VII_00.50_20160705-235840.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_VII.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_VII.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160705/MRMS_GaugeCorr_QPE_01H_00.00_20160705-230000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_GaugeCoor/20160705/MRMS_GaugeCorr_QPE_03H_00.00_20160705-230000.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_gauge.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_001_min_20160705-234500.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_005_min_20160705-234500.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_NLDN_LightningDensity/20160705/MRMS_NLDN_LightningDensity_015_min_20160705-234500.nc.gz ...\n",
      "Create temp file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc\n",
      "Read Netcdf file /home/ldm/proj/TensorFlow/temp/temp_NLDN.nc ...\n",
      "Finish reading data\n",
      "\n",
      "Uncompressing gzip file /home/ldm/var/data//MRMS_Reflectivity/20160705/MRMS_Reflectivity_-10C_00.50_20160705-234437.nc.gz ...\n"
     ]
    }
   ],
   "source": [
    "import time as t\n",
    "st = t.time()\n",
    "half_grid_size = 30\n",
    "grid_size = 1 + half_grid_size * 2\n",
    "KFWS = []\n",
    "datetime_list = create_time_list('20160705', '235959', step_num = 96)\n",
    "for date_time in datetime_list:\n",
    "    temp_str = date_time.split(' ')\n",
    "    date = temp_str[0]\n",
    "    time = temp_str[1]\n",
    "    test.readDataInTime(date, time)\n",
    "    fn, feature = test.getFeatures()\n",
    "    feature = feature[index_lat - half_grid_size:index_lat + half_grid_size + 1, \n",
    "                        index_lon - half_grid_size: index_lon + half_grid_size + 1].reshape(1, grid_size, grid_size, 13).copy()\n",
    "    KFWS.append(feature)\n",
    "ed = t.time()\n",
    "print(ed - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume = np.vstack(KFWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = '/home/ldm/proj/TensorFlow/temp/' +  '20160705.pickle'\n",
    "\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    save = {\n",
    "        'volume':volume\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 0\n",
    "f = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = volume[s, :, :, 12]\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(v)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume[s, :, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = feature[:, :, 5]\n",
    "#f[f <= -990] = np.nan\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(f, extent = [230.005, 299.995, 20.005, 54.995])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
