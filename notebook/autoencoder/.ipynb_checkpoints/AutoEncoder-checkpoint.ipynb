{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS+NWP.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    test_dataset = save['test_dataset']\n",
    "    train_old = save['t_v_dataset']\n",
    "    del save\n",
    "\n",
    "\n",
    "test_data_1 = test_dataset['data_ASOS']\n",
    "test_data_2 = test_dataset['data_NWP']\n",
    "test_label = test_dataset['label']\n",
    "train_data_1 = train_old['data_ASOS']\n",
    "train_data_2 = train_old['data_NWP']\n",
    "train_label = train_old['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = hstack((train_data_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,) (70,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_old_data.mean(axis = 0)\n",
    "std = train_old_data.std(axis = 0)\n",
    "print(mean.shape, std.shape)\n",
    "train_data_n = (train_old_data - mean)/std\n",
    "test_data_n = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train_old_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfering the regression problem to classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_label = pre.transform(train_label.reshape(1, -1))\n",
    "b_test_label = pre.transform(test_label.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_train_label = 1 - b_train_label[0]\n",
    "\n",
    "c_test_label = 1 - b_test_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 199555, 1.0: 2715})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 5267 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#need to balanced the dataset\n",
    "from unbalanced_dataset.over_sampling import SMOTE\n",
    "sm = SMOTE(ratio = 0.04, kind='regular')\n",
    "train_data_n_resample, c_train_label_resample = sm.fit_transform(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle the data set\n",
    "arr = np.arange(c_train_label_resample.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "train_data_n_resample_s =  train_data_n_resample[arr]\n",
    "c_train_label_resample_s = c_train_label_resample[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_label_resample_s[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change from Indice to Vector\n",
    "''''''\n",
    "def makeIndicatorVars(T):\n",
    "    # Make sure T is two-dimensiona. Should be nSamples x 1.\n",
    "    if T.ndim == 1:\n",
    "        T = T.reshape((-1,1))    \n",
    "    return (T == np.unique(T)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_train_label = makeIndicatorVars(c_train_label.reshape(-1, 1))\n",
    "v_test_label = makeIndicatorVars(c_test_label.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_train_label_resample_s = makeIndicatorVars(c_train_label_resample_s.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write create simple linearLogistic Regression model\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(256, 70))\n",
    "    tf_train_label = tf.placeholder(tf.float32, shape=(256,2))\n",
    "    tf_validate_dataset = tf.constant(test_data_n.astype(np.float32)[:, :])\n",
    "    tf_validate_label = tf.constant(v_test_label.astype(np.float32)[:])\n",
    "    #tf_test_dataset1 = tf.constant(test_data_n.astype(np.float32)[:30000, :])\n",
    "    #tf_test_label1 = tf.constant(test_label.astype(np.float32)[:30000])\n",
    "    #tf_test_dataset2 = tf.constant(test_data_n.astype(np.float32)[30000:, :])\n",
    "    #tf_test_label2 = tf.constant(test_label.astype(np.float32)[30000:])\n",
    "    weights1 = tf.Variable(tf.truncated_normal([train_data_n.shape[1], 10]))\n",
    "    biases1 = tf.Variable(tf.zeros([10]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([10, 2]))\n",
    "    biases2 = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "    def acc(predict, label):\n",
    "        #correct_prediction = tf.equal(predicted_label, tf_train_label)\n",
    "        correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(label, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        predict_event = tf.reduce_sum(tf.argmax(predict, 1))\n",
    "        label_event = tf.reduce_sum(tf.argmax(label, 1))\n",
    "        true_positive = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 2), tf.int64))\n",
    "        true_negative = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 0), tf.int64))\n",
    "        false_positive = predict_event - true_positive \n",
    "        false_negative = label_event - true_positive\n",
    "        return accuracy, false_positive, false_negative, true_positive, true_negative\n",
    "    def ROC(FP, FN, TP, TN):\n",
    "        TP_percent = TP / (TP + FN)\n",
    "        FP_percent = FP / (FP + TN)\n",
    "        return TP_percent, FP_percent\n",
    "    \n",
    "    def PRC(FP, FN, TP, TN):\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f_score = 2 * precision * recall / (precision + recall)\n",
    "        return precision, recall, f_score\n",
    "    \n",
    "    def train_model(X):\n",
    "        hidden = tf.nn.relu6(tf.matmul(X, weights1) + biases1)\n",
    "        #hidden = tf.nn.dropout(hidden, 1.0)\n",
    "        return tf.nn.softmax(tf.matmul(hidden, weights2) + biases2)\n",
    "    \n",
    "    def eval_model(X):\n",
    "        hidden = tf.nn.relu6(tf.matmul(X, weights1) + biases1)\n",
    "        return tf.nn.softmax(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "    predicted_label = train_model(tf_train_dataset)\n",
    "    #loss = tf.reduce_mean(tf.square(predicted_label - tf_train_label))\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(tf_train_label * tf.log(predicted_label), reduction_indices=[1]))\n",
    "\n",
    "    # Learning rate decay\n",
    "    global_step = tf.Variable(0)\n",
    "    starter_learning_rate = 0.05\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 2500, 0.96, staircase=True)\n",
    "    op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "\n",
    "    \n",
    "    train_acc, _, _, _, _ = acc(predicted_label, tf_train_label)\n",
    "    validate_acc, FP, FN, TP, TN = acc(eval_model(tf_validate_dataset), tf_validate_label)\n",
    "    t_p, f_p = ROC(FP, FN, TP, TN)\n",
    "    pre, rec, f_s = PRC(FP, FN, TP, TN)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #train_loss = tf.reduce_mean(tf.abs(predicted_label - tf_train_label))\n",
    "    #test_loss1 = tf.reduce_mean(tf.abs(model(tf_test_dataset1, weights, biases) - tf_test_label1))\n",
    "    #test_loss2 = tf.reduce_mean(tf.abs(model(tf_test_dataset2, weights, biases) - tf_test_label2))\n",
    "    #test_loss = (test_loss1 * 30000 + test_loss2 * (test_size - 30000)) / test_size\n",
    "    #validate_loss = tf.reduce_mean(tf.abs(model(tf_validate_dataset, weights, biases) - tf_validate_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0 : train acc = 0.480469, validate acc = 0.506595\n",
      "240 24469 482 25378\n",
      "precision = 0.009713, recall = 0.332410, f_score = 0.018875\n",
      "Loss at step 1000 : train acc = 0.968750, validate acc = 0.979770\n",
      "203 504 519 49343\n",
      "precision = 0.287129, recall = 0.281163, f_score = 0.284115\n",
      "Loss at step 2000 : train acc = 0.972656, validate acc = 0.980284\n",
      "250 525 472 49322\n",
      "precision = 0.322581, recall = 0.346260, f_score = 0.334001\n",
      "Loss at step 3000 : train acc = 0.953125, validate acc = 0.981214\n",
      "262 490 460 49357\n",
      "precision = 0.348404, recall = 0.362881, f_score = 0.355495\n",
      "Loss at step 4000 : train acc = 0.953125, validate acc = 0.982717\n",
      "266 418 456 49429\n",
      "precision = 0.388889, recall = 0.368421, f_score = 0.378378\n",
      "Loss at step 5000 : train acc = 0.968750, validate acc = 0.984437\n",
      "256 321 466 49526\n",
      "precision = 0.443674, recall = 0.354571, f_score = 0.394149\n",
      "Loss at step 6000 : train acc = 0.976562, validate acc = 0.984477\n",
      "259 322 463 49525\n",
      "precision = 0.445783, recall = 0.358726, f_score = 0.397544\n",
      "Loss at step 7000 : train acc = 0.984375, validate acc = 0.984556\n",
      "270 329 452 49518\n",
      "precision = 0.450751, recall = 0.373961, f_score = 0.408781\n",
      "Loss at step 8000 : train acc = 0.980469, validate acc = 0.985109\n",
      "258 289 464 49558\n",
      "precision = 0.471664, recall = 0.357341, f_score = 0.406619\n",
      "Loss at step 9000 : train acc = 0.968750, validate acc = 0.984655\n",
      "297 351 425 49496\n",
      "precision = 0.458333, recall = 0.411357, f_score = 0.433577\n",
      "Loss at step 10000 : train acc = 0.984375, validate acc = 0.984773\n",
      "310 358 412 49489\n",
      "precision = 0.464072, recall = 0.429363, f_score = 0.446043\n",
      "Loss at step 11000 : train acc = 0.972656, validate acc = 0.985406\n",
      "295 311 427 49536\n",
      "precision = 0.486799, recall = 0.408587, f_score = 0.444277\n",
      "Loss at step 12000 : train acc = 0.968750, validate acc = 0.985841\n",
      "273 267 449 49580\n",
      "precision = 0.505556, recall = 0.378116, f_score = 0.432647\n",
      "Loss at step 13000 : train acc = 0.964844, validate acc = 0.985980\n",
      "267 254 455 49593\n",
      "precision = 0.512476, recall = 0.369806, f_score = 0.429606\n",
      "Loss at step 14000 : train acc = 0.972656, validate acc = 0.986118\n",
      "263 243 459 49604\n",
      "precision = 0.519763, recall = 0.364266, f_score = 0.428339\n",
      "Loss at step 15000 : train acc = 0.968750, validate acc = 0.985228\n",
      "306 331 416 49516\n",
      "precision = 0.480377, recall = 0.423823, f_score = 0.450331\n",
      "Loss at step 16000 : train acc = 0.976562, validate acc = 0.985980\n",
      "279 266 443 49581\n",
      "precision = 0.511927, recall = 0.386427, f_score = 0.440410\n",
      "Loss at step 17000 : train acc = 0.976562, validate acc = 0.984971\n",
      "321 359 401 49488\n",
      "precision = 0.472059, recall = 0.444598, f_score = 0.457917\n",
      "Loss at step 18000 : train acc = 0.976562, validate acc = 0.984931\n",
      "330 370 392 49477\n",
      "precision = 0.471429, recall = 0.457064, f_score = 0.464135\n",
      "Loss at step 19000 : train acc = 0.984375, validate acc = 0.985406\n",
      "319 335 403 49512\n",
      "precision = 0.487768, recall = 0.441828, f_score = 0.463663\n",
      "Loss at step 20000 : train acc = 0.976562, validate acc = 0.986415\n",
      "272 237 450 49610\n",
      "precision = 0.534381, recall = 0.376731, f_score = 0.441917\n",
      "Loss at step 21000 : train acc = 0.957031, validate acc = 0.986316\n",
      "290 260 432 49587\n",
      "precision = 0.527273, recall = 0.401662, f_score = 0.455975\n",
      "Loss at step 22000 : train acc = 0.988281, validate acc = 0.986296\n",
      "289 260 433 49587\n",
      "precision = 0.526412, recall = 0.400277, f_score = 0.454760\n",
      "Loss at step 23000 : train acc = 0.980469, validate acc = 0.985802\n",
      "298 294 424 49553\n",
      "precision = 0.503378, recall = 0.412742, f_score = 0.453577\n",
      "Loss at step 24000 : train acc = 0.972656, validate acc = 0.985722\n",
      "301 301 421 49546\n",
      "precision = 0.500000, recall = 0.416898, f_score = 0.454683\n",
      "Loss at step 25000 : train acc = 0.972656, validate acc = 0.985406\n",
      "328 344 394 49503\n",
      "precision = 0.488095, recall = 0.454294, f_score = 0.470588\n",
      "Loss at step 26000 : train acc = 0.980469, validate acc = 0.985643\n",
      "309 313 413 49534\n",
      "precision = 0.496785, recall = 0.427978, f_score = 0.459821\n",
      "Loss at step 27000 : train acc = 0.980469, validate acc = 0.986355\n",
      "293 261 429 49586\n",
      "precision = 0.528881, recall = 0.405817, f_score = 0.459248\n",
      "Loss at step 28000 : train acc = 0.968750, validate acc = 0.986494\n",
      "297 258 425 49589\n",
      "precision = 0.535135, recall = 0.411357, f_score = 0.465153\n",
      "Loss at step 29000 : train acc = 0.980469, validate acc = 0.986454\n",
      "296 259 426 49588\n",
      "precision = 0.533333, recall = 0.409972, f_score = 0.463587\n",
      "Loss at step 30000 : train acc = 0.968750, validate acc = 0.985505\n",
      "326 337 396 49510\n",
      "precision = 0.491704, recall = 0.451524, f_score = 0.470758\n",
      "Loss at step 31000 : train acc = 0.988281, validate acc = 0.986395\n",
      "295 261 427 49586\n",
      "precision = 0.530576, recall = 0.408587, f_score = 0.461659\n",
      "Loss at step 32000 : train acc = 0.980469, validate acc = 0.986039\n",
      "324 308 398 49539\n",
      "precision = 0.512658, recall = 0.448753, f_score = 0.478582\n",
      "Loss at step 33000 : train acc = 0.988281, validate acc = 0.986138\n",
      "310 289 412 49558\n",
      "precision = 0.517529, recall = 0.429363, f_score = 0.469341\n",
      "Loss at step 34000 : train acc = 0.992188, validate acc = 0.985802\n",
      "337 333 385 49514\n",
      "precision = 0.502985, recall = 0.466759, f_score = 0.484195\n",
      "Loss at step 35000 : train acc = 0.972656, validate acc = 0.986217\n",
      "308 283 414 49564\n",
      "precision = 0.521151, recall = 0.426593, f_score = 0.469155\n",
      "Loss at step 36000 : train acc = 0.968750, validate acc = 0.986454\n",
      "299 262 423 49585\n",
      "precision = 0.532977, recall = 0.414127, f_score = 0.466095\n",
      "Loss at step 37000 : train acc = 0.980469, validate acc = 0.986197\n",
      "319 295 403 49552\n",
      "precision = 0.519544, recall = 0.441828, f_score = 0.477545\n",
      "Loss at step 38000 : train acc = 0.953125, validate acc = 0.986237\n",
      "322 296 400 49551\n",
      "precision = 0.521036, recall = 0.445983, f_score = 0.480597\n",
      "Loss at step 39000 : train acc = 0.976562, validate acc = 0.986355\n",
      "312 280 410 49567\n",
      "precision = 0.527027, recall = 0.432133, f_score = 0.474886\n",
      "Loss at step 40000 : train acc = 0.996094, validate acc = 0.986217\n",
      "340 315 382 49532\n",
      "precision = 0.519084, recall = 0.470914, f_score = 0.493827\n",
      "Loss at step 41000 : train acc = 0.984375, validate acc = 0.986217\n",
      "338 313 384 49534\n",
      "precision = 0.519201, recall = 0.468144, f_score = 0.492353\n",
      "Loss at step 42000 : train acc = 0.972656, validate acc = 0.986909\n",
      "305 245 417 49602\n",
      "precision = 0.554545, recall = 0.422438, f_score = 0.479560\n",
      "Loss at step 43000 : train acc = 0.964844, validate acc = 0.986474\n",
      "324 286 398 49561\n",
      "precision = 0.531148, recall = 0.448753, f_score = 0.486486\n",
      "Loss at step 44000 : train acc = 0.980469, validate acc = 0.986869\n",
      "302 244 420 49603\n",
      "precision = 0.553114, recall = 0.418283, f_score = 0.476341\n",
      "Loss at step 45000 : train acc = 0.972656, validate acc = 0.986118\n",
      "358 338 364 49509\n",
      "precision = 0.514368, recall = 0.495845, f_score = 0.504937\n",
      "Loss at step 46000 : train acc = 0.996094, validate acc = 0.986672\n",
      "318 270 404 49577\n",
      "precision = 0.540816, recall = 0.440443, f_score = 0.485496\n",
      "Loss at step 47000 : train acc = 0.972656, validate acc = 0.986691\n",
      "330 281 392 49566\n",
      "precision = 0.540098, recall = 0.457064, f_score = 0.495124\n",
      "Loss at step 48000 : train acc = 0.960938, validate acc = 0.986711\n",
      "328 278 394 49569\n",
      "precision = 0.541254, recall = 0.454294, f_score = 0.493976\n",
      "Loss at step 49000 : train acc = 0.972656, validate acc = 0.986652\n",
      "346 299 376 49548\n",
      "precision = 0.536434, recall = 0.479224, f_score = 0.506218\n",
      "Loss at step 50000 : train acc = 0.980469, validate acc = 0.986751\n",
      "336 284 386 49563\n",
      "precision = 0.541935, recall = 0.465374, f_score = 0.500745\n",
      "Loss at step 51000 : train acc = 0.996094, validate acc = 0.986869\n",
      "336 278 386 49569\n",
      "precision = 0.547231, recall = 0.465374, f_score = 0.502994\n",
      "Loss at step 52000 : train acc = 0.972656, validate acc = 0.986909\n",
      "330 270 392 49577\n",
      "precision = 0.550000, recall = 0.457064, f_score = 0.499244\n",
      "Loss at step 53000 : train acc = 0.968750, validate acc = 0.986751\n",
      "346 294 376 49553\n",
      "precision = 0.540625, recall = 0.479224, f_score = 0.508076\n",
      "Loss at step 54000 : train acc = 0.980469, validate acc = 0.986949\n",
      "328 266 394 49581\n",
      "precision = 0.552189, recall = 0.454294, f_score = 0.498480\n",
      "Loss at step 55000 : train acc = 0.984375, validate acc = 0.986830\n",
      "348 292 374 49555\n",
      "precision = 0.543750, recall = 0.481994, f_score = 0.511013\n",
      "Loss at step 56000 : train acc = 0.968750, validate acc = 0.986869\n",
      "350 292 372 49555\n",
      "precision = 0.545171, recall = 0.484765, f_score = 0.513196\n",
      "Loss at step 57000 : train acc = 0.968750, validate acc = 0.987127\n",
      "332 261 390 49586\n",
      "precision = 0.559865, recall = 0.459834, f_score = 0.504943\n",
      "Loss at step 58000 : train acc = 0.992188, validate acc = 0.987127\n",
      "330 259 392 49588\n",
      "precision = 0.560272, recall = 0.457064, f_score = 0.503432\n",
      "Loss at step 59000 : train acc = 0.976562, validate acc = 0.987127\n",
      "332 261 390 49586\n",
      "precision = 0.559865, recall = 0.459834, f_score = 0.504943\n",
      "Loss at step 60000 : train acc = 0.992188, validate acc = 0.986553\n",
      "374 332 348 49515\n",
      "precision = 0.529745, recall = 0.518006, f_score = 0.523810\n",
      "Loss at step 61000 : train acc = 0.976562, validate acc = 0.986869\n",
      "353 295 369 49552\n",
      "precision = 0.544753, recall = 0.488920, f_score = 0.515328\n",
      "Loss at step 62000 : train acc = 0.980469, validate acc = 0.987403\n",
      "326 241 396 49606\n",
      "precision = 0.574956, recall = 0.451524, f_score = 0.505818\n",
      "Loss at step 63000 : train acc = 1.000000, validate acc = 0.987225\n",
      "332 256 390 49591\n",
      "precision = 0.564626, recall = 0.459834, f_score = 0.506870\n",
      "Loss at step 64000 : train acc = 0.980469, validate acc = 0.986968\n",
      "346 283 376 49564\n",
      "precision = 0.550079, recall = 0.479224, f_score = 0.512213\n",
      "Loss at step 65000 : train acc = 0.984375, validate acc = 0.987107\n",
      "354 284 368 49563\n",
      "precision = 0.554859, recall = 0.490305, f_score = 0.520588\n",
      "Loss at step 66000 : train acc = 0.984375, validate acc = 0.987166\n",
      "353 280 369 49567\n",
      "precision = 0.557662, recall = 0.488920, f_score = 0.521033\n",
      "Loss at step 67000 : train acc = 0.964844, validate acc = 0.987225\n",
      "336 260 386 49587\n",
      "precision = 0.563758, recall = 0.465374, f_score = 0.509863\n",
      "Loss at step 68000 : train acc = 0.980469, validate acc = 0.987324\n",
      "343 262 379 49585\n",
      "precision = 0.566942, recall = 0.475069, f_score = 0.516956\n",
      "Loss at step 69000 : train acc = 0.968750, validate acc = 0.987344\n",
      "351 269 371 49578\n",
      "precision = 0.566129, recall = 0.486150, f_score = 0.523100\n",
      "Loss at step 70000 : train acc = 0.984375, validate acc = 0.987423\n",
      "348 262 374 49585\n",
      "precision = 0.570492, recall = 0.481994, f_score = 0.522523\n",
      "Loss at step 71000 : train acc = 0.988281, validate acc = 0.987146\n",
      "364 292 358 49555\n",
      "precision = 0.554878, recall = 0.504155, f_score = 0.528302\n",
      "Loss at step 72000 : train acc = 0.980469, validate acc = 0.987403\n",
      "351 266 371 49581\n",
      "precision = 0.568882, recall = 0.486150, f_score = 0.524272\n",
      "Loss at step 73000 : train acc = 0.980469, validate acc = 0.987522\n",
      "348 257 374 49590\n",
      "precision = 0.575207, recall = 0.481994, f_score = 0.524491\n",
      "Loss at step 74000 : train acc = 0.964844, validate acc = 0.987621\n",
      "347 251 375 49596\n",
      "precision = 0.580268, recall = 0.480609, f_score = 0.525758\n",
      "Loss at step 75000 : train acc = 0.992188, validate acc = 0.986731\n",
      "380 329 342 49518\n",
      "precision = 0.535966, recall = 0.526316, f_score = 0.531097\n",
      "Loss at step 76000 : train acc = 0.976562, validate acc = 0.987186\n",
      "362 288 360 49559\n",
      "precision = 0.556923, recall = 0.501385, f_score = 0.527697\n",
      "Loss at step 77000 : train acc = 0.972656, validate acc = 0.987680\n",
      "335 236 387 49611\n",
      "precision = 0.586690, recall = 0.463989, f_score = 0.518175\n",
      "Loss at step 78000 : train acc = 0.976562, validate acc = 0.987482\n",
      "353 264 369 49583\n",
      "precision = 0.572123, recall = 0.488920, f_score = 0.527259\n",
      "Loss at step 79000 : train acc = 0.976562, validate acc = 0.987127\n",
      "366 295 356 49552\n",
      "precision = 0.553707, recall = 0.506925, f_score = 0.529284\n",
      "Loss at step 80000 : train acc = 0.976562, validate acc = 0.987304\n",
      "362 282 360 49565\n",
      "precision = 0.562112, recall = 0.501385, f_score = 0.530015\n",
      "Loss at step 81000 : train acc = 0.976562, validate acc = 0.987522\n",
      "361 270 361 49577\n",
      "precision = 0.572108, recall = 0.500000, f_score = 0.533629\n",
      "Loss at step 82000 : train acc = 0.984375, validate acc = 0.987482\n",
      "352 263 370 49584\n",
      "precision = 0.572358, recall = 0.487535, f_score = 0.526552\n",
      "Loss at step 83000 : train acc = 0.976562, validate acc = 0.987324\n",
      "366 285 356 49562\n",
      "precision = 0.562212, recall = 0.506925, f_score = 0.533139\n",
      "Loss at step 84000 : train acc = 0.988281, validate acc = 0.987522\n",
      "357 266 365 49581\n",
      "precision = 0.573034, recall = 0.494460, f_score = 0.530855\n",
      "Loss at step 85000 : train acc = 0.972656, validate acc = 0.987581\n",
      "357 263 365 49584\n",
      "precision = 0.575806, recall = 0.494460, f_score = 0.532042\n",
      "Loss at step 86000 : train acc = 0.976562, validate acc = 0.987245\n",
      "366 289 356 49558\n",
      "precision = 0.558779, recall = 0.506925, f_score = 0.531590\n",
      "Loss at step 87000 : train acc = 0.980469, validate acc = 0.987463\n",
      "358 270 364 49577\n",
      "precision = 0.570064, recall = 0.495845, f_score = 0.530370\n",
      "Loss at step 88000 : train acc = 0.976562, validate acc = 0.987700\n",
      "354 254 368 49593\n",
      "precision = 0.582237, recall = 0.490305, f_score = 0.532331\n",
      "Loss at step 89000 : train acc = 0.988281, validate acc = 0.987740\n",
      "354 252 368 49595\n",
      "precision = 0.584158, recall = 0.490305, f_score = 0.533133\n",
      "Loss at step 90000 : train acc = 0.968750, validate acc = 0.986909\n",
      "381 321 341 49526\n",
      "precision = 0.542735, recall = 0.527701, f_score = 0.535112\n",
      "Loss at step 91000 : train acc = 0.960938, validate acc = 0.987344\n",
      "364 282 358 49565\n",
      "precision = 0.563467, recall = 0.504155, f_score = 0.532164\n",
      "Loss at step 92000 : train acc = 0.988281, validate acc = 0.988056\n",
      "349 231 373 49616\n",
      "precision = 0.601724, recall = 0.483380, f_score = 0.536098\n",
      "Loss at step 93000 : train acc = 0.980469, validate acc = 0.987680\n",
      "358 259 364 49588\n",
      "precision = 0.580227, recall = 0.495845, f_score = 0.534727\n",
      "Loss at step 94000 : train acc = 0.988281, validate acc = 0.987285\n",
      "360 281 362 49566\n",
      "precision = 0.561622, recall = 0.498615, f_score = 0.528247\n",
      "Loss at step 95000 : train acc = 0.976562, validate acc = 0.987285\n",
      "366 287 356 49560\n",
      "precision = 0.560490, recall = 0.506925, f_score = 0.532364\n",
      "Loss at step 96000 : train acc = 0.968750, validate acc = 0.987720\n",
      "358 257 364 49590\n",
      "precision = 0.582114, recall = 0.495845, f_score = 0.535527\n",
      "Loss at step 97000 : train acc = 0.976562, validate acc = 0.987601\n",
      "359 264 363 49583\n",
      "precision = 0.576244, recall = 0.497230, f_score = 0.533829\n",
      "Loss at step 98000 : train acc = 0.980469, validate acc = 0.987364\n",
      "364 281 358 49566\n",
      "precision = 0.564341, recall = 0.504155, f_score = 0.532553\n",
      "Loss at step 99000 : train acc = 0.992188, validate acc = 0.987838\n",
      "355 248 367 49599\n",
      "precision = 0.588723, recall = 0.491690, f_score = 0.535849\n",
      "Loss at step 100000 : train acc = 0.980469, validate acc = 0.987799\n",
      "357 252 365 49595\n",
      "precision = 0.586207, recall = 0.494460, f_score = 0.536439\n",
      "Loss at step 101000 : train acc = 0.976562, validate acc = 0.987245\n",
      "368 291 354 49556\n",
      "precision = 0.558422, recall = 0.509695, f_score = 0.532947\n",
      "Loss at step 102000 : train acc = 0.988281, validate acc = 0.987660\n",
      "358 260 364 49587\n",
      "precision = 0.579288, recall = 0.495845, f_score = 0.534328\n",
      "Loss at step 103000 : train acc = 0.957031, validate acc = 0.987720\n",
      "358 257 364 49590\n",
      "precision = 0.582114, recall = 0.495845, f_score = 0.535527\n",
      "Loss at step 104000 : train acc = 0.996094, validate acc = 0.987720\n",
      "358 257 364 49590\n",
      "precision = 0.582114, recall = 0.495845, f_score = 0.535527\n",
      "Loss at step 105000 : train acc = 0.976562, validate acc = 0.987047\n",
      "378 311 344 49536\n",
      "precision = 0.548621, recall = 0.523546, f_score = 0.535790\n",
      "Loss at step 106000 : train acc = 0.964844, validate acc = 0.987463\n",
      "363 275 359 49572\n",
      "precision = 0.568966, recall = 0.502770, f_score = 0.533824\n",
      "Loss at step 107000 : train acc = 0.972656, validate acc = 0.988056\n",
      "354 236 368 49611\n",
      "precision = 0.600000, recall = 0.490305, f_score = 0.539634\n",
      "Loss at step 108000 : train acc = 0.984375, validate acc = 0.987304\n",
      "366 286 356 49561\n",
      "precision = 0.561350, recall = 0.506925, f_score = 0.532751\n",
      "Loss at step 109000 : train acc = 0.996094, validate acc = 0.987285\n",
      "371 292 351 49555\n",
      "precision = 0.559578, recall = 0.513850, f_score = 0.535740\n",
      "Loss at step 110000 : train acc = 0.960938, validate acc = 0.987581\n",
      "361 267 361 49580\n",
      "precision = 0.574841, recall = 0.500000, f_score = 0.534815\n",
      "Loss at step 111000 : train acc = 0.972656, validate acc = 0.987937\n",
      "357 245 365 49602\n",
      "precision = 0.593023, recall = 0.494460, f_score = 0.539275\n",
      "Loss at step 112000 : train acc = 0.960938, validate acc = 0.987562\n",
      "360 267 362 49580\n",
      "precision = 0.574163, recall = 0.498615, f_score = 0.533729\n",
      "Loss at step 113000 : train acc = 0.984375, validate acc = 0.987344\n",
      "364 282 358 49565\n",
      "precision = 0.563467, recall = 0.504155, f_score = 0.532164\n",
      "Loss at step 114000 : train acc = 0.980469, validate acc = 0.987838\n",
      "357 250 365 49597\n",
      "precision = 0.588138, recall = 0.494460, f_score = 0.537246\n",
      "Loss at step 115000 : train acc = 0.984375, validate acc = 0.987937\n",
      "356 244 366 49603\n",
      "precision = 0.593333, recall = 0.493075, f_score = 0.538578\n",
      "Loss at step 116000 : train acc = 0.957031, validate acc = 0.987423\n",
      "367 281 355 49566\n",
      "precision = 0.566358, recall = 0.508310, f_score = 0.535766\n",
      "Loss at step 117000 : train acc = 0.972656, validate acc = 0.987720\n",
      "362 261 360 49586\n",
      "precision = 0.581059, recall = 0.501385, f_score = 0.538290\n",
      "Loss at step 118000 : train acc = 0.980469, validate acc = 0.987799\n",
      "362 257 360 49590\n",
      "precision = 0.584814, recall = 0.501385, f_score = 0.539896\n",
      "Loss at step 119000 : train acc = 0.984375, validate acc = 0.987700\n",
      "360 260 362 49587\n",
      "precision = 0.580645, recall = 0.498615, f_score = 0.536513\n",
      "Loss at step 120000 : train acc = 0.968750, validate acc = 0.987127\n",
      "376 305 346 49542\n",
      "precision = 0.552129, recall = 0.520776, f_score = 0.535994\n",
      "Loss at step 121000 : train acc = 0.984375, validate acc = 0.987542\n",
      "362 270 360 49577\n",
      "precision = 0.572785, recall = 0.501385, f_score = 0.534712\n",
      "Loss at step 122000 : train acc = 0.984375, validate acc = 0.987878\n",
      "356 247 366 49600\n",
      "precision = 0.590381, recall = 0.493075, f_score = 0.537358\n",
      "Loss at step 123000 : train acc = 0.992188, validate acc = 0.987522\n",
      "363 272 359 49575\n",
      "precision = 0.571654, recall = 0.502770, f_score = 0.535004\n",
      "Loss at step 124000 : train acc = 0.988281, validate acc = 0.987344\n",
      "370 288 352 49559\n",
      "precision = 0.562310, recall = 0.512465, f_score = 0.536232\n",
      "Loss at step 125000 : train acc = 0.980469, validate acc = 0.987463\n",
      "365 277 357 49570\n",
      "precision = 0.568536, recall = 0.505540, f_score = 0.535191\n",
      "Loss at step 126000 : train acc = 1.000000, validate acc = 0.987779\n",
      "362 258 360 49589\n",
      "precision = 0.583871, recall = 0.501385, f_score = 0.539493\n",
      "Loss at step 127000 : train acc = 0.976562, validate acc = 0.987720\n",
      "359 258 363 49589\n",
      "precision = 0.581848, recall = 0.497230, f_score = 0.536221\n",
      "Loss at step 128000 : train acc = 0.992188, validate acc = 0.987364\n",
      "366 283 356 49564\n",
      "precision = 0.563945, recall = 0.506925, f_score = 0.533917\n",
      "Loss at step 129000 : train acc = 0.960938, validate acc = 0.987779\n",
      "358 254 364 49593\n",
      "precision = 0.584967, recall = 0.495845, f_score = 0.536732\n",
      "Loss at step 130000 : train acc = 0.980469, validate acc = 0.987858\n",
      "356 248 366 49599\n",
      "precision = 0.589404, recall = 0.493075, f_score = 0.536953\n",
      "Loss at step 131000 : train acc = 0.980469, validate acc = 0.987423\n",
      "369 283 353 49564\n",
      "precision = 0.565951, recall = 0.511080, f_score = 0.537118\n",
      "Loss at step 132000 : train acc = 0.980469, validate acc = 0.987581\n",
      "364 270 358 49577\n",
      "precision = 0.574132, recall = 0.504155, f_score = 0.536873\n",
      "Loss at step 133000 : train acc = 0.992188, validate acc = 0.987641\n",
      "367 270 355 49577\n",
      "precision = 0.576138, recall = 0.508310, f_score = 0.540103\n",
      "Loss at step 134000 : train acc = 0.988281, validate acc = 0.987680\n",
      "365 266 357 49581\n",
      "precision = 0.578447, recall = 0.505540, f_score = 0.539542\n",
      "Loss at step 135000 : train acc = 0.988281, validate acc = 0.987127\n",
      "376 305 346 49542\n",
      "precision = 0.552129, recall = 0.520776, f_score = 0.535994\n",
      "Loss at step 136000 : train acc = 0.976562, validate acc = 0.987740\n",
      "363 261 359 49586\n",
      "precision = 0.581731, recall = 0.502770, f_score = 0.539376\n",
      "Loss at step 137000 : train acc = 0.968750, validate acc = 0.987898\n",
      "356 246 366 49601\n",
      "precision = 0.591362, recall = 0.493075, f_score = 0.537764\n",
      "Loss at step 138000 : train acc = 0.988281, validate acc = 0.987740\n",
      "365 263 357 49584\n",
      "precision = 0.581210, recall = 0.505540, f_score = 0.540741\n",
      "Loss at step 139000 : train acc = 0.988281, validate acc = 0.987285\n",
      "373 294 349 49553\n",
      "precision = 0.559220, recall = 0.516620, f_score = 0.537077\n",
      "Loss at step 140000 : train acc = 0.984375, validate acc = 0.987641\n",
      "364 267 358 49580\n",
      "precision = 0.576862, recall = 0.504155, f_score = 0.538064\n",
      "Loss at step 141000 : train acc = 0.992188, validate acc = 0.987720\n",
      "365 264 357 49583\n",
      "precision = 0.580286, recall = 0.505540, f_score = 0.540340\n",
      "Loss at step 142000 : train acc = 0.984375, validate acc = 0.987759\n",
      "365 262 357 49585\n",
      "precision = 0.582137, recall = 0.505540, f_score = 0.541142\n",
      "Loss at step 143000 : train acc = 0.972656, validate acc = 0.987403\n",
      "370 285 352 49562\n",
      "precision = 0.564885, recall = 0.512465, f_score = 0.537400\n",
      "Loss at step 144000 : train acc = 0.972656, validate acc = 0.987838\n",
      "362 255 360 49592\n",
      "precision = 0.586710, recall = 0.501385, f_score = 0.540702\n",
      "Loss at step 145000 : train acc = 0.984375, validate acc = 0.987917\n",
      "357 246 365 49601\n",
      "precision = 0.592040, recall = 0.494460, f_score = 0.538868\n",
      "Loss at step 146000 : train acc = 0.980469, validate acc = 0.987403\n",
      "369 284 353 49563\n",
      "precision = 0.565084, recall = 0.511080, f_score = 0.536727\n",
      "Loss at step 147000 : train acc = 0.988281, validate acc = 0.987700\n",
      "365 265 357 49582\n",
      "precision = 0.579365, recall = 0.505540, f_score = 0.539941\n",
      "Loss at step 148000 : train acc = 0.984375, validate acc = 0.987581\n",
      "366 272 356 49575\n",
      "precision = 0.573668, recall = 0.506925, f_score = 0.538235\n",
      "Loss at step 149000 : train acc = 0.988281, validate acc = 0.987759\n",
      "364 261 358 49586\n",
      "precision = 0.582400, recall = 0.504155, f_score = 0.540460\n",
      "Loss at step 150000 : train acc = 0.988281, validate acc = 0.987225\n",
      "378 302 344 49545\n",
      "precision = 0.555882, recall = 0.523546, f_score = 0.539230\n",
      "Loss at step 151000 : train acc = 0.976562, validate acc = 0.987542\n",
      "365 273 357 49574\n",
      "precision = 0.572100, recall = 0.505540, f_score = 0.536765\n",
      "Loss at step 152000 : train acc = 0.976562, validate acc = 0.987878\n",
      "359 250 363 49597\n",
      "precision = 0.589491, recall = 0.497230, f_score = 0.539444\n",
      "Loss at step 153000 : train acc = 0.988281, validate acc = 0.987700\n",
      "365 265 357 49582\n",
      "precision = 0.579365, recall = 0.505540, f_score = 0.539941\n",
      "Loss at step 154000 : train acc = 0.980469, validate acc = 0.987344\n",
      "374 292 348 49555\n",
      "precision = 0.561562, recall = 0.518006, f_score = 0.538905\n",
      "Loss at step 155000 : train acc = 0.984375, validate acc = 0.987641\n",
      "365 268 357 49579\n",
      "precision = 0.576619, recall = 0.505540, f_score = 0.538745\n",
      "Loss at step 156000 : train acc = 1.000000, validate acc = 0.987621\n",
      "365 269 357 49578\n",
      "precision = 0.575710, recall = 0.505540, f_score = 0.538348\n",
      "Loss at step 157000 : train acc = 0.968750, validate acc = 0.987660\n",
      "365 267 357 49580\n",
      "precision = 0.577532, recall = 0.505540, f_score = 0.539143\n",
      "Loss at step 158000 : train acc = 0.972656, validate acc = 0.987482\n",
      "368 279 354 49568\n",
      "precision = 0.568779, recall = 0.509695, f_score = 0.537619\n",
      "Loss at step 159000 : train acc = 0.968750, validate acc = 0.987779\n",
      "364 260 358 49587\n",
      "precision = 0.583333, recall = 0.504155, f_score = 0.540862\n",
      "Loss at step 160000 : train acc = 0.992188, validate acc = 0.987819\n",
      "359 253 363 49594\n",
      "precision = 0.586601, recall = 0.497230, f_score = 0.538231\n",
      "Loss at step 161000 : train acc = 0.964844, validate acc = 0.987364\n",
      "371 288 351 49559\n",
      "precision = 0.562974, recall = 0.513850, f_score = 0.537292\n",
      "Loss at step 162000 : train acc = 0.996094, validate acc = 0.987562\n",
      "366 273 356 49574\n",
      "precision = 0.572770, recall = 0.506925, f_score = 0.537840\n",
      "Loss at step 163000 : train acc = 0.976562, validate acc = 0.987641\n",
      "365 268 357 49579\n",
      "precision = 0.576619, recall = 0.505540, f_score = 0.538745\n",
      "Loss at step 164000 : train acc = 0.960938, validate acc = 0.987779\n",
      "363 259 359 49588\n",
      "precision = 0.583601, recall = 0.502770, f_score = 0.540179\n",
      "Loss at step 165000 : train acc = 0.976562, validate acc = 0.987403\n",
      "380 295 342 49552\n",
      "precision = 0.562963, recall = 0.526316, f_score = 0.544023\n",
      "Loss at step 166000 : train acc = 0.984375, validate acc = 0.987542\n",
      "369 277 353 49570\n",
      "precision = 0.571207, recall = 0.511080, f_score = 0.539474\n",
      "Loss at step 167000 : train acc = 0.996094, validate acc = 0.987759\n",
      "363 260 359 49587\n",
      "precision = 0.582665, recall = 0.502770, f_score = 0.539777\n",
      "Loss at step 168000 : train acc = 0.960938, validate acc = 0.987700\n",
      "364 264 358 49583\n",
      "precision = 0.579618, recall = 0.504155, f_score = 0.539259\n",
      "Loss at step 169000 : train acc = 0.968750, validate acc = 0.987463\n",
      "379 291 343 49556\n",
      "precision = 0.565672, recall = 0.524931, f_score = 0.544540\n",
      "Loss at step 170000 : train acc = 0.976562, validate acc = 0.987601\n",
      "365 270 357 49577\n",
      "precision = 0.574803, recall = 0.505540, f_score = 0.537951\n",
      "Loss at step 171000 : train acc = 0.992188, validate acc = 0.987641\n",
      "365 268 357 49579\n",
      "precision = 0.576619, recall = 0.505540, f_score = 0.538745\n",
      "Loss at step 172000 : train acc = 0.972656, validate acc = 0.987700\n",
      "365 265 357 49582\n",
      "precision = 0.579365, recall = 0.505540, f_score = 0.539941\n",
      "Loss at step 173000 : train acc = 0.976562, validate acc = 0.987601\n",
      "373 278 349 49569\n",
      "precision = 0.572965, recall = 0.516620, f_score = 0.543336\n",
      "Loss at step 174000 : train acc = 0.996094, validate acc = 0.987759\n",
      "364 261 358 49586\n",
      "precision = 0.582400, recall = 0.504155, f_score = 0.540460\n",
      "Loss at step 175000 : train acc = 0.980469, validate acc = 0.987779\n",
      "362 258 360 49589\n",
      "precision = 0.583871, recall = 0.501385, f_score = 0.539493\n",
      "Loss at step 176000 : train acc = 0.988281, validate acc = 0.987443\n",
      "375 288 347 49559\n",
      "precision = 0.565611, recall = 0.519391, f_score = 0.541516\n",
      "Loss at step 177000 : train acc = 0.972656, validate acc = 0.987542\n",
      "373 281 349 49566\n",
      "precision = 0.570336, recall = 0.516620, f_score = 0.542151\n",
      "Loss at step 178000 : train acc = 0.980469, validate acc = 0.987759\n",
      "364 261 358 49586\n",
      "precision = 0.582400, recall = 0.504155, f_score = 0.540460\n",
      "Loss at step 179000 : train acc = 1.000000, validate acc = 0.987779\n",
      "363 259 359 49588\n",
      "precision = 0.583601, recall = 0.502770, f_score = 0.540179\n",
      "Loss at step 180000 : train acc = 0.992188, validate acc = 0.987502\n",
      "378 288 344 49559\n",
      "precision = 0.567568, recall = 0.523546, f_score = 0.544669\n",
      "Loss at step 181000 : train acc = 0.984375, validate acc = 0.987542\n",
      "372 280 350 49567\n",
      "precision = 0.570552, recall = 0.515235, f_score = 0.541485\n",
      "Loss at step 182000 : train acc = 0.980469, validate acc = 0.987759\n",
      "365 262 357 49585\n",
      "precision = 0.582137, recall = 0.505540, f_score = 0.541142\n",
      "Loss at step 183000 : train acc = 0.972656, validate acc = 0.987759\n",
      "363 260 359 49587\n",
      "precision = 0.582665, recall = 0.502770, f_score = 0.539777\n",
      "Loss at step 184000 : train acc = 0.972656, validate acc = 0.987542\n",
      "374 282 348 49565\n",
      "precision = 0.570122, recall = 0.518006, f_score = 0.542816\n",
      "Loss at step 185000 : train acc = 0.972656, validate acc = 0.987581\n",
      "371 277 351 49570\n",
      "precision = 0.572531, recall = 0.513850, f_score = 0.541606\n",
      "Loss at step 186000 : train acc = 0.984375, validate acc = 0.987759\n",
      "365 262 357 49585\n",
      "precision = 0.582137, recall = 0.505540, f_score = 0.541142\n",
      "Loss at step 187000 : train acc = 0.992188, validate acc = 0.987601\n",
      "368 273 354 49574\n",
      "precision = 0.574103, recall = 0.509695, f_score = 0.539985\n",
      "Loss at step 188000 : train acc = 0.984375, validate acc = 0.987562\n",
      "374 281 348 49566\n",
      "precision = 0.570992, recall = 0.518006, f_score = 0.543210\n",
      "Loss at step 189000 : train acc = 0.976562, validate acc = 0.987680\n",
      "366 267 356 49580\n",
      "precision = 0.578199, recall = 0.506925, f_score = 0.540221\n",
      "Loss at step 190000 : train acc = 0.976562, validate acc = 0.987819\n",
      "364 258 358 49589\n",
      "precision = 0.585209, recall = 0.504155, f_score = 0.541667\n",
      "Loss at step 191000 : train acc = 0.980469, validate acc = 0.987581\n",
      "379 285 343 49562\n",
      "precision = 0.570783, recall = 0.524931, f_score = 0.546898\n",
      "Loss at step 192000 : train acc = 0.984375, validate acc = 0.987562\n",
      "375 282 347 49565\n",
      "precision = 0.570776, recall = 0.519391, f_score = 0.543872\n",
      "Loss at step 193000 : train acc = 0.972656, validate acc = 0.987680\n",
      "365 266 357 49581\n",
      "precision = 0.578447, recall = 0.505540, f_score = 0.539542\n",
      "Loss at step 194000 : train acc = 0.980469, validate acc = 0.987759\n",
      "366 263 356 49584\n",
      "precision = 0.581876, recall = 0.506925, f_score = 0.541821\n",
      "Loss at step 195000 : train acc = 0.988281, validate acc = 0.987502\n",
      "379 289 343 49558\n",
      "precision = 0.567365, recall = 0.524931, f_score = 0.545324\n",
      "Loss at step 196000 : train acc = 0.980469, validate acc = 0.987562\n",
      "374 281 348 49566\n",
      "precision = 0.570992, recall = 0.518006, f_score = 0.543210\n",
      "Loss at step 197000 : train acc = 0.976562, validate acc = 0.987720\n",
      "367 266 355 49581\n",
      "precision = 0.579779, recall = 0.508310, f_score = 0.541697\n",
      "Loss at step 198000 : train acc = 0.988281, validate acc = 0.987740\n",
      "366 264 356 49583\n",
      "precision = 0.580952, recall = 0.506925, f_score = 0.541420\n",
      "Loss at step 199000 : train acc = 0.976562, validate acc = 0.987581\n",
      "379 285 343 49562\n",
      "precision = 0.570783, recall = 0.524931, f_score = 0.546898\n",
      "Loss at step 200000 : train acc = 0.980469, validate acc = 0.987601\n",
      "373 278 349 49569\n",
      "precision = 0.572965, recall = 0.516620, f_score = 0.543336\n",
      "Loss at step 201000 : train acc = 0.976562, validate acc = 0.987720\n",
      "368 267 354 49580\n",
      "precision = 0.579528, recall = 0.509695, f_score = 0.542373\n",
      "Loss at step 202000 : train acc = 0.968750, validate acc = 0.987621\n",
      "369 273 353 49574\n",
      "precision = 0.574766, recall = 0.511080, f_score = 0.541056\n",
      "Loss at step 203000 : train acc = 0.992188, validate acc = 0.987641\n",
      "377 280 345 49567\n",
      "precision = 0.573820, recall = 0.522161, f_score = 0.546773\n",
      "Loss at step 204000 : train acc = 0.972656, validate acc = 0.987680\n",
      "369 270 353 49577\n",
      "precision = 0.577465, recall = 0.511080, f_score = 0.542248\n",
      "Loss at step 205000 : train acc = 0.980469, validate acc = 0.987779\n",
      "366 262 356 49585\n",
      "precision = 0.582803, recall = 0.506925, f_score = 0.542222\n",
      "Loss at step 206000 : train acc = 0.964844, validate acc = 0.987581\n",
      "378 284 344 49563\n",
      "precision = 0.570997, recall = 0.523546, f_score = 0.546243\n",
      "Loss at step 207000 : train acc = 0.972656, validate acc = 0.987641\n",
      "377 280 345 49567\n",
      "precision = 0.573820, recall = 0.522161, f_score = 0.546773\n",
      "Loss at step 208000 : train acc = 0.976562, validate acc = 0.987720\n",
      "368 267 354 49580\n",
      "precision = 0.579528, recall = 0.509695, f_score = 0.542373\n",
      "Loss at step 209000 : train acc = 0.984375, validate acc = 0.987700\n",
      "368 268 354 49579\n",
      "precision = 0.578616, recall = 0.509695, f_score = 0.541973\n",
      "Loss at step 210000 : train acc = 0.980469, validate acc = 0.987601\n",
      "378 283 344 49564\n",
      "precision = 0.571861, recall = 0.523546, f_score = 0.546638\n",
      "Loss at step 211000 : train acc = 0.976562, validate acc = 0.987641\n",
      "377 280 345 49567\n",
      "precision = 0.573820, recall = 0.522161, f_score = 0.546773\n",
      "Loss at step 212000 : train acc = 0.972656, validate acc = 0.987720\n",
      "368 267 354 49580\n",
      "precision = 0.579528, recall = 0.509695, f_score = 0.542373\n",
      "Loss at step 213000 : train acc = 0.992188, validate acc = 0.987700\n",
      "368 268 354 49579\n",
      "precision = 0.578616, recall = 0.509695, f_score = 0.541973\n",
      "Loss at step 214000 : train acc = 0.980469, validate acc = 0.987601\n",
      "378 283 344 49564\n",
      "precision = 0.571861, recall = 0.523546, f_score = 0.546638\n",
      "Loss at step 215000 : train acc = 0.988281, validate acc = 0.987680\n",
      "374 275 348 49572\n",
      "precision = 0.576271, recall = 0.518006, f_score = 0.545587\n",
      "Loss at step 216000 : train acc = 0.988281, validate acc = 0.987680\n",
      "368 269 354 49578\n",
      "precision = 0.577708, recall = 0.509695, f_score = 0.541575\n",
      "Loss at step 217000 : train acc = 0.992188, validate acc = 0.987700\n",
      "372 272 350 49575\n",
      "precision = 0.577640, recall = 0.515235, f_score = 0.544656\n",
      "Loss at step 218000 : train acc = 0.988281, validate acc = 0.987641\n",
      "377 280 345 49567\n",
      "precision = 0.573820, recall = 0.522161, f_score = 0.546773\n",
      "Loss at step 219000 : train acc = 0.980469, validate acc = 0.987680\n",
      "374 275 348 49572\n",
      "precision = 0.576271, recall = 0.518006, f_score = 0.545587\n",
      "Loss at step 220000 : train acc = 0.984375, validate acc = 0.987740\n",
      "368 266 354 49581\n",
      "precision = 0.580442, recall = 0.509695, f_score = 0.542773\n",
      "Loss at step 221000 : train acc = 0.972656, validate acc = 0.987601\n",
      "377 282 345 49565\n",
      "precision = 0.572079, recall = 0.522161, f_score = 0.545981\n",
      "Loss at step 222000 : train acc = 0.976562, validate acc = 0.987621\n",
      "376 280 346 49567\n",
      "precision = 0.573171, recall = 0.520776, f_score = 0.545718\n",
      "Loss at step 223000 : train acc = 0.964844, validate acc = 0.987720\n",
      "370 269 352 49578\n",
      "precision = 0.579030, recall = 0.512465, f_score = 0.543718\n",
      "Loss at step 224000 : train acc = 0.992188, validate acc = 0.987720\n",
      "372 271 350 49576\n",
      "precision = 0.578538, recall = 0.515235, f_score = 0.545055\n",
      "Loss at step 225000 : train acc = 0.992188, validate acc = 0.987601\n",
      "378 283 344 49564\n",
      "precision = 0.571861, recall = 0.523546, f_score = 0.546638\n",
      "Loss at step 226000 : train acc = 0.964844, validate acc = 0.987641\n",
      "375 278 347 49569\n",
      "precision = 0.574273, recall = 0.519391, f_score = 0.545455\n",
      "Loss at step 227000 : train acc = 0.988281, validate acc = 0.987740\n",
      "370 268 352 49579\n",
      "precision = 0.579937, recall = 0.512465, f_score = 0.544118\n",
      "Loss at step 228000 : train acc = 0.980469, validate acc = 0.987720\n",
      "372 271 350 49576\n",
      "precision = 0.578538, recall = 0.515235, f_score = 0.545055\n",
      "Loss at step 229000 : train acc = 0.992188, validate acc = 0.987601\n",
      "377 282 345 49565\n",
      "precision = 0.572079, recall = 0.522161, f_score = 0.545981\n",
      "Loss at step 230000 : train acc = 0.988281, validate acc = 0.987700\n",
      "375 275 347 49572\n",
      "precision = 0.576923, recall = 0.519391, f_score = 0.546647\n",
      "Loss at step 231000 : train acc = 0.988281, validate acc = 0.987740\n",
      "370 268 352 49579\n",
      "precision = 0.579937, recall = 0.512465, f_score = 0.544118\n",
      "Loss at step 232000 : train acc = 0.949219, validate acc = 0.987740\n",
      "374 272 348 49575\n",
      "precision = 0.578947, recall = 0.518006, f_score = 0.546784\n",
      "Loss at step 233000 : train acc = 0.957031, validate acc = 0.987601\n",
      "375 280 347 49567\n",
      "precision = 0.572519, recall = 0.519391, f_score = 0.544662\n",
      "Loss at step 234000 : train acc = 0.972656, validate acc = 0.987680\n",
      "375 276 347 49571\n",
      "precision = 0.576037, recall = 0.519391, f_score = 0.546249\n",
      "Loss at step 235000 : train acc = 0.972656, validate acc = 0.987759\n",
      "373 270 349 49577\n",
      "precision = 0.580093, recall = 0.516620, f_score = 0.546520\n",
      "Loss at step 236000 : train acc = 0.964844, validate acc = 0.987601\n",
      "376 281 346 49566\n",
      "precision = 0.572298, recall = 0.520776, f_score = 0.545323\n",
      "Loss at step 237000 : train acc = 0.980469, validate acc = 0.987621\n",
      "376 280 346 49567\n",
      "precision = 0.573171, recall = 0.520776, f_score = 0.545718\n",
      "Loss at step 238000 : train acc = 0.980469, validate acc = 0.987720\n",
      "373 272 349 49575\n",
      "precision = 0.578295, recall = 0.516620, f_score = 0.545721\n",
      "Loss at step 239000 : train acc = 0.988281, validate acc = 0.987720\n",
      "373 272 349 49575\n",
      "precision = 0.578295, recall = 0.516620, f_score = 0.545721\n",
      "Loss at step 240000 : train acc = 0.996094, validate acc = 0.987581\n",
      "377 283 345 49564\n",
      "precision = 0.571212, recall = 0.522161, f_score = 0.545586\n",
      "Loss at step 241000 : train acc = 0.980469, validate acc = 0.987621\n",
      "376 280 346 49567\n",
      "precision = 0.573171, recall = 0.520776, f_score = 0.545718\n",
      "Loss at step 242000 : train acc = 1.000000, validate acc = 0.987700\n",
      "373 273 349 49574\n",
      "precision = 0.577399, recall = 0.516620, f_score = 0.545322\n",
      "Loss at step 243000 : train acc = 0.980469, validate acc = 0.987720\n",
      "373 272 349 49575\n",
      "precision = 0.578295, recall = 0.516620, f_score = 0.545721\n",
      "Loss at step 244000 : train acc = 0.992188, validate acc = 0.987581\n",
      "377 283 345 49564\n",
      "precision = 0.571212, recall = 0.522161, f_score = 0.545586\n",
      "Loss at step 245000 : train acc = 0.968750, validate acc = 0.987680\n",
      "376 277 346 49570\n",
      "precision = 0.575804, recall = 0.520776, f_score = 0.546909\n",
      "Loss at step 246000 : train acc = 0.980469, validate acc = 0.987740\n",
      "373 271 349 49576\n",
      "precision = 0.579193, recall = 0.516620, f_score = 0.546120\n",
      "Loss at step 247000 : train acc = 0.972656, validate acc = 0.987720\n",
      "374 273 348 49574\n",
      "precision = 0.578053, recall = 0.518006, f_score = 0.546384\n",
      "Loss at step 248000 : train acc = 0.984375, validate acc = 0.987601\n",
      "376 281 346 49566\n",
      "precision = 0.572298, recall = 0.520776, f_score = 0.545323\n",
      "Loss at step 249000 : train acc = 0.996094, validate acc = 0.987660\n",
      "376 278 346 49569\n",
      "precision = 0.574924, recall = 0.520776, f_score = 0.546512\n"
     ]
    }
   ],
   "source": [
    "#train the model with stochastic gradient descent training\n",
    "batch_size = 256\n",
    "num_steps = 250000\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_label.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_data_n_resample_s[offset:(offset + batch_size), :]\n",
    "        #print(batch_data.shape)\n",
    "        batch_labels = v_train_label_resample_s[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_label : batch_labels}\n",
    "        #session.run(predicted_label, feed_dict=feed_dict)\n",
    "        _, l, _, r = session.run([predicted_label, loss, op, learning_rate], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 1000 == 0):\n",
    "            print('Loss at step %d : train acc = %f, validate acc = %f' % (step, train_acc.eval(feed_dict=feed_dict), validate_acc.eval()))\n",
    "            print(TP.eval(), FP.eval(), FN.eval(), TN.eval())\n",
    "            print(\"precision = %f, recall = %f, f_score = %f\" % (pre.eval(), rec.eval(), f_s.eval()))\n",
    "            #print('Loss at step %d: LR %f MSE %f MAE %f VALIDATE MAE %f' % (step, r, l, train_loss.eval(feed_dict=feed_dict), validate_loss.eval()))\n",
    "    #print(c_train_label_resample.reshape(-1, 1)[0:128, :])\n",
    "    #print('test1, test2, test MAE: %.3f, %.3f, %.3f' % (test_loss1.eval(), test_loss2.eval(), test_loss.eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_label_resample[0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
