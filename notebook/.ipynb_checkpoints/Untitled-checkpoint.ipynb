{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = 10, 5\n",
    "np.random.seed(0)\n",
    "y = np.random.randn(n_samples)\n",
    "X = np.random.randn(n_samples, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.511309694328974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((clf.predict(X) - y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.3524220050028379"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y.mean() - y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f41ca8e3650>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+pUBMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41caba2990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 8 7 1 3 6 0 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 8 7 1 3 6 0 2 4]\n"
     ]
    }
   ],
   "source": [
    "m = np.arange(10) * 10\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 90, 80, 70, 10, 30, 60,  0, 20, 40])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "middle_layer = [1, 2 ,3 ] \n",
    "test_list = [-1] + middle_layer + [170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "for layer in test_list:\n",
    "    print (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1:2, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn_cell, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=7, h=7)\n"
     ]
    }
   ],
   "source": [
    "lstm = rnn_cell.BasicLSTMCell(7, state_is_tuple=True)\n",
    "print(lstm.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_scale = 0.1\n",
    "input_data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5]\n",
    "target = [2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 8, 7 ,6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "n_features = 1\n",
    "n_steps = 3\n",
    "batch_size = 1\n",
    "n_labels = 1\n",
    "n_hidden = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(\"float32\", [None, n_steps, n_features])\n",
    "    labels = tf.placeholder(\"float32\", [None, n_labels])\n",
    "    \n",
    "    weights = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_features, n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_labels]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_labels]))\n",
    "    }\n",
    "    \n",
    "    def RNN(x, w, b):\n",
    "        # Prepare data shape to match `rnn` function requirements\n",
    "        # Current data input shape: (batch_size, n_steps, n_input)\n",
    "        # Required shape: 'n_steps' tensors list of shape (batch_size, n_hidden)\n",
    "    \n",
    "        # Permuting batch_size and n_steps\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshaping to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, n_features])\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "        x = tf.split(0, n_steps, x)\n",
    "\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # Linear activation, using rnn inner loop last output\n",
    "        return tf.matmul(outputs[-1], w['out']) + b['out']\n",
    "    \n",
    "    pred = RNN(inputs, weights, biases)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.square(pred - labels))\n",
    "    op = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "loss = 2.442387\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 2.437186\n",
      "loss = 1.538837\n",
      "batch_data = 3 2 1, batch_label = 2, predicate = 3.240499\n",
      "loss = 0.531516\n",
      "batch_data = 8 7 6, batch_label = 5, predicate = 5.729051\n",
      "loss = 12.640471\n",
      "batch_data = 7 8 9, batch_label = 10, predicate = 6.444656\n",
      "loss = 0.245723\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.504295\n",
      "loss = 0.167288\n",
      "batch_data = 2 1 2, batch_label = 3, predicate = 2.590992\n",
      "loss = 3.179091\n",
      "batch_data = 7 6 5, batch_label = 4, predicate = 5.783000\n",
      "loss = 1.713545\n",
      "batch_data = 8 9 10, batch_label = 9, predicate = 7.690976\n",
      "loss = 0.462336\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.320047\n",
      "loss = 0.240782\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 3.509305\n",
      "loss = 1.875621\n",
      "batch_data = 6 5 4, batch_label = 3, predicate = 4.369533\n",
      "loss = 0.002243\n",
      "batch_data = 9 10 9, batch_label = 8, predicate = 7.952637\n",
      "loss = 0.674860\n",
      "batch_data = 4 5 6, batch_label = 7, predicate = 6.178501\n",
      "loss = 0.087299\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.704536\n",
      "loss = 0.284708\n",
      "batch_data = 5 4 3, batch_label = 2, predicate = 2.533581\n",
      "loss = 0.610157\n",
      "batch_data = 10 9 8, batch_label = 7, predicate = 7.781126\n",
      "loss = 0.986337\n",
      "batch_data = 5 6 7, batch_label = 8, predicate = 7.006855\n",
      "loss = 0.145000\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.619211\n",
      "loss = 0.496849\n",
      "batch_data = 4 3 2, batch_label = 1, predicate = 1.704875\n",
      "loss = 0.778221\n",
      "batch_data = 9 8 7, batch_label = 6, predicate = 6.882168\n",
      "loss = 1.299494\n",
      "batch_data = 6 7 8, batch_label = 9, predicate = 7.860046\n",
      "loss = 0.023138\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 4.152111\n",
      "loss = 0.412477\n",
      "batch_data = 3 2 1, batch_label = 2, predicate = 1.357757\n",
      "loss = 0.070910\n",
      "batch_data = 8 7 6, batch_label = 5, predicate = 5.266289\n",
      "loss = 1.942064\n",
      "batch_data = 7 8 9, batch_label = 10, predicate = 8.606421\n",
      "loss = 0.018419\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 5.135715\n",
      "loss = 0.017770\n",
      "batch_data = 2 1 2, batch_label = 3, predicate = 2.866697\n",
      "loss = 0.023953\n",
      "batch_data = 7 6 5, batch_label = 4, predicate = 3.845232\n",
      "loss = 0.041389\n",
      "batch_data = 8 9 10, batch_label = 9, predicate = 9.203444\n",
      "loss = 0.000371\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 6.019269\n",
      "loss = 0.006106\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 3.921857\n",
      "loss = 0.013796\n",
      "batch_data = 6 5 4, batch_label = 3, predicate = 2.882543\n",
      "loss = 0.539207\n",
      "batch_data = 9 10 9, batch_label = 8, predicate = 8.734307\n",
      "loss = 0.015674\n",
      "batch_data = 4 5 6, batch_label = 7, predicate = 6.874804\n",
      "loss = 0.002366\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 5.048641\n",
      "loss = 0.034983\n",
      "batch_data = 5 4 3, batch_label = 2, predicate = 2.187038\n",
      "loss = 0.240502\n",
      "batch_data = 10 9 8, batch_label = 7, predicate = 7.490410\n",
      "loss = 0.090375\n",
      "batch_data = 5 6 7, batch_label = 8, predicate = 7.699375\n",
      "loss = 0.001730\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 6.041598\n",
      "loss = 0.438191\n",
      "batch_data = 4 3 2, batch_label = 1, predicate = 1.661960\n",
      "loss = 0.010700\n",
      "batch_data = 9 8 7, batch_label = 6, predicate = 6.103440\n",
      "loss = 0.345307\n",
      "batch_data = 6 7 8, batch_label = 9, predicate = 8.412372\n",
      "loss = 0.003831\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 3.938102\n",
      "loss = 0.080525\n",
      "batch_data = 3 2 1, batch_label = 2, predicate = 1.716231\n",
      "loss = 0.002136\n",
      "batch_data = 8 7 6, batch_label = 5, predicate = 4.953779\n",
      "loss = 1.046708\n",
      "batch_data = 7 8 9, batch_label = 10, predicate = 8.976912\n",
      "loss = 0.006884\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.917030\n",
      "loss = 0.012052\n",
      "batch_data = 2 1 2, batch_label = 3, predicate = 3.109779\n",
      "loss = 0.000323\n",
      "batch_data = 7 6 5, batch_label = 4, predicate = 4.017960\n",
      "loss = 0.181452\n",
      "batch_data = 8 9 10, batch_label = 9, predicate = 9.425972\n",
      "loss = 0.002980\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.945411\n",
      "loss = 0.000372\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 4.019285\n",
      "loss = 0.000003\n",
      "batch_data = 6 5 4, batch_label = 3, predicate = 2.998274\n",
      "loss = 0.149820\n",
      "batch_data = 9 10 9, batch_label = 8, predicate = 8.387066\n",
      "loss = 0.014028\n",
      "batch_data = 4 5 6, batch_label = 7, predicate = 7.118439\n",
      "loss = 0.001844\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.957063\n",
      "loss = 0.015355\n",
      "batch_data = 5 4 3, batch_label = 2, predicate = 1.876086\n",
      "loss = 0.005343\n",
      "batch_data = 10 9 8, batch_label = 7, predicate = 6.926905\n",
      "loss = 0.024534\n",
      "batch_data = 5 6 7, batch_label = 8, predicate = 8.156632\n",
      "loss = 0.018162\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.865233\n",
      "loss = 0.050497\n",
      "batch_data = 4 3 2, batch_label = 1, predicate = 1.224715\n",
      "loss = 0.060707\n",
      "batch_data = 9 8 7, batch_label = 6, predicate = 5.753611\n",
      "loss = 0.028154\n",
      "batch_data = 6 7 8, batch_label = 9, predicate = 8.832209\n",
      "loss = 0.000515\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 4.022703\n",
      "loss = 0.008470\n",
      "batch_data = 3 2 1, batch_label = 2, predicate = 1.907970\n",
      "loss = 0.003660\n",
      "batch_data = 8 7 6, batch_label = 5, predicate = 5.060499\n",
      "loss = 0.666244\n",
      "batch_data = 7 8 9, batch_label = 10, predicate = 9.183763\n",
      "loss = 0.000012\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.996536\n",
      "loss = 0.000363\n",
      "batch_data = 2 1 2, batch_label = 3, predicate = 2.980935\n",
      "loss = 0.004277\n",
      "batch_data = 7 6 5, batch_label = 4, predicate = 4.065400\n",
      "loss = 0.245893\n",
      "batch_data = 8 9 10, batch_label = 9, predicate = 9.495876\n",
      "loss = 0.006084\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.922000\n",
      "loss = 0.011379\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 4.106672\n",
      "loss = 0.003810\n",
      "batch_data = 6 5 4, batch_label = 3, predicate = 3.061729\n",
      "loss = 0.021131\n",
      "batch_data = 9 10 9, batch_label = 8, predicate = 7.854634\n",
      "loss = 0.006729\n",
      "batch_data = 4 5 6, batch_label = 7, predicate = 7.082032\n",
      "loss = 0.001454\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.961873\n",
      "loss = 0.012376\n",
      "batch_data = 5 4 3, batch_label = 2, predicate = 1.888754\n",
      "loss = 0.006893\n",
      "batch_data = 10 9 8, batch_label = 7, predicate = 6.916975\n",
      "loss = 0.015792\n",
      "batch_data = 5 6 7, batch_label = 8, predicate = 8.125668\n",
      "loss = 0.003517\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.940694\n",
      "loss = 0.021408\n",
      "batch_data = 4 3 2, batch_label = 1, predicate = 1.146315\n",
      "loss = 0.000001\n",
      "batch_data = 9 8 7, batch_label = 6, predicate = 5.998816\n",
      "loss = 0.002936\n",
      "batch_data = 6 7 8, batch_label = 9, predicate = 9.054182\n",
      "loss = 0.001177\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 3.965685\n",
      "loss = 0.056375\n",
      "batch_data = 3 2 1, batch_label = 2, predicate = 1.762565\n",
      "loss = 0.003610\n",
      "batch_data = 8 7 6, batch_label = 5, predicate = 5.060082\n",
      "loss = 1.179059\n",
      "batch_data = 7 8 9, batch_label = 10, predicate = 8.914155\n",
      "loss = 0.020802\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 5.144228\n",
      "loss = 0.002464\n",
      "batch_data = 2 1 2, batch_label = 3, predicate = 2.950362\n",
      "loss = 0.001469\n",
      "batch_data = 7 6 5, batch_label = 4, predicate = 4.038331\n",
      "loss = 0.120526\n",
      "batch_data = 8 9 10, batch_label = 9, predicate = 9.347168\n",
      "loss = 0.000473\n",
      "batch_data = 3 4 5, batch_label = 6, predicate = 5.978245\n",
      "loss = 0.000749\n",
      "batch_data = 1 2 3, batch_label = 4, predicate = 4.027372\n",
      "loss = 0.000768\n",
      "batch_data = 6 5 4, batch_label = 3, predicate = 3.027720\n",
      "loss = 0.016302\n",
      "batch_data = 9 10 9, batch_label = 8, predicate = 8.127680\n",
      "loss = 0.003604\n",
      "batch_data = 4 5 6, batch_label = 7, predicate = 7.060030\n",
      "loss = 0.038865\n",
      "batch_data = 2 3 4, batch_label = 5, predicate = 4.802857\n",
      "loss = 0.053232\n",
      "batch_data = 5 4 3, batch_label = 2, predicate = 1.769280\n",
      "loss = 0.024910\n",
      "batch_data = 10 9 8, batch_label = 7, predicate = 6.842171\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(steps):\n",
    "        off = step * batch_size % (24 - n_steps)\n",
    "        temp = np.array(input_data[off:off+n_steps])\n",
    "        batch_data = temp.reshape(1, 3, 1)\n",
    "        batch_label = np.array(target[off+n_steps - 1]).reshape(1, -1)\n",
    "        feed_dict = {inputs:batch_data, labels:batch_label}\n",
    "        p, l, _ = session.run([pred, loss, op], feed_dict=feed_dict)\n",
    "        if step % 100 == 0:\n",
    "            print('loss = %f' % (l))\n",
    "            print('batch_data = %d %d %d, batch_label = %d, predicate = %f' % (batch_data[0, 0, 0],batch_data[0, 1, 0],batch_data[0, 2, 0], batch_label[0, 0], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "for step in range(0, 10):\n",
    "    off = step * batch_size % (11 - n_steps)\n",
    "    temp = np.array(target[off + n_steps - 1])\n",
    "    batch = temp.reshape(1, -1)\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
