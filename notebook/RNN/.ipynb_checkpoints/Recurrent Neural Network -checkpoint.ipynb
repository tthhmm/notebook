{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn_cell, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS_time_serial.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    #train_dataset= save['train_dataset']\n",
    "    #validate_dataset = save['validate_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    #test_old = save['v_t_dataset']\n",
    "    train_old = save['t_v_dataset']\n",
    "    del save\n",
    "\n",
    "#train_time = train_dataset['time']\n",
    "#train_data = train_dataset['data']\n",
    "#train_label = train_dataset['label']\n",
    "#validate_time = validate_dataset['time']\n",
    "#validate_data = validate_dataset['data']\n",
    "#validate_label = validate_dataset['label']\n",
    "#test_time = test_dataset['time']\n",
    "test_data = test_dataset['data']\n",
    "test_label = test_dataset['label']\n",
    "#test_old_data = test_old['data']\n",
    "#test_old_label = test_old['label']\n",
    "train_old_data = train_old['data']\n",
    "train_old_label = train_old['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29993, 8, 70) (29993, 8, 1)\n",
      "(119966, 8, 70) (119966, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape, test_label.shape)\n",
    "print(train_old_data.shape, train_old_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,) (70,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_old_data.mean(axis = (0,1))\n",
    "std = train_old_data.std(axis = (0,1))\n",
    "print(mean.shape, std.shape)\n",
    "train_data_n = (train_old_data - mean)/std\n",
    "#validate_data_n = (validate_data - mean)/std\n",
    "test_data_n = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train_old_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119966\n"
     ]
    }
   ],
   "source": [
    "a = test_label[:10, 7, :].shape\n",
    "print(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 70\n",
    "n_steps = 8\n",
    "n_labels = 1\n",
    "\n",
    "n_hidden = 140\n",
    "total_size = train_old_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(\"float32\", [None, n_steps, n_features])\n",
    "    labels = tf.placeholder(\"float32\", [None, n_labels])\n",
    "    \n",
    "    weights = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_features, n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_labels]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_labels]))\n",
    "    }\n",
    "    \n",
    "    def RNN(x, w, b):\n",
    "        # Prepare data shape to match `rnn` function requirements\n",
    "        # Current data input shape: (batch_size, n_steps, n_input)\n",
    "        # Required shape: 'n_steps' tensors list of shape (batch_size, n_hidden)\n",
    "    \n",
    "        # Permuting batch_size and n_steps\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshaping to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, n_features])\n",
    "        \n",
    "        # Linear activation\n",
    "        x = tf.matmul(x, w['hidden']) + b['hidden']\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "        x = tf.split(0, n_steps, x)\n",
    "\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # Linear activation, using rnn inner loop last output\n",
    "        return tf.matmul(outputs[-1], w['out']) + b['out']\n",
    "    \n",
    "    pred = RNN(inputs, weights, biases)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.square(pred - labels))\n",
    "    \n",
    "    # Learning rate decay\n",
    "    global_step = tf.Variable(0)\n",
    "    starter_learning_rate = 0.05\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 500, 0.90, staircase=True)\n",
    "    op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "    MAE = tf.reduce_mean(tf.abs(pred - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step: 0, LR = 0.050000, min batch loss = 133.201797, test MAE = 17.025288\n",
      "step: 10, LR = 0.050000, min batch loss = 43.083408, test MAE = 4.369280\n",
      "step: 20, LR = 0.050000, min batch loss = 6.099579, test MAE = 4.059394\n",
      "step: 30, LR = 0.050000, min batch loss = 3.830898, test MAE = 3.841203\n",
      "step: 40, LR = 0.050000, min batch loss = 17.280468, test MAE = 2.880110\n",
      "step: 50, LR = 0.050000, min batch loss = 7.432853, test MAE = 3.305273\n",
      "step: 60, LR = 0.050000, min batch loss = 20.624699, test MAE = 3.409530\n",
      "step: 70, LR = 0.050000, min batch loss = 14.002827, test MAE = 2.497970\n",
      "step: 80, LR = 0.050000, min batch loss = 7.022384, test MAE = 1.988173\n",
      "step: 90, LR = 0.050000, min batch loss = 2.532738, test MAE = 1.972177\n",
      "step: 100, LR = 0.050000, min batch loss = 7.286420, test MAE = 1.769380\n",
      "step: 110, LR = 0.050000, min batch loss = 1.671923, test MAE = 1.687430\n",
      "step: 120, LR = 0.050000, min batch loss = 2.427509, test MAE = 1.655931\n",
      "step: 130, LR = 0.050000, min batch loss = 1.750825, test MAE = 1.648908\n",
      "step: 140, LR = 0.050000, min batch loss = 10.004231, test MAE = 1.687540\n",
      "step: 150, LR = 0.050000, min batch loss = 12.638037, test MAE = 2.336999\n",
      "step: 160, LR = 0.050000, min batch loss = 1.072874, test MAE = 1.820310\n",
      "step: 170, LR = 0.050000, min batch loss = 6.223264, test MAE = 1.670203\n",
      "step: 180, LR = 0.050000, min batch loss = 8.495166, test MAE = 1.624694\n",
      "step: 190, LR = 0.050000, min batch loss = 1.155510, test MAE = 1.453860\n",
      "step: 200, LR = 0.050000, min batch loss = 0.842024, test MAE = 1.332587\n",
      "step: 210, LR = 0.050000, min batch loss = 4.854005, test MAE = 1.457065\n",
      "step: 220, LR = 0.050000, min batch loss = 3.853137, test MAE = 1.368782\n",
      "step: 230, LR = 0.050000, min batch loss = 2.421920, test MAE = 1.293871\n",
      "step: 240, LR = 0.050000, min batch loss = 1.777283, test MAE = 1.258483\n",
      "step: 250, LR = 0.050000, min batch loss = 1.031759, test MAE = 1.265646\n",
      "step: 260, LR = 0.050000, min batch loss = 2.757355, test MAE = 1.495860\n",
      "step: 270, LR = 0.050000, min batch loss = 1.837847, test MAE = 1.425396\n",
      "step: 280, LR = 0.050000, min batch loss = 2.733114, test MAE = 1.365796\n",
      "step: 290, LR = 0.050000, min batch loss = 3.085131, test MAE = 1.489910\n",
      "step: 300, LR = 0.050000, min batch loss = 1.990390, test MAE = 1.338739\n",
      "step: 310, LR = 0.050000, min batch loss = 3.680686, test MAE = 1.160091\n",
      "step: 320, LR = 0.050000, min batch loss = 0.700874, test MAE = 1.133521\n",
      "step: 330, LR = 0.050000, min batch loss = 0.492413, test MAE = 1.107825\n",
      "step: 340, LR = 0.050000, min batch loss = 3.843609, test MAE = 1.146687\n",
      "step: 350, LR = 0.050000, min batch loss = 3.328455, test MAE = 1.105996\n",
      "step: 360, LR = 0.050000, min batch loss = 1.801247, test MAE = 1.230050\n",
      "step: 370, LR = 0.050000, min batch loss = 0.966530, test MAE = 1.089814\n",
      "step: 380, LR = 0.050000, min batch loss = 1.349476, test MAE = 1.163775\n",
      "step: 390, LR = 0.050000, min batch loss = 5.996591, test MAE = 1.359406\n",
      "step: 400, LR = 0.050000, min batch loss = 4.822159, test MAE = 1.177167\n",
      "step: 410, LR = 0.050000, min batch loss = 5.651960, test MAE = 1.543055\n",
      "step: 420, LR = 0.050000, min batch loss = 5.774437, test MAE = 1.775335\n",
      "step: 430, LR = 0.050000, min batch loss = 2.049449, test MAE = 1.498371\n",
      "step: 440, LR = 0.050000, min batch loss = 0.583718, test MAE = 1.169683\n",
      "step: 450, LR = 0.050000, min batch loss = 3.429087, test MAE = 1.000751\n",
      "step: 460, LR = 0.050000, min batch loss = 1.299618, test MAE = 1.015363\n",
      "step: 470, LR = 0.050000, min batch loss = 2.156169, test MAE = 0.976874\n",
      "step: 480, LR = 0.050000, min batch loss = 2.549555, test MAE = 1.017793\n",
      "step: 490, LR = 0.050000, min batch loss = 2.690986, test MAE = 1.015885\n",
      "step: 500, LR = 0.045000, min batch loss = 2.977919, test MAE = 1.231552\n",
      "step: 510, LR = 0.045000, min batch loss = 2.301035, test MAE = 1.065053\n",
      "step: 520, LR = 0.045000, min batch loss = 2.611464, test MAE = 1.108763\n",
      "step: 530, LR = 0.045000, min batch loss = 1.450805, test MAE = 1.160864\n",
      "step: 540, LR = 0.045000, min batch loss = 5.001753, test MAE = 1.215172\n",
      "step: 550, LR = 0.045000, min batch loss = 2.543978, test MAE = 1.132473\n",
      "step: 560, LR = 0.045000, min batch loss = 3.368939, test MAE = 1.027853\n",
      "step: 570, LR = 0.045000, min batch loss = 1.327100, test MAE = 0.970463\n",
      "step: 580, LR = 0.045000, min batch loss = 1.758123, test MAE = 0.966435\n",
      "step: 590, LR = 0.045000, min batch loss = 2.584672, test MAE = 0.941320\n",
      "step: 600, LR = 0.045000, min batch loss = 0.588739, test MAE = 0.960265\n",
      "step: 610, LR = 0.045000, min batch loss = 0.654140, test MAE = 0.886782\n",
      "step: 620, LR = 0.045000, min batch loss = 0.600726, test MAE = 0.891114\n",
      "step: 630, LR = 0.045000, min batch loss = 4.700028, test MAE = 0.904331\n",
      "step: 640, LR = 0.045000, min batch loss = 1.871840, test MAE = 1.037621\n",
      "step: 650, LR = 0.045000, min batch loss = 0.392044, test MAE = 0.970874\n",
      "step: 660, LR = 0.045000, min batch loss = 5.477270, test MAE = 1.099691\n",
      "step: 670, LR = 0.045000, min batch loss = 0.805698, test MAE = 0.998685\n",
      "step: 680, LR = 0.045000, min batch loss = 0.271441, test MAE = 1.058598\n",
      "step: 690, LR = 0.045000, min batch loss = 3.067662, test MAE = 0.912190\n",
      "step: 700, LR = 0.045000, min batch loss = 0.520582, test MAE = 0.936708\n",
      "step: 710, LR = 0.045000, min batch loss = 0.623785, test MAE = 0.914941\n",
      "step: 720, LR = 0.045000, min batch loss = 2.043973, test MAE = 0.963965\n",
      "step: 730, LR = 0.045000, min batch loss = 1.384564, test MAE = 0.867713\n",
      "step: 740, LR = 0.045000, min batch loss = 1.435001, test MAE = 0.867654\n",
      "step: 750, LR = 0.045000, min batch loss = 0.688259, test MAE = 0.938710\n",
      "step: 760, LR = 0.045000, min batch loss = 3.458480, test MAE = 0.882125\n",
      "step: 770, LR = 0.045000, min batch loss = 1.356556, test MAE = 0.887053\n",
      "step: 780, LR = 0.045000, min batch loss = 3.873955, test MAE = 1.302128\n",
      "step: 790, LR = 0.045000, min batch loss = 1.092526, test MAE = 1.038783\n",
      "step: 800, LR = 0.045000, min batch loss = 0.430128, test MAE = 0.854638\n",
      "step: 810, LR = 0.045000, min batch loss = 0.267153, test MAE = 0.858373\n",
      "step: 820, LR = 0.045000, min batch loss = 0.130846, test MAE = 0.892806\n",
      "step: 830, LR = 0.045000, min batch loss = 0.186442, test MAE = 0.859138\n",
      "step: 840, LR = 0.045000, min batch loss = 0.488530, test MAE = 0.872880\n",
      "step: 850, LR = 0.045000, min batch loss = 0.547726, test MAE = 0.870960\n",
      "step: 860, LR = 0.045000, min batch loss = 0.388060, test MAE = 0.896604\n",
      "step: 870, LR = 0.045000, min batch loss = 0.641012, test MAE = 0.899991\n",
      "step: 880, LR = 0.045000, min batch loss = 0.253193, test MAE = 1.005715\n",
      "step: 890, LR = 0.045000, min batch loss = 3.565778, test MAE = 0.887346\n",
      "step: 900, LR = 0.045000, min batch loss = 0.429309, test MAE = 0.899999\n",
      "step: 910, LR = 0.045000, min batch loss = 0.626960, test MAE = 0.935196\n",
      "step: 920, LR = 0.045000, min batch loss = 2.104219, test MAE = 0.965545\n",
      "step: 930, LR = 0.045000, min batch loss = 0.244717, test MAE = 0.879636\n",
      "step: 940, LR = 0.045000, min batch loss = 2.307163, test MAE = 0.853509\n",
      "step: 950, LR = 0.045000, min batch loss = 3.141594, test MAE = 0.872024\n",
      "step: 960, LR = 0.045000, min batch loss = 1.648688, test MAE = 0.935301\n",
      "step: 970, LR = 0.045000, min batch loss = 0.870903, test MAE = 0.823889\n",
      "step: 980, LR = 0.045000, min batch loss = 0.134949, test MAE = 0.834763\n",
      "step: 990, LR = 0.045000, min batch loss = 4.660851, test MAE = 1.031855\n",
      "step: 1000, LR = 0.040500, min batch loss = 1.315657, test MAE = 0.925826\n",
      "step: 1010, LR = 0.040500, min batch loss = 1.303512, test MAE = 0.883314\n",
      "step: 1020, LR = 0.040500, min batch loss = 2.810892, test MAE = 0.907200\n",
      "step: 1030, LR = 0.040500, min batch loss = 0.205021, test MAE = 0.796809\n",
      "step: 1040, LR = 0.040500, min batch loss = 0.962160, test MAE = 0.812548\n",
      "step: 1050, LR = 0.040500, min batch loss = 1.265854, test MAE = 0.817244\n",
      "step: 1060, LR = 0.040500, min batch loss = 2.060954, test MAE = 0.876724\n",
      "step: 1070, LR = 0.040500, min batch loss = 2.204363, test MAE = 0.820017\n",
      "step: 1080, LR = 0.040500, min batch loss = 0.291183, test MAE = 0.825750\n",
      "step: 1090, LR = 0.040500, min batch loss = 1.769921, test MAE = 0.876126\n",
      "step: 1100, LR = 0.040500, min batch loss = 3.362211, test MAE = 0.891029\n",
      "step: 1110, LR = 0.040500, min batch loss = 1.987611, test MAE = 0.848115\n",
      "step: 1120, LR = 0.040500, min batch loss = 1.273509, test MAE = 0.877627\n",
      "step: 1130, LR = 0.040500, min batch loss = 0.281323, test MAE = 0.886002\n",
      "step: 1140, LR = 0.040500, min batch loss = 0.657254, test MAE = 0.908969\n",
      "step: 1150, LR = 0.040500, min batch loss = 0.280917, test MAE = 0.830322\n",
      "step: 1160, LR = 0.040500, min batch loss = 1.320654, test MAE = 0.801701\n",
      "step: 1170, LR = 0.040500, min batch loss = 1.315717, test MAE = 0.819085\n",
      "step: 1180, LR = 0.040500, min batch loss = 0.150844, test MAE = 0.793739\n",
      "step: 1190, LR = 0.040500, min batch loss = 0.690879, test MAE = 0.879038\n",
      "step: 1200, LR = 0.040500, min batch loss = 1.255565, test MAE = 0.866542\n",
      "step: 1210, LR = 0.040500, min batch loss = 2.903523, test MAE = 0.794506\n",
      "step: 1220, LR = 0.040500, min batch loss = 4.063166, test MAE = 0.815909\n",
      "step: 1230, LR = 0.040500, min batch loss = 4.149484, test MAE = 0.952433\n",
      "step: 1240, LR = 0.040500, min batch loss = 0.518302, test MAE = 0.877924\n",
      "step: 1250, LR = 0.040500, min batch loss = 1.687654, test MAE = 0.801442\n",
      "step: 1260, LR = 0.040500, min batch loss = 1.486638, test MAE = 0.775150\n",
      "step: 1270, LR = 0.040500, min batch loss = 0.464099, test MAE = 0.771735\n",
      "step: 1280, LR = 0.040500, min batch loss = 0.445635, test MAE = 0.764322\n",
      "step: 1290, LR = 0.040500, min batch loss = 1.986592, test MAE = 0.890612\n",
      "step: 1300, LR = 0.040500, min batch loss = 0.368087, test MAE = 0.794217\n",
      "step: 1310, LR = 0.040500, min batch loss = 2.933753, test MAE = 0.813259\n",
      "step: 1320, LR = 0.040500, min batch loss = 5.178786, test MAE = 1.093991\n",
      "step: 1330, LR = 0.040500, min batch loss = 2.704902, test MAE = 0.971731\n",
      "step: 1340, LR = 0.040500, min batch loss = 2.415606, test MAE = 0.942813\n",
      "step: 1350, LR = 0.040500, min batch loss = 0.239863, test MAE = 0.832820\n",
      "step: 1360, LR = 0.040500, min batch loss = 1.376782, test MAE = 0.938984\n",
      "step: 1370, LR = 0.040500, min batch loss = 1.784842, test MAE = 0.881982\n",
      "step: 1380, LR = 0.040500, min batch loss = 1.144117, test MAE = 0.807645\n",
      "step: 1390, LR = 0.040500, min batch loss = 1.755131, test MAE = 0.782261\n",
      "step: 1400, LR = 0.040500, min batch loss = 5.316600, test MAE = 0.831255\n",
      "step: 1410, LR = 0.040500, min batch loss = 1.444302, test MAE = 0.786397\n",
      "step: 1420, LR = 0.040500, min batch loss = 0.440411, test MAE = 0.786430\n",
      "step: 1430, LR = 0.040500, min batch loss = 2.486354, test MAE = 0.908517\n",
      "step: 1440, LR = 0.040500, min batch loss = 0.218963, test MAE = 0.763518\n",
      "step: 1450, LR = 0.040500, min batch loss = 0.557675, test MAE = 0.790505\n",
      "step: 1460, LR = 0.040500, min batch loss = 2.002108, test MAE = 0.793029\n",
      "step: 1470, LR = 0.040500, min batch loss = 0.390126, test MAE = 0.858587\n",
      "step: 1480, LR = 0.040500, min batch loss = 2.383260, test MAE = 0.828523\n",
      "step: 1490, LR = 0.040500, min batch loss = 3.891969, test MAE = 0.789152\n",
      "step: 1500, LR = 0.036450, min batch loss = 2.301993, test MAE = 0.812273\n",
      "step: 1510, LR = 0.036450, min batch loss = 0.155632, test MAE = 0.785145\n",
      "step: 1520, LR = 0.036450, min batch loss = 0.420722, test MAE = 0.770183\n",
      "step: 1530, LR = 0.036450, min batch loss = 0.300590, test MAE = 0.801657\n",
      "step: 1540, LR = 0.036450, min batch loss = 3.069194, test MAE = 0.833677\n",
      "step: 1550, LR = 0.036450, min batch loss = 1.576038, test MAE = 0.774415\n",
      "step: 1560, LR = 0.036450, min batch loss = 0.266801, test MAE = 0.775617\n",
      "step: 1570, LR = 0.036450, min batch loss = 1.553779, test MAE = 0.813352\n",
      "step: 1580, LR = 0.036450, min batch loss = 5.157616, test MAE = 1.256645\n",
      "step: 1590, LR = 0.036450, min batch loss = 2.942152, test MAE = 1.003865\n",
      "step: 1600, LR = 0.036450, min batch loss = 1.027722, test MAE = 0.799806\n",
      "step: 1610, LR = 0.036450, min batch loss = 0.687434, test MAE = 0.809405\n",
      "step: 1620, LR = 0.036450, min batch loss = 0.923777, test MAE = 0.872483\n",
      "step: 1630, LR = 0.036450, min batch loss = 0.200290, test MAE = 0.833236\n",
      "step: 1640, LR = 0.036450, min batch loss = 2.365557, test MAE = 0.800363\n",
      "step: 1650, LR = 0.036450, min batch loss = 0.259954, test MAE = 0.760374\n",
      "step: 1660, LR = 0.036450, min batch loss = 1.577428, test MAE = 0.812259\n",
      "step: 1670, LR = 0.036450, min batch loss = 0.227803, test MAE = 0.735610\n",
      "step: 1680, LR = 0.036450, min batch loss = 0.479410, test MAE = 0.738820\n",
      "step: 1690, LR = 0.036450, min batch loss = 0.488868, test MAE = 0.777529\n",
      "step: 1700, LR = 0.036450, min batch loss = 3.682263, test MAE = 0.762646\n",
      "step: 1710, LR = 0.036450, min batch loss = 0.125664, test MAE = 0.821051\n",
      "step: 1720, LR = 0.036450, min batch loss = 0.440009, test MAE = 0.739985\n",
      "step: 1730, LR = 0.036450, min batch loss = 1.812285, test MAE = 0.753734\n",
      "step: 1740, LR = 0.036450, min batch loss = 1.821491, test MAE = 0.754314\n",
      "step: 1750, LR = 0.036450, min batch loss = 0.120260, test MAE = 0.812108\n",
      "step: 1760, LR = 0.036450, min batch loss = 3.112070, test MAE = 0.767356\n",
      "step: 1770, LR = 0.036450, min batch loss = 0.197640, test MAE = 0.751660\n",
      "step: 1780, LR = 0.036450, min batch loss = 1.566674, test MAE = 0.802693\n",
      "step: 1790, LR = 0.036450, min batch loss = 0.069664, test MAE = 0.770616\n",
      "step: 1800, LR = 0.036450, min batch loss = 0.251424, test MAE = 0.815712\n",
      "step: 1810, LR = 0.036450, min batch loss = 2.083768, test MAE = 0.801674\n",
      "step: 1820, LR = 0.036450, min batch loss = 0.287845, test MAE = 0.822175\n",
      "step: 1830, LR = 0.036450, min batch loss = 1.002440, test MAE = 0.803936\n",
      "step: 1840, LR = 0.036450, min batch loss = 3.037595, test MAE = 0.959696\n",
      "step: 1850, LR = 0.036450, min batch loss = 0.513692, test MAE = 0.863024\n",
      "step: 1860, LR = 0.036450, min batch loss = 3.602005, test MAE = 0.783003\n",
      "step: 1870, LR = 0.036450, min batch loss = 1.557432, test MAE = 0.751328\n",
      "step: 1880, LR = 0.036450, min batch loss = 0.949864, test MAE = 0.754873\n",
      "step: 1890, LR = 0.036450, min batch loss = 0.785784, test MAE = 0.748003\n",
      "step: 1900, LR = 0.036450, min batch loss = 0.106507, test MAE = 0.726154\n",
      "step: 1910, LR = 0.036450, min batch loss = 0.677426, test MAE = 0.719415\n",
      "step: 1920, LR = 0.036450, min batch loss = 0.352262, test MAE = 0.728447\n",
      "step: 1930, LR = 0.036450, min batch loss = 0.587621, test MAE = 0.804993\n",
      "step: 1940, LR = 0.036450, min batch loss = 1.010364, test MAE = 0.835500\n",
      "step: 1950, LR = 0.036450, min batch loss = 0.113488, test MAE = 0.757992\n",
      "step: 1960, LR = 0.036450, min batch loss = 1.079957, test MAE = 0.773991\n",
      "step: 1970, LR = 0.036450, min batch loss = 3.393295, test MAE = 0.716789\n",
      "step: 1980, LR = 0.036450, min batch loss = 0.068651, test MAE = 0.713131\n",
      "step: 1990, LR = 0.036450, min batch loss = 1.292359, test MAE = 0.714198\n",
      "step: 2000, LR = 0.032805, min batch loss = 0.521000, test MAE = 0.724908\n",
      "step: 2010, LR = 0.032805, min batch loss = 0.168789, test MAE = 0.724451\n",
      "step: 2020, LR = 0.032805, min batch loss = 0.994151, test MAE = 0.722407\n",
      "step: 2030, LR = 0.032805, min batch loss = 2.196393, test MAE = 0.729164\n",
      "step: 2040, LR = 0.032805, min batch loss = 3.292174, test MAE = 0.770093\n",
      "step: 2050, LR = 0.032805, min batch loss = 1.051310, test MAE = 0.845458\n",
      "step: 2060, LR = 0.032805, min batch loss = 0.833031, test MAE = 0.764824\n",
      "step: 2070, LR = 0.032805, min batch loss = 3.405877, test MAE = 0.815879\n",
      "step: 2080, LR = 0.032805, min batch loss = 0.359877, test MAE = 0.743235\n",
      "step: 2090, LR = 0.032805, min batch loss = 1.014479, test MAE = 0.740224\n",
      "step: 2100, LR = 0.032805, min batch loss = 0.324189, test MAE = 0.766488\n",
      "step: 2110, LR = 0.032805, min batch loss = 1.750926, test MAE = 0.757626\n",
      "step: 2120, LR = 0.032805, min batch loss = 0.089258, test MAE = 0.728525\n",
      "step: 2130, LR = 0.032805, min batch loss = 1.632128, test MAE = 0.806104\n",
      "step: 2140, LR = 0.032805, min batch loss = 3.333982, test MAE = 0.735670\n",
      "step: 2150, LR = 0.032805, min batch loss = 4.065240, test MAE = 0.773383\n",
      "step: 2160, LR = 0.032805, min batch loss = 2.814292, test MAE = 0.769590\n",
      "step: 2170, LR = 0.032805, min batch loss = 3.548552, test MAE = 0.830648\n",
      "step: 2180, LR = 0.032805, min batch loss = 1.785571, test MAE = 0.788032\n",
      "step: 2190, LR = 0.032805, min batch loss = 1.790330, test MAE = 0.735861\n",
      "step: 2200, LR = 0.032805, min batch loss = 1.782094, test MAE = 0.713320\n",
      "step: 2210, LR = 0.032805, min batch loss = 0.185382, test MAE = 0.713562\n",
      "step: 2220, LR = 0.032805, min batch loss = 0.129251, test MAE = 0.715352\n",
      "step: 2230, LR = 0.032805, min batch loss = 0.191827, test MAE = 0.734713\n",
      "step: 2240, LR = 0.032805, min batch loss = 0.658379, test MAE = 0.729751\n",
      "step: 2250, LR = 0.032805, min batch loss = 0.761342, test MAE = 0.739724\n",
      "step: 2260, LR = 0.032805, min batch loss = 1.822299, test MAE = 0.820012\n",
      "step: 2270, LR = 0.032805, min batch loss = 0.247303, test MAE = 0.788096\n",
      "step: 2280, LR = 0.032805, min batch loss = 2.071105, test MAE = 0.785667\n",
      "step: 2290, LR = 0.032805, min batch loss = 1.317698, test MAE = 0.819728\n",
      "step: 2300, LR = 0.032805, min batch loss = 0.819005, test MAE = 1.069572\n",
      "step: 2310, LR = 0.032805, min batch loss = 0.327488, test MAE = 0.805079\n",
      "step: 2320, LR = 0.032805, min batch loss = 2.267864, test MAE = 0.741680\n",
      "step: 2330, LR = 0.032805, min batch loss = 0.226733, test MAE = 0.719905\n",
      "step: 2340, LR = 0.032805, min batch loss = 0.126036, test MAE = 0.721128\n",
      "step: 2350, LR = 0.032805, min batch loss = 2.749392, test MAE = 0.751396\n",
      "step: 2360, LR = 0.032805, min batch loss = 0.928018, test MAE = 0.708135\n",
      "step: 2370, LR = 0.032805, min batch loss = 2.427425, test MAE = 0.720443\n",
      "step: 2380, LR = 0.032805, min batch loss = 0.384033, test MAE = 0.707741\n",
      "step: 2390, LR = 0.032805, min batch loss = 4.516149, test MAE = 0.887953\n",
      "step: 2400, LR = 0.032805, min batch loss = 1.123701, test MAE = 0.777394\n",
      "step: 2410, LR = 0.032805, min batch loss = 0.932476, test MAE = 0.777407\n",
      "step: 2420, LR = 0.032805, min batch loss = 2.305427, test MAE = 0.762966\n",
      "step: 2430, LR = 0.032805, min batch loss = 0.352905, test MAE = 0.726127\n",
      "step: 2440, LR = 0.032805, min batch loss = 0.923411, test MAE = 0.754492\n",
      "step: 2450, LR = 0.032805, min batch loss = 0.366238, test MAE = 0.725010\n",
      "step: 2460, LR = 0.032805, min batch loss = 0.161622, test MAE = 0.710082\n",
      "step: 2470, LR = 0.032805, min batch loss = 0.262053, test MAE = 0.727734\n",
      "step: 2480, LR = 0.032805, min batch loss = 0.444156, test MAE = 0.710913\n",
      "step: 2490, LR = 0.032805, min batch loss = 0.110872, test MAE = 0.715851\n",
      "step: 2500, LR = 0.029524, min batch loss = 2.242658, test MAE = 0.725513\n",
      "step: 2510, LR = 0.029524, min batch loss = 2.922428, test MAE = 0.728877\n",
      "step: 2520, LR = 0.029524, min batch loss = 0.181116, test MAE = 0.858305\n",
      "step: 2530, LR = 0.029524, min batch loss = 3.660731, test MAE = 0.757158\n",
      "step: 2540, LR = 0.029524, min batch loss = 5.270424, test MAE = 0.750405\n",
      "step: 2550, LR = 0.029524, min batch loss = 3.212164, test MAE = 0.743249\n",
      "step: 2560, LR = 0.029524, min batch loss = 3.222571, test MAE = 0.729831\n",
      "step: 2570, LR = 0.029524, min batch loss = 1.041532, test MAE = 0.729767\n",
      "step: 2580, LR = 0.029524, min batch loss = 1.094257, test MAE = 0.728712\n",
      "step: 2590, LR = 0.029524, min batch loss = 0.214847, test MAE = 0.714464\n",
      "step: 2600, LR = 0.029524, min batch loss = 1.321095, test MAE = 0.753948\n",
      "step: 2610, LR = 0.029524, min batch loss = 0.945079, test MAE = 0.709557\n",
      "step: 2620, LR = 0.029524, min batch loss = 0.218255, test MAE = 0.703812\n",
      "step: 2630, LR = 0.029524, min batch loss = 0.586628, test MAE = 0.840065\n",
      "step: 2640, LR = 0.029524, min batch loss = 1.873752, test MAE = 0.727721\n",
      "step: 2650, LR = 0.029524, min batch loss = 0.303691, test MAE = 0.746390\n",
      "step: 2660, LR = 0.029524, min batch loss = 2.145457, test MAE = 0.719214\n",
      "step: 2670, LR = 0.029524, min batch loss = 2.846590, test MAE = 0.700418\n",
      "step: 2680, LR = 0.029524, min batch loss = 0.079859, test MAE = 0.687983\n",
      "step: 2690, LR = 0.029524, min batch loss = 1.022891, test MAE = 0.704925\n",
      "step: 2700, LR = 0.029524, min batch loss = 0.064725, test MAE = 0.736871\n",
      "step: 2710, LR = 0.029524, min batch loss = 0.127137, test MAE = 0.732142\n",
      "step: 2720, LR = 0.029524, min batch loss = 0.477684, test MAE = 0.726571\n",
      "step: 2730, LR = 0.029524, min batch loss = 0.340077, test MAE = 0.718392\n",
      "step: 2740, LR = 0.029524, min batch loss = 1.544078, test MAE = 0.725884\n",
      "step: 2750, LR = 0.029524, min batch loss = 1.433516, test MAE = 0.801999\n",
      "step: 2760, LR = 0.029524, min batch loss = 0.261597, test MAE = 0.724155\n",
      "step: 2770, LR = 0.029524, min batch loss = 0.361449, test MAE = 0.722850\n",
      "step: 2780, LR = 0.029524, min batch loss = 1.310018, test MAE = 0.771141\n",
      "step: 2790, LR = 0.029524, min batch loss = 2.329136, test MAE = 0.745810\n",
      "step: 2800, LR = 0.029524, min batch loss = 0.921817, test MAE = 0.721557\n",
      "step: 2810, LR = 0.029524, min batch loss = 0.530189, test MAE = 0.714900\n",
      "step: 2820, LR = 0.029524, min batch loss = 2.138561, test MAE = 0.741550\n",
      "step: 2830, LR = 0.029524, min batch loss = 0.862954, test MAE = 0.714745\n",
      "step: 2840, LR = 0.029524, min batch loss = 1.187983, test MAE = 0.730095\n",
      "step: 2850, LR = 0.029524, min batch loss = 0.258087, test MAE = 0.733894\n",
      "step: 2860, LR = 0.029524, min batch loss = 2.532262, test MAE = 0.748141\n",
      "step: 2870, LR = 0.029524, min batch loss = 3.049275, test MAE = 0.722828\n",
      "step: 2880, LR = 0.029524, min batch loss = 3.560204, test MAE = 0.756890\n",
      "step: 2890, LR = 0.029524, min batch loss = 2.273902, test MAE = 0.720973\n",
      "step: 2900, LR = 0.029524, min batch loss = 0.265060, test MAE = 0.694128\n",
      "step: 2910, LR = 0.029524, min batch loss = 3.193174, test MAE = 0.732346\n",
      "step: 2920, LR = 0.029524, min batch loss = 0.291823, test MAE = 0.696145\n",
      "step: 2930, LR = 0.029524, min batch loss = 0.906571, test MAE = 0.677548\n",
      "step: 2940, LR = 0.029524, min batch loss = 0.695784, test MAE = 0.700155\n",
      "step: 2950, LR = 0.029524, min batch loss = 4.773760, test MAE = 0.734921\n",
      "step: 2960, LR = 0.029524, min batch loss = 1.216055, test MAE = 0.737777\n",
      "step: 2970, LR = 0.029524, min batch loss = 3.181046, test MAE = 0.703637\n",
      "step: 2980, LR = 0.029524, min batch loss = 1.637377, test MAE = 0.708953\n",
      "step: 2990, LR = 0.029524, min batch loss = 0.874239, test MAE = 0.778121\n",
      "step: 3000, LR = 0.026572, min batch loss = 1.833223, test MAE = 0.760780\n",
      "step: 3010, LR = 0.026572, min batch loss = 1.380311, test MAE = 0.744719\n",
      "step: 3020, LR = 0.026572, min batch loss = 0.373682, test MAE = 0.763675\n",
      "step: 3030, LR = 0.026572, min batch loss = 1.199770, test MAE = 0.721117\n",
      "step: 3040, LR = 0.026572, min batch loss = 0.424330, test MAE = 0.732772\n",
      "step: 3050, LR = 0.026572, min batch loss = 2.029604, test MAE = 0.697375\n",
      "step: 3060, LR = 0.026572, min batch loss = 0.927764, test MAE = 0.750618\n",
      "step: 3070, LR = 0.026572, min batch loss = 1.972858, test MAE = 0.749310\n",
      "step: 3080, LR = 0.026572, min batch loss = 3.702785, test MAE = 0.764531\n",
      "step: 3090, LR = 0.026572, min batch loss = 4.052830, test MAE = 0.757223\n",
      "step: 3100, LR = 0.026572, min batch loss = 3.931098, test MAE = 0.739960\n",
      "step: 3110, LR = 0.026572, min batch loss = 1.552954, test MAE = 0.715713\n",
      "step: 3120, LR = 0.026572, min batch loss = 0.084443, test MAE = 0.720873\n",
      "step: 3130, LR = 0.026572, min batch loss = 0.118162, test MAE = 0.684330\n",
      "step: 3140, LR = 0.026572, min batch loss = 1.454420, test MAE = 0.721178\n",
      "step: 3150, LR = 0.026572, min batch loss = 0.368315, test MAE = 0.682238\n",
      "step: 3160, LR = 0.026572, min batch loss = 2.782775, test MAE = 0.688320\n",
      "step: 3170, LR = 0.026572, min batch loss = 1.513243, test MAE = 0.713585\n",
      "step: 3180, LR = 0.026572, min batch loss = 3.742976, test MAE = 0.728182\n",
      "step: 3190, LR = 0.026572, min batch loss = 0.878077, test MAE = 0.702473\n",
      "step: 3200, LR = 0.026572, min batch loss = 2.686102, test MAE = 0.815377\n",
      "step: 3210, LR = 0.026572, min batch loss = 3.511688, test MAE = 0.744586\n",
      "step: 3220, LR = 0.026572, min batch loss = 0.348909, test MAE = 0.766592\n",
      "step: 3230, LR = 0.026572, min batch loss = 3.444632, test MAE = 0.875287\n",
      "step: 3240, LR = 0.026572, min batch loss = 0.350444, test MAE = 0.893302\n",
      "step: 3250, LR = 0.026572, min batch loss = 1.262884, test MAE = 0.747096\n",
      "step: 3260, LR = 0.026572, min batch loss = 0.162817, test MAE = 0.707294\n",
      "step: 3270, LR = 0.026572, min batch loss = 1.636534, test MAE = 0.706112\n",
      "step: 3280, LR = 0.026572, min batch loss = 0.209500, test MAE = 0.700767\n",
      "step: 3290, LR = 0.026572, min batch loss = 2.615883, test MAE = 0.700921\n",
      "step: 3300, LR = 0.026572, min batch loss = 2.596636, test MAE = 0.710685\n",
      "step: 3310, LR = 0.026572, min batch loss = 3.243789, test MAE = 0.737345\n",
      "step: 3320, LR = 0.026572, min batch loss = 2.060602, test MAE = 0.728356\n",
      "step: 3330, LR = 0.026572, min batch loss = 0.293465, test MAE = 0.741977\n",
      "step: 3340, LR = 0.026572, min batch loss = 0.224388, test MAE = 0.714369\n",
      "step: 3350, LR = 0.026572, min batch loss = 2.221795, test MAE = 0.701225\n",
      "step: 3360, LR = 0.026572, min batch loss = 0.169791, test MAE = 0.687217\n",
      "step: 3370, LR = 0.026572, min batch loss = 2.406129, test MAE = 0.706916\n",
      "step: 3380, LR = 0.026572, min batch loss = 1.366738, test MAE = 0.702811\n",
      "step: 3390, LR = 0.026572, min batch loss = 1.579459, test MAE = 0.701033\n",
      "step: 3400, LR = 0.026572, min batch loss = 2.231136, test MAE = 0.696273\n",
      "step: 3410, LR = 0.026572, min batch loss = 1.007144, test MAE = 0.688027\n",
      "step: 3420, LR = 0.026572, min batch loss = 0.329716, test MAE = 0.682265\n",
      "step: 3430, LR = 0.026572, min batch loss = 0.076227, test MAE = 0.693192\n",
      "step: 3440, LR = 0.026572, min batch loss = 1.179245, test MAE = 0.750494\n",
      "step: 3450, LR = 0.026572, min batch loss = 1.666032, test MAE = 0.725610\n",
      "step: 3460, LR = 0.026572, min batch loss = 1.374412, test MAE = 0.688807\n",
      "step: 3470, LR = 0.026572, min batch loss = 1.590674, test MAE = 0.693797\n",
      "step: 3480, LR = 0.026572, min batch loss = 5.459708, test MAE = 0.728229\n",
      "step: 3490, LR = 0.026572, min batch loss = 0.699686, test MAE = 0.733031\n",
      "step: 3500, LR = 0.023915, min batch loss = 3.767271, test MAE = 0.729880\n",
      "step: 3510, LR = 0.023915, min batch loss = 0.953982, test MAE = 0.709387\n",
      "step: 3520, LR = 0.023915, min batch loss = 0.670906, test MAE = 0.692107\n",
      "step: 3530, LR = 0.023915, min batch loss = 0.181198, test MAE = 0.686694\n",
      "step: 3540, LR = 0.023915, min batch loss = 2.284248, test MAE = 0.679446\n",
      "step: 3550, LR = 0.023915, min batch loss = 0.293134, test MAE = 0.679708\n",
      "step: 3560, LR = 0.023915, min batch loss = 0.232987, test MAE = 0.680451\n",
      "step: 3570, LR = 0.023915, min batch loss = 0.342077, test MAE = 0.748367\n",
      "step: 3580, LR = 0.023915, min batch loss = 1.641065, test MAE = 0.690405\n",
      "step: 3590, LR = 0.023915, min batch loss = 1.330622, test MAE = 0.772520\n",
      "step: 3600, LR = 0.023915, min batch loss = 1.759665, test MAE = 0.696341\n",
      "step: 3610, LR = 0.023915, min batch loss = 1.471485, test MAE = 0.667389\n",
      "step: 3620, LR = 0.023915, min batch loss = 2.409645, test MAE = 0.702351\n",
      "step: 3630, LR = 0.023915, min batch loss = 0.619934, test MAE = 0.689671\n",
      "step: 3640, LR = 0.023915, min batch loss = 0.060023, test MAE = 0.677022\n",
      "step: 3650, LR = 0.023915, min batch loss = 0.398896, test MAE = 0.696372\n",
      "step: 3660, LR = 0.023915, min batch loss = 0.138867, test MAE = 0.689906\n",
      "step: 3670, LR = 0.023915, min batch loss = 0.136499, test MAE = 0.687340\n",
      "step: 3680, LR = 0.023915, min batch loss = 0.118863, test MAE = 0.669312\n",
      "step: 3690, LR = 0.023915, min batch loss = 0.075763, test MAE = 0.695490\n",
      "step: 3700, LR = 0.023915, min batch loss = 1.114666, test MAE = 0.700952\n",
      "step: 3710, LR = 0.023915, min batch loss = 0.190898, test MAE = 0.732984\n",
      "step: 3720, LR = 0.023915, min batch loss = 0.077991, test MAE = 0.736246\n",
      "step: 3730, LR = 0.023915, min batch loss = 1.098661, test MAE = 0.716654\n",
      "step: 3740, LR = 0.023915, min batch loss = 0.137500, test MAE = 0.698832\n",
      "step: 3750, LR = 0.023915, min batch loss = 0.252797, test MAE = 0.716420\n",
      "step: 3760, LR = 0.023915, min batch loss = 0.292016, test MAE = 0.679372\n",
      "step: 3770, LR = 0.023915, min batch loss = 0.407387, test MAE = 0.665377\n",
      "step: 3780, LR = 0.023915, min batch loss = 0.355064, test MAE = 0.663565\n",
      "step: 3790, LR = 0.023915, min batch loss = 1.055543, test MAE = 0.662410\n",
      "step: 3800, LR = 0.023915, min batch loss = 1.100936, test MAE = 0.712251\n",
      "step: 3810, LR = 0.023915, min batch loss = 0.922816, test MAE = 0.716121\n",
      "step: 3820, LR = 0.023915, min batch loss = 1.826638, test MAE = 0.711909\n",
      "step: 3830, LR = 0.023915, min batch loss = 1.009546, test MAE = 0.709597\n",
      "step: 3840, LR = 0.023915, min batch loss = 0.073680, test MAE = 0.671944\n",
      "step: 3850, LR = 0.023915, min batch loss = 0.140637, test MAE = 0.671830\n",
      "step: 3860, LR = 0.023915, min batch loss = 0.921466, test MAE = 0.659001\n",
      "step: 3870, LR = 0.023915, min batch loss = 3.929527, test MAE = 0.682319\n",
      "step: 3880, LR = 0.023915, min batch loss = 0.408479, test MAE = 0.715823\n",
      "step: 3890, LR = 0.023915, min batch loss = 0.352745, test MAE = 0.685114\n",
      "step: 3900, LR = 0.023915, min batch loss = 0.928160, test MAE = 0.696743\n",
      "step: 3910, LR = 0.023915, min batch loss = 3.685882, test MAE = 0.671716\n",
      "step: 3920, LR = 0.023915, min batch loss = 2.396976, test MAE = 0.736382\n",
      "step: 3930, LR = 0.023915, min batch loss = 1.599601, test MAE = 0.681493\n",
      "step: 3940, LR = 0.023915, min batch loss = 2.310658, test MAE = 0.719717\n",
      "step: 3950, LR = 0.023915, min batch loss = 1.121911, test MAE = 0.755633\n",
      "step: 3960, LR = 0.023915, min batch loss = 0.551984, test MAE = 0.693495\n",
      "step: 3970, LR = 0.023915, min batch loss = 5.390320, test MAE = 0.707398\n",
      "step: 3980, LR = 0.023915, min batch loss = 0.569844, test MAE = 0.691092\n",
      "step: 3990, LR = 0.023915, min batch loss = 2.932708, test MAE = 0.710722\n",
      "step: 4000, LR = 0.021523, min batch loss = 1.732177, test MAE = 0.686422\n",
      "step: 4010, LR = 0.021523, min batch loss = 1.463820, test MAE = 0.724519\n",
      "step: 4020, LR = 0.021523, min batch loss = 2.033073, test MAE = 0.678863\n",
      "step: 4030, LR = 0.021523, min batch loss = 5.120425, test MAE = 0.718136\n",
      "step: 4040, LR = 0.021523, min batch loss = 0.722729, test MAE = 0.685309\n",
      "step: 4050, LR = 0.021523, min batch loss = 1.207807, test MAE = 0.685755\n",
      "step: 4060, LR = 0.021523, min batch loss = 2.216218, test MAE = 0.667606\n",
      "step: 4070, LR = 0.021523, min batch loss = 0.147629, test MAE = 0.661407\n",
      "step: 4080, LR = 0.021523, min batch loss = 0.155797, test MAE = 0.658270\n",
      "step: 4090, LR = 0.021523, min batch loss = 1.413592, test MAE = 0.668816\n",
      "step: 4100, LR = 0.021523, min batch loss = 1.143982, test MAE = 0.699748\n",
      "step: 4110, LR = 0.021523, min batch loss = 0.421622, test MAE = 0.681122\n",
      "step: 4120, LR = 0.021523, min batch loss = 1.185633, test MAE = 0.704719\n",
      "step: 4130, LR = 0.021523, min batch loss = 1.573875, test MAE = 0.765738\n",
      "step: 4140, LR = 0.021523, min batch loss = 2.156646, test MAE = 0.676032\n",
      "step: 4150, LR = 0.021523, min batch loss = 1.627373, test MAE = 0.739594\n",
      "step: 4160, LR = 0.021523, min batch loss = 1.324929, test MAE = 0.721711\n",
      "step: 4170, LR = 0.021523, min batch loss = 0.721060, test MAE = 0.769152\n",
      "step: 4180, LR = 0.021523, min batch loss = 1.332776, test MAE = 0.736747\n",
      "step: 4190, LR = 0.021523, min batch loss = 2.423469, test MAE = 0.698278\n",
      "step: 4200, LR = 0.021523, min batch loss = 0.051938, test MAE = 0.677643\n",
      "step: 4210, LR = 0.021523, min batch loss = 0.202576, test MAE = 0.689427\n",
      "step: 4220, LR = 0.021523, min batch loss = 2.031866, test MAE = 0.671223\n",
      "step: 4230, LR = 0.021523, min batch loss = 1.592565, test MAE = 0.661506\n",
      "step: 4240, LR = 0.021523, min batch loss = 0.804417, test MAE = 0.708365\n",
      "step: 4250, LR = 0.021523, min batch loss = 0.772106, test MAE = 0.666228\n",
      "step: 4260, LR = 0.021523, min batch loss = 0.337963, test MAE = 0.693851\n",
      "step: 4270, LR = 0.021523, min batch loss = 3.226072, test MAE = 0.671428\n",
      "step: 4280, LR = 0.021523, min batch loss = 0.649655, test MAE = 0.682638\n",
      "step: 4290, LR = 0.021523, min batch loss = 1.990831, test MAE = 0.679296\n",
      "step: 4300, LR = 0.021523, min batch loss = 2.838838, test MAE = 0.679501\n",
      "step: 4310, LR = 0.021523, min batch loss = 0.092346, test MAE = 0.671321\n",
      "step: 4320, LR = 0.021523, min batch loss = 1.826318, test MAE = 0.659371\n",
      "step: 4330, LR = 0.021523, min batch loss = 2.662664, test MAE = 0.704699\n",
      "step: 4340, LR = 0.021523, min batch loss = 1.263814, test MAE = 0.673759\n",
      "step: 4350, LR = 0.021523, min batch loss = 0.222838, test MAE = 0.680482\n",
      "step: 4360, LR = 0.021523, min batch loss = 0.092622, test MAE = 0.670208\n",
      "step: 4370, LR = 0.021523, min batch loss = 0.128858, test MAE = 0.668579\n",
      "step: 4380, LR = 0.021523, min batch loss = 0.485501, test MAE = 0.678211\n",
      "step: 4390, LR = 0.021523, min batch loss = 1.894757, test MAE = 0.724410\n",
      "step: 4400, LR = 0.021523, min batch loss = 3.328027, test MAE = 0.731016\n",
      "step: 4410, LR = 0.021523, min batch loss = 0.231330, test MAE = 0.678761\n",
      "step: 4420, LR = 0.021523, min batch loss = 0.722644, test MAE = 0.695581\n",
      "step: 4430, LR = 0.021523, min batch loss = 0.408637, test MAE = 0.731082\n",
      "step: 4440, LR = 0.021523, min batch loss = 0.566862, test MAE = 0.697934\n",
      "step: 4450, LR = 0.021523, min batch loss = 0.410465, test MAE = 0.691806\n",
      "step: 4460, LR = 0.021523, min batch loss = 2.390325, test MAE = 0.705480\n",
      "step: 4470, LR = 0.021523, min batch loss = 0.043741, test MAE = 0.688982\n",
      "step: 4480, LR = 0.021523, min batch loss = 0.089023, test MAE = 0.670416\n",
      "step: 4490, LR = 0.021523, min batch loss = 0.270261, test MAE = 0.657897\n",
      "step: 4500, LR = 0.019371, min batch loss = 1.990760, test MAE = 0.762617\n",
      "step: 4510, LR = 0.019371, min batch loss = 1.502209, test MAE = 0.700845\n",
      "step: 4520, LR = 0.019371, min batch loss = 0.304614, test MAE = 0.676699\n",
      "step: 4530, LR = 0.019371, min batch loss = 0.402379, test MAE = 0.672566\n",
      "step: 4540, LR = 0.019371, min batch loss = 2.456654, test MAE = 0.665566\n",
      "step: 4550, LR = 0.019371, min batch loss = 0.302043, test MAE = 0.656470\n",
      "step: 4560, LR = 0.019371, min batch loss = 0.093678, test MAE = 0.662312\n",
      "step: 4570, LR = 0.019371, min batch loss = 1.438814, test MAE = 0.676150\n",
      "step: 4580, LR = 0.019371, min batch loss = 0.651850, test MAE = 0.676677\n",
      "step: 4590, LR = 0.019371, min batch loss = 0.177280, test MAE = 0.697930\n",
      "step: 4600, LR = 0.019371, min batch loss = 0.521734, test MAE = 0.683154\n",
      "step: 4610, LR = 0.019371, min batch loss = 2.148785, test MAE = 0.789589\n",
      "step: 4620, LR = 0.019371, min batch loss = 1.552535, test MAE = 0.679257\n",
      "step: 4630, LR = 0.019371, min batch loss = 3.676747, test MAE = 0.696256\n",
      "step: 4640, LR = 0.019371, min batch loss = 2.459023, test MAE = 0.732303\n",
      "step: 4650, LR = 0.019371, min batch loss = 2.971456, test MAE = 0.730726\n",
      "step: 4660, LR = 0.019371, min batch loss = 1.445817, test MAE = 0.666693\n",
      "step: 4670, LR = 0.019371, min batch loss = 0.719693, test MAE = 0.690861\n",
      "step: 4680, LR = 0.019371, min batch loss = 1.822198, test MAE = 0.663589\n",
      "step: 4690, LR = 0.019371, min batch loss = 0.741677, test MAE = 0.671903\n",
      "step: 4700, LR = 0.019371, min batch loss = 0.847736, test MAE = 0.703531\n",
      "step: 4710, LR = 0.019371, min batch loss = 0.100093, test MAE = 0.656883\n",
      "step: 4720, LR = 0.019371, min batch loss = 0.361689, test MAE = 0.669304\n",
      "step: 4730, LR = 0.019371, min batch loss = 1.297864, test MAE = 0.664108\n",
      "step: 4740, LR = 0.019371, min batch loss = 3.246136, test MAE = 0.701346\n",
      "step: 4750, LR = 0.019371, min batch loss = 0.223428, test MAE = 0.690280\n",
      "step: 4760, LR = 0.019371, min batch loss = 1.631581, test MAE = 0.673366\n",
      "step: 4770, LR = 0.019371, min batch loss = 1.324281, test MAE = 0.665125\n",
      "step: 4780, LR = 0.019371, min batch loss = 0.119831, test MAE = 0.665384\n",
      "step: 4790, LR = 0.019371, min batch loss = 0.454617, test MAE = 0.655418\n",
      "step: 4800, LR = 0.019371, min batch loss = 0.116092, test MAE = 0.649099\n",
      "step: 4810, LR = 0.019371, min batch loss = 0.123184, test MAE = 0.673637\n",
      "step: 4820, LR = 0.019371, min batch loss = 0.158849, test MAE = 0.657926\n",
      "step: 4830, LR = 0.019371, min batch loss = 4.479274, test MAE = 0.676454\n",
      "step: 4840, LR = 0.019371, min batch loss = 2.562922, test MAE = 0.676507\n",
      "step: 4850, LR = 0.019371, min batch loss = 3.078096, test MAE = 0.673398\n",
      "step: 4860, LR = 0.019371, min batch loss = 2.705721, test MAE = 0.688530\n",
      "step: 4870, LR = 0.019371, min batch loss = 0.172497, test MAE = 0.685188\n",
      "step: 4880, LR = 0.019371, min batch loss = 0.768981, test MAE = 0.697096\n",
      "step: 4890, LR = 0.019371, min batch loss = 0.199724, test MAE = 0.686042\n",
      "step: 4900, LR = 0.019371, min batch loss = 0.145984, test MAE = 0.671628\n",
      "step: 4910, LR = 0.019371, min batch loss = 1.058815, test MAE = 0.681694\n",
      "step: 4920, LR = 0.019371, min batch loss = 0.124704, test MAE = 0.675139\n",
      "step: 4930, LR = 0.019371, min batch loss = 0.084920, test MAE = 0.668976\n",
      "step: 4940, LR = 0.019371, min batch loss = 2.325663, test MAE = 0.683632\n",
      "step: 4950, LR = 0.019371, min batch loss = 1.597287, test MAE = 0.671816\n",
      "step: 4960, LR = 0.019371, min batch loss = 1.826573, test MAE = 0.680627\n",
      "step: 4970, LR = 0.019371, min batch loss = 0.519857, test MAE = 0.660932\n",
      "step: 4980, LR = 0.019371, min batch loss = 0.712810, test MAE = 0.671062\n",
      "step: 4990, LR = 0.019371, min batch loss = 0.572331, test MAE = 0.678265\n",
      "step: 5000, LR = 0.017434, min batch loss = 0.802357, test MAE = 0.659416\n",
      "step: 5010, LR = 0.017434, min batch loss = 0.462055, test MAE = 0.660137\n",
      "step: 5020, LR = 0.017434, min batch loss = 0.119573, test MAE = 0.650468\n",
      "step: 5030, LR = 0.017434, min batch loss = 3.993774, test MAE = 0.652980\n",
      "step: 5040, LR = 0.017434, min batch loss = 0.778939, test MAE = 0.674844\n",
      "step: 5050, LR = 0.017434, min batch loss = 0.230457, test MAE = 0.681097\n",
      "step: 5060, LR = 0.017434, min batch loss = 0.083008, test MAE = 0.678875\n",
      "step: 5070, LR = 0.017434, min batch loss = 1.818717, test MAE = 0.720103\n",
      "step: 5080, LR = 0.017434, min batch loss = 0.843578, test MAE = 0.693018\n",
      "step: 5090, LR = 0.017434, min batch loss = 0.285191, test MAE = 0.681456\n",
      "step: 5100, LR = 0.017434, min batch loss = 0.425074, test MAE = 0.704713\n",
      "step: 5110, LR = 0.017434, min batch loss = 0.122677, test MAE = 0.808747\n",
      "step: 5120, LR = 0.017434, min batch loss = 2.620691, test MAE = 0.706459\n",
      "step: 5130, LR = 0.017434, min batch loss = 0.585599, test MAE = 0.664107\n",
      "step: 5140, LR = 0.017434, min batch loss = 0.953642, test MAE = 0.665364\n",
      "step: 5150, LR = 0.017434, min batch loss = 0.158719, test MAE = 0.654069\n",
      "step: 5160, LR = 0.017434, min batch loss = 1.010407, test MAE = 0.661339\n",
      "step: 5170, LR = 0.017434, min batch loss = 1.491980, test MAE = 0.646859\n",
      "step: 5180, LR = 0.017434, min batch loss = 0.592236, test MAE = 0.655409\n",
      "step: 5190, LR = 0.017434, min batch loss = 1.051049, test MAE = 0.651988\n",
      "step: 5200, LR = 0.017434, min batch loss = 0.887875, test MAE = 0.713340\n",
      "step: 5210, LR = 0.017434, min batch loss = 1.889811, test MAE = 0.675532\n",
      "step: 5220, LR = 0.017434, min batch loss = 1.001955, test MAE = 0.661226\n",
      "step: 5230, LR = 0.017434, min batch loss = 0.193626, test MAE = 0.662380\n",
      "step: 5240, LR = 0.017434, min batch loss = 0.576036, test MAE = 0.662172\n",
      "step: 5250, LR = 0.017434, min batch loss = 0.052470, test MAE = 0.662945\n",
      "step: 5260, LR = 0.017434, min batch loss = 1.353252, test MAE = 0.662055\n",
      "step: 5270, LR = 0.017434, min batch loss = 2.431959, test MAE = 0.666125\n",
      "step: 5280, LR = 0.017434, min batch loss = 1.163357, test MAE = 0.663210\n",
      "step: 5290, LR = 0.017434, min batch loss = 0.036449, test MAE = 0.656743\n",
      "step: 5300, LR = 0.017434, min batch loss = 0.292186, test MAE = 0.654827\n",
      "step: 5310, LR = 0.017434, min batch loss = 0.739114, test MAE = 0.684040\n",
      "step: 5320, LR = 0.017434, min batch loss = 0.129325, test MAE = 0.654199\n",
      "step: 5330, LR = 0.017434, min batch loss = 3.573898, test MAE = 0.688942\n",
      "step: 5340, LR = 0.017434, min batch loss = 1.139622, test MAE = 0.654509\n",
      "step: 5350, LR = 0.017434, min batch loss = 1.847867, test MAE = 0.655762\n",
      "step: 5360, LR = 0.017434, min batch loss = 4.348368, test MAE = 0.718789\n",
      "step: 5370, LR = 0.017434, min batch loss = 2.213895, test MAE = 0.659158\n",
      "step: 5380, LR = 0.017434, min batch loss = 2.732949, test MAE = 0.676695\n",
      "step: 5390, LR = 0.017434, min batch loss = 2.112650, test MAE = 0.657453\n",
      "step: 5400, LR = 0.017434, min batch loss = 0.087407, test MAE = 0.652321\n",
      "step: 5410, LR = 0.017434, min batch loss = 1.126283, test MAE = 0.652537\n",
      "step: 5420, LR = 0.017434, min batch loss = 0.140725, test MAE = 0.647439\n",
      "step: 5430, LR = 0.017434, min batch loss = 0.812875, test MAE = 0.651029\n",
      "step: 5440, LR = 0.017434, min batch loss = 1.636451, test MAE = 0.712751\n",
      "step: 5450, LR = 0.017434, min batch loss = 0.180528, test MAE = 0.674579\n",
      "step: 5460, LR = 0.017434, min batch loss = 1.206154, test MAE = 0.687017\n",
      "step: 5470, LR = 0.017434, min batch loss = 0.879624, test MAE = 0.681693\n",
      "step: 5480, LR = 0.017434, min batch loss = 1.678995, test MAE = 0.644322\n",
      "step: 5490, LR = 0.017434, min batch loss = 1.396107, test MAE = 0.643269\n",
      "step: 5500, LR = 0.015691, min batch loss = 0.673988, test MAE = 0.652092\n",
      "step: 5510, LR = 0.015691, min batch loss = 0.047209, test MAE = 0.656770\n",
      "step: 5520, LR = 0.015691, min batch loss = 0.060450, test MAE = 0.657425\n",
      "step: 5530, LR = 0.015691, min batch loss = 0.346682, test MAE = 0.661397\n",
      "step: 5540, LR = 0.015691, min batch loss = 0.126320, test MAE = 0.656331\n",
      "step: 5550, LR = 0.015691, min batch loss = 2.220967, test MAE = 0.656321\n",
      "step: 5560, LR = 0.015691, min batch loss = 0.591088, test MAE = 0.657157\n",
      "step: 5570, LR = 0.015691, min batch loss = 1.408408, test MAE = 0.660664\n",
      "step: 5580, LR = 0.015691, min batch loss = 2.340818, test MAE = 0.692563\n",
      "step: 5590, LR = 0.015691, min batch loss = 2.440665, test MAE = 0.671482\n",
      "step: 5600, LR = 0.015691, min batch loss = 0.111055, test MAE = 0.667264\n",
      "step: 5610, LR = 0.015691, min batch loss = 0.075090, test MAE = 0.659036\n",
      "step: 5620, LR = 0.015691, min batch loss = 0.036981, test MAE = 0.645437\n",
      "step: 5630, LR = 0.015691, min batch loss = 0.097737, test MAE = 0.661232\n",
      "step: 5640, LR = 0.015691, min batch loss = 1.696481, test MAE = 0.661886\n",
      "step: 5650, LR = 0.015691, min batch loss = 0.817890, test MAE = 0.657088\n",
      "step: 5660, LR = 0.015691, min batch loss = 1.377059, test MAE = 0.653596\n",
      "step: 5670, LR = 0.015691, min batch loss = 0.973819, test MAE = 0.684014\n",
      "step: 5680, LR = 0.015691, min batch loss = 1.498402, test MAE = 0.669450\n",
      "step: 5690, LR = 0.015691, min batch loss = 0.088851, test MAE = 0.660879\n",
      "step: 5700, LR = 0.015691, min batch loss = 0.097760, test MAE = 0.659324\n",
      "step: 5710, LR = 0.015691, min batch loss = 1.649589, test MAE = 0.646505\n",
      "step: 5720, LR = 0.015691, min batch loss = 0.962570, test MAE = 0.646069\n",
      "step: 5730, LR = 0.015691, min batch loss = 0.615589, test MAE = 0.642654\n",
      "step: 5740, LR = 0.015691, min batch loss = 1.016773, test MAE = 0.651325\n",
      "step: 5750, LR = 0.015691, min batch loss = 0.194921, test MAE = 0.661182\n",
      "step: 5760, LR = 0.015691, min batch loss = 1.294819, test MAE = 0.666651\n",
      "step: 5770, LR = 0.015691, min batch loss = 0.195248, test MAE = 0.664172\n",
      "step: 5780, LR = 0.015691, min batch loss = 0.159173, test MAE = 0.654869\n",
      "step: 5790, LR = 0.015691, min batch loss = 0.046059, test MAE = 0.649897\n",
      "step: 5800, LR = 0.015691, min batch loss = 0.082433, test MAE = 0.670911\n",
      "step: 5810, LR = 0.015691, min batch loss = 0.628357, test MAE = 0.679272\n",
      "step: 5820, LR = 0.015691, min batch loss = 0.309182, test MAE = 0.704334\n",
      "step: 5830, LR = 0.015691, min batch loss = 0.885795, test MAE = 0.689704\n",
      "step: 5840, LR = 0.015691, min batch loss = 1.455069, test MAE = 0.690871\n",
      "step: 5850, LR = 0.015691, min batch loss = 0.065112, test MAE = 0.678993\n",
      "step: 5860, LR = 0.015691, min batch loss = 1.798439, test MAE = 0.664504\n",
      "step: 5870, LR = 0.015691, min batch loss = 0.720059, test MAE = 0.679740\n",
      "step: 5880, LR = 0.015691, min batch loss = 2.734983, test MAE = 0.688566\n",
      "step: 5890, LR = 0.015691, min batch loss = 1.716172, test MAE = 0.658198\n",
      "step: 5900, LR = 0.015691, min batch loss = 3.623602, test MAE = 0.675269\n",
      "step: 5910, LR = 0.015691, min batch loss = 0.560908, test MAE = 0.663071\n",
      "step: 5920, LR = 0.015691, min batch loss = 1.579559, test MAE = 0.666227\n",
      "step: 5930, LR = 0.015691, min batch loss = 1.507360, test MAE = 0.660772\n",
      "step: 5940, LR = 0.015691, min batch loss = 0.115560, test MAE = 0.649898\n",
      "step: 5950, LR = 0.015691, min batch loss = 1.333299, test MAE = 0.657914\n",
      "step: 5960, LR = 0.015691, min batch loss = 1.119102, test MAE = 0.644028\n",
      "step: 5970, LR = 0.015691, min batch loss = 0.363223, test MAE = 0.663474\n",
      "step: 5980, LR = 0.015691, min batch loss = 0.807195, test MAE = 0.670383\n",
      "step: 5990, LR = 0.015691, min batch loss = 1.861382, test MAE = 0.702859\n",
      "step: 6000, LR = 0.014121, min batch loss = 1.353164, test MAE = 0.683016\n",
      "step: 6010, LR = 0.014121, min batch loss = 4.585915, test MAE = 0.775226\n",
      "step: 6020, LR = 0.014121, min batch loss = 3.517006, test MAE = 0.699936\n",
      "step: 6030, LR = 0.014121, min batch loss = 0.723643, test MAE = 0.688886\n",
      "step: 6040, LR = 0.014121, min batch loss = 0.287639, test MAE = 0.764577\n",
      "step: 6050, LR = 0.014121, min batch loss = 0.849180, test MAE = 0.723109\n",
      "step: 6060, LR = 0.014121, min batch loss = 0.069572, test MAE = 0.690243\n",
      "step: 6070, LR = 0.014121, min batch loss = 3.008162, test MAE = 0.665085\n",
      "step: 6080, LR = 0.014121, min batch loss = 2.007737, test MAE = 0.674433\n",
      "step: 6090, LR = 0.014121, min batch loss = 0.132126, test MAE = 0.651173\n",
      "step: 6100, LR = 0.014121, min batch loss = 2.525480, test MAE = 0.655102\n",
      "step: 6110, LR = 0.014121, min batch loss = 0.306048, test MAE = 0.659103\n",
      "step: 6120, LR = 0.014121, min batch loss = 0.148908, test MAE = 0.667295\n",
      "step: 6130, LR = 0.014121, min batch loss = 1.169484, test MAE = 0.681846\n",
      "step: 6140, LR = 0.014121, min batch loss = 1.128702, test MAE = 0.700913\n",
      "step: 6150, LR = 0.014121, min batch loss = 1.560328, test MAE = 0.674781\n",
      "step: 6160, LR = 0.014121, min batch loss = 0.324982, test MAE = 0.644696\n",
      "step: 6170, LR = 0.014121, min batch loss = 1.006653, test MAE = 0.646632\n",
      "step: 6180, LR = 0.014121, min batch loss = 0.150541, test MAE = 0.649360\n",
      "step: 6190, LR = 0.014121, min batch loss = 0.190329, test MAE = 0.650048\n",
      "step: 6200, LR = 0.014121, min batch loss = 1.618006, test MAE = 0.649275\n",
      "step: 6210, LR = 0.014121, min batch loss = 0.645026, test MAE = 0.651014\n",
      "step: 6220, LR = 0.014121, min batch loss = 0.181057, test MAE = 0.652029\n",
      "step: 6230, LR = 0.014121, min batch loss = 0.550396, test MAE = 0.649133\n",
      "step: 6240, LR = 0.014121, min batch loss = 1.318941, test MAE = 0.652287\n",
      "step: 6250, LR = 0.014121, min batch loss = 1.768418, test MAE = 0.664551\n",
      "step: 6260, LR = 0.014121, min batch loss = 1.638194, test MAE = 0.650372\n",
      "step: 6270, LR = 0.014121, min batch loss = 0.799439, test MAE = 0.662405\n",
      "step: 6280, LR = 0.014121, min batch loss = 0.148229, test MAE = 0.643528\n",
      "step: 6290, LR = 0.014121, min batch loss = 1.361099, test MAE = 0.657716\n",
      "step: 6300, LR = 0.014121, min batch loss = 0.616835, test MAE = 0.700402\n",
      "step: 6310, LR = 0.014121, min batch loss = 0.228367, test MAE = 0.673694\n",
      "step: 6320, LR = 0.014121, min batch loss = 3.336483, test MAE = 0.668583\n",
      "step: 6330, LR = 0.014121, min batch loss = 0.305388, test MAE = 0.657315\n",
      "step: 6340, LR = 0.014121, min batch loss = 0.107221, test MAE = 0.653740\n",
      "step: 6350, LR = 0.014121, min batch loss = 0.622460, test MAE = 0.651945\n",
      "step: 6360, LR = 0.014121, min batch loss = 0.224937, test MAE = 0.652220\n",
      "step: 6370, LR = 0.014121, min batch loss = 0.118200, test MAE = 0.650213\n",
      "step: 6380, LR = 0.014121, min batch loss = 0.266760, test MAE = 0.688712\n",
      "step: 6390, LR = 0.014121, min batch loss = 3.266768, test MAE = 0.672563\n",
      "step: 6400, LR = 0.014121, min batch loss = 2.008677, test MAE = 0.670918\n",
      "step: 6410, LR = 0.014121, min batch loss = 0.163096, test MAE = 0.662763\n",
      "step: 6420, LR = 0.014121, min batch loss = 0.050930, test MAE = 0.646957\n",
      "step: 6430, LR = 0.014121, min batch loss = 0.248752, test MAE = 0.651315\n",
      "step: 6440, LR = 0.014121, min batch loss = 1.725690, test MAE = 0.641784\n",
      "step: 6450, LR = 0.014121, min batch loss = 1.075629, test MAE = 0.645648\n",
      "step: 6460, LR = 0.014121, min batch loss = 0.729448, test MAE = 0.678249\n",
      "step: 6470, LR = 0.014121, min batch loss = 2.198119, test MAE = 0.668600\n",
      "step: 6480, LR = 0.014121, min batch loss = 3.338609, test MAE = 0.675849\n",
      "step: 6490, LR = 0.014121, min batch loss = 0.134415, test MAE = 0.652535\n",
      "step: 6500, LR = 0.012709, min batch loss = 1.141674, test MAE = 0.649991\n",
      "step: 6510, LR = 0.012709, min batch loss = 0.922029, test MAE = 0.652786\n",
      "step: 6520, LR = 0.012709, min batch loss = 2.468226, test MAE = 0.688665\n",
      "step: 6530, LR = 0.012709, min batch loss = 2.879227, test MAE = 0.688781\n",
      "step: 6540, LR = 0.012709, min batch loss = 1.392997, test MAE = 0.659576\n",
      "step: 6550, LR = 0.012709, min batch loss = 0.060370, test MAE = 0.654710\n",
      "step: 6560, LR = 0.012709, min batch loss = 0.056564, test MAE = 0.652517\n",
      "step: 6570, LR = 0.012709, min batch loss = 0.117642, test MAE = 0.651277\n",
      "step: 6580, LR = 0.012709, min batch loss = 0.959485, test MAE = 0.645230\n",
      "step: 6590, LR = 0.012709, min batch loss = 0.135491, test MAE = 0.650049\n",
      "step: 6600, LR = 0.012709, min batch loss = 3.058238, test MAE = 0.652634\n",
      "step: 6610, LR = 0.012709, min batch loss = 3.579695, test MAE = 0.678253\n",
      "step: 6620, LR = 0.012709, min batch loss = 1.231577, test MAE = 0.677066\n",
      "step: 6630, LR = 0.012709, min batch loss = 0.227079, test MAE = 0.665698\n",
      "step: 6640, LR = 0.012709, min batch loss = 0.585739, test MAE = 0.665781\n",
      "step: 6650, LR = 0.012709, min batch loss = 0.160919, test MAE = 0.647467\n",
      "step: 6660, LR = 0.012709, min batch loss = 0.042400, test MAE = 0.653967\n",
      "step: 6670, LR = 0.012709, min batch loss = 0.794728, test MAE = 0.639508\n",
      "step: 6680, LR = 0.012709, min batch loss = 1.043962, test MAE = 0.655447\n",
      "step: 6690, LR = 0.012709, min batch loss = 1.767581, test MAE = 0.656976\n",
      "step: 6700, LR = 0.012709, min batch loss = 0.117110, test MAE = 0.642275\n",
      "step: 6710, LR = 0.012709, min batch loss = 2.398981, test MAE = 0.653122\n",
      "step: 6720, LR = 0.012709, min batch loss = 0.871266, test MAE = 0.647515\n",
      "step: 6730, LR = 0.012709, min batch loss = 0.841180, test MAE = 0.662662\n",
      "step: 6740, LR = 0.012709, min batch loss = 2.868808, test MAE = 0.666583\n",
      "step: 6750, LR = 0.012709, min batch loss = 0.129670, test MAE = 0.663984\n",
      "step: 6760, LR = 0.012709, min batch loss = 1.288201, test MAE = 0.695760\n",
      "step: 6770, LR = 0.012709, min batch loss = 0.679048, test MAE = 0.658009\n",
      "step: 6780, LR = 0.012709, min batch loss = 0.264648, test MAE = 0.671604\n",
      "step: 6790, LR = 0.012709, min batch loss = 1.340810, test MAE = 0.657650\n",
      "step: 6800, LR = 0.012709, min batch loss = 1.147377, test MAE = 0.661642\n",
      "step: 6810, LR = 0.012709, min batch loss = 0.655084, test MAE = 0.664611\n",
      "step: 6820, LR = 0.012709, min batch loss = 1.173518, test MAE = 0.664151\n",
      "step: 6830, LR = 0.012709, min batch loss = 0.127030, test MAE = 0.648679\n",
      "step: 6840, LR = 0.012709, min batch loss = 1.833794, test MAE = 0.652056\n",
      "step: 6850, LR = 0.012709, min batch loss = 0.177357, test MAE = 0.652247\n",
      "step: 6860, LR = 0.012709, min batch loss = 1.113481, test MAE = 0.650959\n",
      "step: 6870, LR = 0.012709, min batch loss = 0.197474, test MAE = 0.649884\n",
      "step: 6880, LR = 0.012709, min batch loss = 0.944096, test MAE = 0.644271\n",
      "step: 6890, LR = 0.012709, min batch loss = 1.287552, test MAE = 0.648372\n",
      "step: 6900, LR = 0.012709, min batch loss = 0.759730, test MAE = 0.647530\n",
      "step: 6910, LR = 0.012709, min batch loss = 0.128229, test MAE = 0.665802\n",
      "step: 6920, LR = 0.012709, min batch loss = 0.062721, test MAE = 0.663798\n",
      "step: 6930, LR = 0.012709, min batch loss = 0.873126, test MAE = 0.671649\n",
      "step: 6940, LR = 0.012709, min batch loss = 0.504000, test MAE = 0.698541\n",
      "step: 6950, LR = 0.012709, min batch loss = 2.343857, test MAE = 0.690589\n",
      "step: 6960, LR = 0.012709, min batch loss = 1.626588, test MAE = 0.699481\n",
      "step: 6970, LR = 0.012709, min batch loss = 0.857322, test MAE = 0.670794\n",
      "step: 6980, LR = 0.012709, min batch loss = 7.370951, test MAE = 0.824453\n",
      "step: 6990, LR = 0.012709, min batch loss = 0.137425, test MAE = 0.706023\n",
      "step: 7000, LR = 0.011438, min batch loss = 1.946239, test MAE = 0.667748\n",
      "step: 7010, LR = 0.011438, min batch loss = 0.049479, test MAE = 0.658706\n",
      "step: 7020, LR = 0.011438, min batch loss = 0.070678, test MAE = 0.661119\n",
      "step: 7030, LR = 0.011438, min batch loss = 0.178805, test MAE = 0.651483\n",
      "step: 7040, LR = 0.011438, min batch loss = 2.848371, test MAE = 0.651203\n",
      "step: 7050, LR = 0.011438, min batch loss = 0.185793, test MAE = 0.661543\n",
      "step: 7060, LR = 0.011438, min batch loss = 0.069011, test MAE = 0.651388\n",
      "step: 7070, LR = 0.011438, min batch loss = 1.537012, test MAE = 0.676048\n",
      "step: 7080, LR = 0.011438, min batch loss = 3.348481, test MAE = 0.675566\n",
      "step: 7090, LR = 0.011438, min batch loss = 0.721767, test MAE = 0.653154\n",
      "step: 7100, LR = 0.011438, min batch loss = 2.193736, test MAE = 0.646171\n",
      "step: 7110, LR = 0.011438, min batch loss = 1.043433, test MAE = 0.654995\n",
      "step: 7120, LR = 0.011438, min batch loss = 0.080495, test MAE = 0.647879\n",
      "step: 7130, LR = 0.011438, min batch loss = 1.261288, test MAE = 0.645430\n",
      "step: 7140, LR = 0.011438, min batch loss = 0.522185, test MAE = 0.646926\n",
      "step: 7150, LR = 0.011438, min batch loss = 0.042322, test MAE = 0.646354\n",
      "step: 7160, LR = 0.011438, min batch loss = 0.242515, test MAE = 0.652482\n",
      "step: 7170, LR = 0.011438, min batch loss = 0.583037, test MAE = 0.647869\n",
      "step: 7180, LR = 0.011438, min batch loss = 1.293702, test MAE = 0.657370\n",
      "step: 7190, LR = 0.011438, min batch loss = 0.077044, test MAE = 0.655972\n",
      "step: 7200, LR = 0.011438, min batch loss = 3.015971, test MAE = 0.666506\n",
      "step: 7210, LR = 0.011438, min batch loss = 1.606756, test MAE = 0.660999\n",
      "step: 7220, LR = 0.011438, min batch loss = 4.352566, test MAE = 0.642359\n",
      "step: 7230, LR = 0.011438, min batch loss = 0.587178, test MAE = 0.658085\n",
      "step: 7240, LR = 0.011438, min batch loss = 0.160155, test MAE = 0.674608\n",
      "step: 7250, LR = 0.011438, min batch loss = 0.186503, test MAE = 0.660345\n",
      "step: 7260, LR = 0.011438, min batch loss = 0.392354, test MAE = 0.663347\n",
      "step: 7270, LR = 0.011438, min batch loss = 1.053135, test MAE = 0.649655\n",
      "step: 7280, LR = 0.011438, min batch loss = 0.993126, test MAE = 0.652630\n",
      "step: 7290, LR = 0.011438, min batch loss = 0.130856, test MAE = 0.646070\n",
      "step: 7300, LR = 0.011438, min batch loss = 0.067290, test MAE = 0.640873\n",
      "step: 7310, LR = 0.011438, min batch loss = 2.879338, test MAE = 0.702947\n",
      "step: 7320, LR = 0.011438, min batch loss = 0.455819, test MAE = 0.694834\n",
      "step: 7330, LR = 0.011438, min batch loss = 1.902902, test MAE = 0.661913\n",
      "step: 7340, LR = 0.011438, min batch loss = 1.380638, test MAE = 0.665951\n",
      "step: 7350, LR = 0.011438, min batch loss = 0.151743, test MAE = 0.655342\n",
      "step: 7360, LR = 0.011438, min batch loss = 0.063731, test MAE = 0.640565\n",
      "step: 7370, LR = 0.011438, min batch loss = 0.265399, test MAE = 0.642843\n",
      "step: 7380, LR = 0.011438, min batch loss = 0.378147, test MAE = 0.650993\n",
      "step: 7390, LR = 0.011438, min batch loss = 0.046343, test MAE = 0.649762\n",
      "step: 7400, LR = 0.011438, min batch loss = 0.438006, test MAE = 0.662214\n",
      "step: 7410, LR = 0.011438, min batch loss = 0.236525, test MAE = 0.647761\n",
      "step: 7420, LR = 0.011438, min batch loss = 0.247366, test MAE = 0.683009\n",
      "step: 7430, LR = 0.011438, min batch loss = 0.767087, test MAE = 0.670730\n",
      "step: 7440, LR = 0.011438, min batch loss = 0.150200, test MAE = 0.664682\n",
      "step: 7450, LR = 0.011438, min batch loss = 0.683619, test MAE = 0.679096\n",
      "step: 7460, LR = 0.011438, min batch loss = 2.120271, test MAE = 0.678958\n",
      "step: 7470, LR = 0.011438, min batch loss = 5.368996, test MAE = 0.668911\n",
      "step: 7480, LR = 0.011438, min batch loss = 0.143533, test MAE = 0.653024\n",
      "step: 7490, LR = 0.011438, min batch loss = 0.185107, test MAE = 0.643051\n",
      "step: 7500, LR = 0.010295, min batch loss = 0.053302, test MAE = 0.650978\n",
      "step: 7510, LR = 0.010295, min batch loss = 0.779706, test MAE = 0.668796\n",
      "step: 7520, LR = 0.010295, min batch loss = 0.726430, test MAE = 0.656269\n",
      "step: 7530, LR = 0.010295, min batch loss = 0.508459, test MAE = 0.655962\n",
      "step: 7540, LR = 0.010295, min batch loss = 2.691265, test MAE = 0.681727\n",
      "step: 7550, LR = 0.010295, min batch loss = 4.020936, test MAE = 0.663148\n",
      "step: 7560, LR = 0.010295, min batch loss = 2.951481, test MAE = 0.668153\n",
      "step: 7570, LR = 0.010295, min batch loss = 1.378073, test MAE = 0.672911\n",
      "step: 7580, LR = 0.010295, min batch loss = 0.057763, test MAE = 0.654858\n",
      "step: 7590, LR = 0.010295, min batch loss = 2.005702, test MAE = 0.657922\n",
      "step: 7600, LR = 0.010295, min batch loss = 0.551932, test MAE = 0.646613\n",
      "step: 7610, LR = 0.010295, min batch loss = 1.220734, test MAE = 0.644558\n",
      "step: 7620, LR = 0.010295, min batch loss = 0.262775, test MAE = 0.658467\n",
      "step: 7630, LR = 0.010295, min batch loss = 1.224128, test MAE = 0.647087\n",
      "step: 7640, LR = 0.010295, min batch loss = 0.162785, test MAE = 0.646509\n",
      "step: 7650, LR = 0.010295, min batch loss = 0.132397, test MAE = 0.644138\n",
      "step: 7660, LR = 0.010295, min batch loss = 1.733571, test MAE = 0.640355\n",
      "step: 7670, LR = 0.010295, min batch loss = 3.476775, test MAE = 0.658320\n",
      "step: 7680, LR = 0.010295, min batch loss = 0.068128, test MAE = 0.656613\n",
      "step: 7690, LR = 0.010295, min batch loss = 0.029830, test MAE = 0.669208\n",
      "step: 7700, LR = 0.010295, min batch loss = 1.357261, test MAE = 0.681442\n",
      "step: 7710, LR = 0.010295, min batch loss = 0.829388, test MAE = 0.656211\n",
      "step: 7720, LR = 0.010295, min batch loss = 1.424375, test MAE = 0.666007\n",
      "step: 7730, LR = 0.010295, min batch loss = 0.332104, test MAE = 0.656919\n",
      "step: 7740, LR = 0.010295, min batch loss = 0.114839, test MAE = 0.654698\n",
      "step: 7750, LR = 0.010295, min batch loss = 1.551232, test MAE = 0.662038\n",
      "step: 7760, LR = 0.010295, min batch loss = 0.132469, test MAE = 0.651923\n",
      "step: 7770, LR = 0.010295, min batch loss = 1.574739, test MAE = 0.647610\n",
      "step: 7780, LR = 0.010295, min batch loss = 1.188838, test MAE = 0.650842\n",
      "step: 7790, LR = 0.010295, min batch loss = 1.366825, test MAE = 0.651528\n",
      "step: 7800, LR = 0.010295, min batch loss = 2.906716, test MAE = 0.661155\n",
      "step: 7810, LR = 0.010295, min batch loss = 0.276738, test MAE = 0.646362\n",
      "step: 7820, LR = 0.010295, min batch loss = 0.117078, test MAE = 0.652769\n",
      "step: 7830, LR = 0.010295, min batch loss = 2.912070, test MAE = 0.642488\n",
      "step: 7840, LR = 0.010295, min batch loss = 1.733918, test MAE = 0.643429\n",
      "step: 7850, LR = 0.010295, min batch loss = 0.630666, test MAE = 0.661726\n",
      "step: 7860, LR = 0.010295, min batch loss = 0.281370, test MAE = 0.666940\n",
      "step: 7870, LR = 0.010295, min batch loss = 0.349167, test MAE = 0.675353\n",
      "step: 7880, LR = 0.010295, min batch loss = 3.081211, test MAE = 0.697974\n",
      "step: 7890, LR = 0.010295, min batch loss = 0.794752, test MAE = 0.684850\n",
      "step: 7900, LR = 0.010295, min batch loss = 1.731840, test MAE = 0.675709\n",
      "step: 7910, LR = 0.010295, min batch loss = 1.898965, test MAE = 0.695229\n",
      "step: 7920, LR = 0.010295, min batch loss = 0.197719, test MAE = 0.741809\n",
      "step: 7930, LR = 0.010295, min batch loss = 0.060828, test MAE = 0.686212\n",
      "step: 7940, LR = 0.010295, min batch loss = 2.360919, test MAE = 0.660886\n",
      "step: 7950, LR = 0.010295, min batch loss = 0.737335, test MAE = 0.652716\n",
      "step: 7960, LR = 0.010295, min batch loss = 1.475586, test MAE = 0.650085\n",
      "step: 7970, LR = 0.010295, min batch loss = 1.072208, test MAE = 0.642000\n",
      "step: 7980, LR = 0.010295, min batch loss = 1.575357, test MAE = 0.644106\n",
      "step: 7990, LR = 0.010295, min batch loss = 1.672497, test MAE = 0.656382\n",
      "step: 8000, LR = 0.009265, min batch loss = 1.228303, test MAE = 0.643052\n",
      "step: 8010, LR = 0.009265, min batch loss = 0.925165, test MAE = 0.679598\n",
      "step: 8020, LR = 0.009265, min batch loss = 0.068002, test MAE = 0.664309\n",
      "step: 8030, LR = 0.009265, min batch loss = 3.844520, test MAE = 0.638136\n",
      "step: 8040, LR = 0.009265, min batch loss = 0.969286, test MAE = 0.639465\n",
      "step: 8050, LR = 0.009265, min batch loss = 1.470614, test MAE = 0.638195\n",
      "step: 8060, LR = 0.009265, min batch loss = 0.612382, test MAE = 0.643708\n",
      "step: 8070, LR = 0.009265, min batch loss = 1.277774, test MAE = 0.646812\n",
      "step: 8080, LR = 0.009265, min batch loss = 1.633759, test MAE = 0.638562\n",
      "step: 8090, LR = 0.009265, min batch loss = 0.126909, test MAE = 0.640652\n",
      "step: 8100, LR = 0.009265, min batch loss = 0.156501, test MAE = 0.640685\n",
      "step: 8110, LR = 0.009265, min batch loss = 0.376799, test MAE = 0.643495\n",
      "step: 8120, LR = 0.009265, min batch loss = 3.200523, test MAE = 0.656274\n",
      "step: 8130, LR = 0.009265, min batch loss = 1.108301, test MAE = 0.644274\n",
      "step: 8140, LR = 0.009265, min batch loss = 0.217381, test MAE = 0.651496\n",
      "step: 8150, LR = 0.009265, min batch loss = 1.998429, test MAE = 0.641446\n",
      "step: 8160, LR = 0.009265, min batch loss = 0.906730, test MAE = 0.638899\n",
      "step: 8170, LR = 0.009265, min batch loss = 0.101802, test MAE = 0.664599\n",
      "step: 8180, LR = 0.009265, min batch loss = 2.001922, test MAE = 0.652107\n",
      "step: 8190, LR = 0.009265, min batch loss = 0.258170, test MAE = 0.661113\n",
      "step: 8200, LR = 0.009265, min batch loss = 0.236485, test MAE = 0.648462\n",
      "step: 8210, LR = 0.009265, min batch loss = 1.606763, test MAE = 0.647695\n",
      "step: 8220, LR = 0.009265, min batch loss = 0.621966, test MAE = 0.652103\n",
      "step: 8230, LR = 0.009265, min batch loss = 0.940979, test MAE = 0.643607\n",
      "step: 8240, LR = 0.009265, min batch loss = 0.051131, test MAE = 0.640630\n",
      "step: 8250, LR = 0.009265, min batch loss = 2.262965, test MAE = 0.679352\n",
      "step: 8260, LR = 0.009265, min batch loss = 0.945746, test MAE = 0.660291\n",
      "step: 8270, LR = 0.009265, min batch loss = 2.674124, test MAE = 0.673558\n",
      "step: 8280, LR = 0.009265, min batch loss = 1.390188, test MAE = 0.675566\n",
      "step: 8290, LR = 0.009265, min batch loss = 0.109206, test MAE = 0.639756\n",
      "step: 8300, LR = 0.009265, min batch loss = 0.062104, test MAE = 0.637374\n",
      "step: 8310, LR = 0.009265, min batch loss = 0.068143, test MAE = 0.639524\n",
      "step: 8320, LR = 0.009265, min batch loss = 0.046426, test MAE = 0.641572\n",
      "step: 8330, LR = 0.009265, min batch loss = 0.335284, test MAE = 0.639901\n",
      "step: 8340, LR = 0.009265, min batch loss = 0.181876, test MAE = 0.647334\n",
      "step: 8350, LR = 0.009265, min batch loss = 0.630714, test MAE = 0.638038\n",
      "step: 8360, LR = 0.009265, min batch loss = 0.520252, test MAE = 0.653591\n",
      "step: 8370, LR = 0.009265, min batch loss = 0.101380, test MAE = 0.649474\n",
      "step: 8380, LR = 0.009265, min batch loss = 1.978426, test MAE = 0.646066\n",
      "step: 8390, LR = 0.009265, min batch loss = 0.121062, test MAE = 0.668699\n",
      "step: 8400, LR = 0.009265, min batch loss = 0.235815, test MAE = 0.662214\n",
      "step: 8410, LR = 0.009265, min batch loss = 1.530576, test MAE = 0.658960\n",
      "step: 8420, LR = 0.009265, min batch loss = 0.123158, test MAE = 0.646539\n",
      "step: 8430, LR = 0.009265, min batch loss = 1.775984, test MAE = 0.638231\n",
      "step: 8440, LR = 0.009265, min batch loss = 2.340259, test MAE = 0.662080\n",
      "step: 8450, LR = 0.009265, min batch loss = 0.658411, test MAE = 0.656531\n",
      "step: 8460, LR = 0.009265, min batch loss = 1.433655, test MAE = 0.649696\n",
      "step: 8470, LR = 0.009265, min batch loss = 0.033535, test MAE = 0.648024\n",
      "step: 8480, LR = 0.009265, min batch loss = 2.494431, test MAE = 0.669604\n",
      "step: 8490, LR = 0.009265, min batch loss = 0.886874, test MAE = 0.664055\n",
      "step: 8500, LR = 0.008339, min batch loss = 0.718741, test MAE = 0.657715\n",
      "step: 8510, LR = 0.008339, min batch loss = 2.089787, test MAE = 0.660683\n",
      "step: 8520, LR = 0.008339, min batch loss = 0.142734, test MAE = 0.651351\n",
      "step: 8530, LR = 0.008339, min batch loss = 0.609329, test MAE = 0.656917\n",
      "step: 8540, LR = 0.008339, min batch loss = 0.411088, test MAE = 0.642037\n",
      "step: 8550, LR = 0.008339, min batch loss = 1.823123, test MAE = 0.645725\n",
      "step: 8560, LR = 0.008339, min batch loss = 2.298095, test MAE = 0.646257\n",
      "step: 8570, LR = 0.008339, min batch loss = 0.218809, test MAE = 0.643275\n",
      "step: 8580, LR = 0.008339, min batch loss = 0.602469, test MAE = 0.642841\n",
      "step: 8590, LR = 0.008339, min batch loss = 2.530198, test MAE = 0.642522\n",
      "step: 8600, LR = 0.008339, min batch loss = 1.883997, test MAE = 0.639245\n",
      "step: 8610, LR = 0.008339, min batch loss = 1.196288, test MAE = 0.648839\n",
      "step: 8620, LR = 0.008339, min batch loss = 0.191524, test MAE = 0.649099\n",
      "step: 8630, LR = 0.008339, min batch loss = 0.697510, test MAE = 0.670691\n",
      "step: 8640, LR = 0.008339, min batch loss = 0.070643, test MAE = 0.658253\n",
      "step: 8650, LR = 0.008339, min batch loss = 0.703480, test MAE = 0.661088\n",
      "step: 8660, LR = 0.008339, min batch loss = 0.504883, test MAE = 0.659810\n",
      "step: 8670, LR = 0.008339, min batch loss = 0.038227, test MAE = 0.655996\n",
      "step: 8680, LR = 0.008339, min batch loss = 0.112016, test MAE = 0.666426\n",
      "step: 8690, LR = 0.008339, min batch loss = 1.366066, test MAE = 0.666605\n",
      "step: 8700, LR = 0.008339, min batch loss = 1.348091, test MAE = 0.641517\n",
      "step: 8710, LR = 0.008339, min batch loss = 1.781174, test MAE = 0.648954\n",
      "step: 8720, LR = 0.008339, min batch loss = 1.009019, test MAE = 0.646246\n",
      "step: 8730, LR = 0.008339, min batch loss = 1.211866, test MAE = 0.649464\n",
      "step: 8740, LR = 0.008339, min batch loss = 2.119712, test MAE = 0.647850\n",
      "step: 8750, LR = 0.008339, min batch loss = 1.164207, test MAE = 0.642283\n",
      "step: 8760, LR = 0.008339, min batch loss = 0.324890, test MAE = 0.646067\n",
      "step: 8770, LR = 0.008339, min batch loss = 0.927415, test MAE = 0.638328\n",
      "step: 8780, LR = 0.008339, min batch loss = 1.461582, test MAE = 0.655645\n",
      "step: 8790, LR = 0.008339, min batch loss = 0.233295, test MAE = 0.655787\n",
      "step: 8800, LR = 0.008339, min batch loss = 1.446136, test MAE = 0.660633\n",
      "step: 8810, LR = 0.008339, min batch loss = 3.034581, test MAE = 0.686683\n",
      "step: 8820, LR = 0.008339, min batch loss = 2.699372, test MAE = 0.715489\n",
      "step: 8830, LR = 0.008339, min batch loss = 1.478082, test MAE = 0.688469\n",
      "step: 8840, LR = 0.008339, min batch loss = 0.100018, test MAE = 0.667178\n",
      "step: 8850, LR = 0.008339, min batch loss = 0.476956, test MAE = 0.703767\n",
      "step: 8860, LR = 0.008339, min batch loss = 1.322300, test MAE = 0.700284\n",
      "step: 8870, LR = 0.008339, min batch loss = 0.531680, test MAE = 0.674859\n",
      "step: 8880, LR = 0.008339, min batch loss = 0.821331, test MAE = 0.650873\n",
      "step: 8890, LR = 0.008339, min batch loss = 4.405165, test MAE = 0.658699\n",
      "step: 8900, LR = 0.008339, min batch loss = 0.881257, test MAE = 0.645278\n",
      "step: 8910, LR = 0.008339, min batch loss = 0.352017, test MAE = 0.639841\n",
      "step: 8920, LR = 0.008339, min batch loss = 2.052604, test MAE = 0.651143\n",
      "step: 8930, LR = 0.008339, min batch loss = 0.119482, test MAE = 0.646513\n",
      "step: 8940, LR = 0.008339, min batch loss = 0.088184, test MAE = 0.649676\n",
      "step: 8950, LR = 0.008339, min batch loss = 0.972128, test MAE = 0.657680\n",
      "step: 8960, LR = 0.008339, min batch loss = 0.163332, test MAE = 0.653030\n",
      "step: 8970, LR = 0.008339, min batch loss = 1.403785, test MAE = 0.634270\n",
      "step: 8980, LR = 0.008339, min batch loss = 2.680651, test MAE = 0.635417\n",
      "step: 8990, LR = 0.008339, min batch loss = 1.547058, test MAE = 0.641071\n",
      "step: 9000, LR = 0.007505, min batch loss = 0.048510, test MAE = 0.641836\n",
      "step: 9010, LR = 0.007505, min batch loss = 0.065602, test MAE = 0.638764\n",
      "step: 9020, LR = 0.007505, min batch loss = 0.102623, test MAE = 0.635709\n",
      "step: 9030, LR = 0.007505, min batch loss = 2.466743, test MAE = 0.641501\n",
      "step: 9040, LR = 0.007505, min batch loss = 1.217839, test MAE = 0.636746\n",
      "step: 9050, LR = 0.007505, min batch loss = 0.085339, test MAE = 0.638151\n",
      "step: 9060, LR = 0.007505, min batch loss = 1.329411, test MAE = 0.649592\n",
      "step: 9070, LR = 0.007505, min batch loss = 3.119690, test MAE = 0.653440\n",
      "step: 9080, LR = 0.007505, min batch loss = 1.868998, test MAE = 0.651998\n",
      "step: 9090, LR = 0.007505, min batch loss = 0.851631, test MAE = 0.635321\n",
      "step: 9100, LR = 0.007505, min batch loss = 0.588104, test MAE = 0.641851\n",
      "step: 9110, LR = 0.007505, min batch loss = 0.761913, test MAE = 0.671151\n",
      "step: 9120, LR = 0.007505, min batch loss = 0.096132, test MAE = 0.656991\n",
      "step: 9130, LR = 0.007505, min batch loss = 1.432307, test MAE = 0.655423\n",
      "step: 9140, LR = 0.007505, min batch loss = 0.135139, test MAE = 0.644670\n",
      "step: 9150, LR = 0.007505, min batch loss = 0.906908, test MAE = 0.647229\n",
      "step: 9160, LR = 0.007505, min batch loss = 0.086848, test MAE = 0.641082\n",
      "step: 9170, LR = 0.007505, min batch loss = 0.609863, test MAE = 0.637971\n",
      "step: 9180, LR = 0.007505, min batch loss = 0.681873, test MAE = 0.638593\n",
      "step: 9190, LR = 0.007505, min batch loss = 3.162427, test MAE = 0.661485\n",
      "step: 9200, LR = 0.007505, min batch loss = 0.051989, test MAE = 0.657855\n",
      "step: 9210, LR = 0.007505, min batch loss = 0.158732, test MAE = 0.658948\n",
      "step: 9220, LR = 0.007505, min batch loss = 1.470666, test MAE = 0.658308\n",
      "step: 9230, LR = 0.007505, min batch loss = 1.337566, test MAE = 0.643452\n",
      "step: 9240, LR = 0.007505, min batch loss = 0.062439, test MAE = 0.639871\n",
      "step: 9250, LR = 0.007505, min batch loss = 2.671771, test MAE = 0.642537\n",
      "step: 9260, LR = 0.007505, min batch loss = 0.067823, test MAE = 0.636357\n",
      "step: 9270, LR = 0.007505, min batch loss = 1.862938, test MAE = 0.654924\n",
      "step: 9280, LR = 0.007505, min batch loss = 0.051961, test MAE = 0.646042\n",
      "step: 9290, LR = 0.007505, min batch loss = 0.104670, test MAE = 0.650373\n",
      "step: 9300, LR = 0.007505, min batch loss = 1.845841, test MAE = 0.655016\n",
      "step: 9310, LR = 0.007505, min batch loss = 0.113182, test MAE = 0.646367\n",
      "step: 9320, LR = 0.007505, min batch loss = 0.325941, test MAE = 0.643231\n",
      "step: 9330, LR = 0.007505, min batch loss = 3.048410, test MAE = 0.673440\n",
      "step: 9340, LR = 0.007505, min batch loss = 1.551814, test MAE = 0.664275\n",
      "step: 9350, LR = 0.007505, min batch loss = 2.645121, test MAE = 0.644192\n",
      "step: 9360, LR = 0.007505, min batch loss = 2.244841, test MAE = 0.639686\n",
      "step: 9370, LR = 0.007505, min batch loss = 0.744540, test MAE = 0.641258\n",
      "step: 9380, LR = 0.007505, min batch loss = 0.534103, test MAE = 0.648458\n",
      "step: 9390, LR = 0.007505, min batch loss = 0.135946, test MAE = 0.642384\n",
      "step: 9400, LR = 0.007505, min batch loss = 0.312687, test MAE = 0.647161\n",
      "step: 9410, LR = 0.007505, min batch loss = 0.150501, test MAE = 0.642009\n",
      "step: 9420, LR = 0.007505, min batch loss = 0.558437, test MAE = 0.660488\n",
      "step: 9430, LR = 0.007505, min batch loss = 0.934312, test MAE = 0.666580\n",
      "step: 9440, LR = 0.007505, min batch loss = 0.061368, test MAE = 0.658740\n",
      "step: 9450, LR = 0.007505, min batch loss = 0.847216, test MAE = 0.652681\n",
      "step: 9460, LR = 0.007505, min batch loss = 1.731704, test MAE = 0.650111\n",
      "step: 9470, LR = 0.007505, min batch loss = 0.039006, test MAE = 0.650956\n",
      "step: 9480, LR = 0.007505, min batch loss = 0.876072, test MAE = 0.640925\n",
      "step: 9490, LR = 0.007505, min batch loss = 0.598973, test MAE = 0.646485\n",
      "step: 9500, LR = 0.006754, min batch loss = 0.110602, test MAE = 0.645611\n",
      "step: 9510, LR = 0.006754, min batch loss = 0.928077, test MAE = 0.638072\n",
      "step: 9520, LR = 0.006754, min batch loss = 0.529669, test MAE = 0.640744\n",
      "step: 9530, LR = 0.006754, min batch loss = 1.873746, test MAE = 0.635107\n",
      "step: 9540, LR = 0.006754, min batch loss = 0.272460, test MAE = 0.643368\n",
      "step: 9550, LR = 0.006754, min batch loss = 0.817192, test MAE = 0.651305\n",
      "step: 9560, LR = 0.006754, min batch loss = 2.424398, test MAE = 0.661199\n",
      "step: 9570, LR = 0.006754, min batch loss = 0.036238, test MAE = 0.664986\n",
      "step: 9580, LR = 0.006754, min batch loss = 0.980689, test MAE = 0.648868\n",
      "step: 9590, LR = 0.006754, min batch loss = 0.464163, test MAE = 0.651254\n",
      "step: 9600, LR = 0.006754, min batch loss = 1.324253, test MAE = 0.656153\n",
      "step: 9610, LR = 0.006754, min batch loss = 0.055004, test MAE = 0.653272\n",
      "step: 9620, LR = 0.006754, min batch loss = 1.422024, test MAE = 0.657215\n",
      "step: 9630, LR = 0.006754, min batch loss = 1.634280, test MAE = 0.649272\n",
      "step: 9640, LR = 0.006754, min batch loss = 2.074357, test MAE = 0.641197\n",
      "step: 9650, LR = 0.006754, min batch loss = 3.072213, test MAE = 0.643773\n",
      "step: 9660, LR = 0.006754, min batch loss = 3.180553, test MAE = 0.647524\n",
      "step: 9670, LR = 0.006754, min batch loss = 1.715032, test MAE = 0.646487\n",
      "step: 9680, LR = 0.006754, min batch loss = 1.389152, test MAE = 0.642321\n",
      "step: 9690, LR = 0.006754, min batch loss = 2.184322, test MAE = 0.640555\n",
      "step: 9700, LR = 0.006754, min batch loss = 0.456001, test MAE = 0.637804\n",
      "step: 9710, LR = 0.006754, min batch loss = 0.034445, test MAE = 0.639011\n",
      "step: 9720, LR = 0.006754, min batch loss = 0.130550, test MAE = 0.648554\n",
      "step: 9730, LR = 0.006754, min batch loss = 0.714670, test MAE = 0.650686\n",
      "step: 9740, LR = 0.006754, min batch loss = 0.603334, test MAE = 0.659287\n",
      "step: 9750, LR = 0.006754, min batch loss = 1.399650, test MAE = 0.673966\n",
      "step: 9760, LR = 0.006754, min batch loss = 0.113433, test MAE = 0.684022\n",
      "step: 9770, LR = 0.006754, min batch loss = 1.756858, test MAE = 0.674938\n",
      "step: 9780, LR = 0.006754, min batch loss = 0.333141, test MAE = 0.664699\n",
      "step: 9790, LR = 0.006754, min batch loss = 0.232299, test MAE = 0.724447\n",
      "step: 9800, LR = 0.006754, min batch loss = 0.166621, test MAE = 0.680840\n",
      "step: 9810, LR = 0.006754, min batch loss = 1.699935, test MAE = 0.657038\n",
      "step: 9820, LR = 0.006754, min batch loss = 0.220501, test MAE = 0.647908\n",
      "step: 9830, LR = 0.006754, min batch loss = 0.063094, test MAE = 0.648457\n",
      "step: 9840, LR = 0.006754, min batch loss = 2.318781, test MAE = 0.641611\n",
      "step: 9850, LR = 0.006754, min batch loss = 0.642043, test MAE = 0.638411\n",
      "step: 9860, LR = 0.006754, min batch loss = 2.569065, test MAE = 0.641866\n",
      "step: 9870, LR = 0.006754, min batch loss = 0.400174, test MAE = 0.638291\n",
      "step: 9880, LR = 0.006754, min batch loss = 4.407967, test MAE = 0.658362\n",
      "step: 9890, LR = 0.006754, min batch loss = 0.297854, test MAE = 0.653926\n",
      "step: 9900, LR = 0.006754, min batch loss = 0.715537, test MAE = 0.640271\n",
      "step: 9910, LR = 0.006754, min batch loss = 1.006069, test MAE = 0.633927\n",
      "step: 9920, LR = 0.006754, min batch loss = 0.130240, test MAE = 0.639708\n",
      "step: 9930, LR = 0.006754, min batch loss = 0.727729, test MAE = 0.639297\n",
      "step: 9940, LR = 0.006754, min batch loss = 0.603679, test MAE = 0.640658\n",
      "step: 9950, LR = 0.006754, min batch loss = 0.304244, test MAE = 0.634627\n",
      "step: 9960, LR = 0.006754, min batch loss = 0.156507, test MAE = 0.635731\n",
      "step: 9970, LR = 0.006754, min batch loss = 0.265935, test MAE = 0.638860\n",
      "step: 9980, LR = 0.006754, min batch loss = 0.069744, test MAE = 0.637877\n",
      "step: 9990, LR = 0.006754, min batch loss = 1.691144, test MAE = 0.643296\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    test_feed_dict = {inputs:test_data_n, labels:test_label[:,-1,:]}\n",
    "    for step in range(steps):\n",
    "        off = step * batch_size % (total_size - batch_size)\n",
    "        batch_data = train_data_n[off:off+batch_size, :, :]\n",
    "        batch_label = train_label[off:off+batch_size, -1, :]\n",
    "        feed_dict = {inputs:batch_data, labels:batch_label}\n",
    "        l, _, r = session.run([loss, op, learning_rate], feed_dict=feed_dict)\n",
    "        if step % 10 == 0:\n",
    "            test_mae = MAE.eval(feed_dict=test_feed_dict)\n",
    "            print('step: %d, LR = %f, min batch loss = %f, test MAE = %f' % (step, r, l, test_mae))\n",
    "            #print('batch_data = %d %d %d, batch_label = %d, predicate = %f' % (batch_data[0, 0, 0],batch_data[0, 1, 0],batch_data[0, 2, 0], batch_label[0, 0], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label1 = train_label.reshape(train_label.shape[0], train_label.shape[1])\n",
    "label2 = test_label.reshape(test_label.shape[0], test_label.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do classification later\n",
    "from sklearn.preprocessing import Binarizer\n",
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_label = pre.transform(label1)\n",
    "b_test_label = pre.transform(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14737,), (119966, 8), (959728, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_label = 1 - b_train_label\n",
    "r, _ = (c_train_label == 1).nonzero()\n",
    "r.shape, c_train_label.shape, c_train_label.reshape(c_train_label.shape[0]*c_train_label.shape[1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train_label = 1 - b_train_label\n",
    "c_test_label = 1 - b_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change from Indice to Vector\n",
    "''''''\n",
    "def makeIndicatorVars(T):\n",
    "    # Make sure T is two-dimensiona. Should be nSamples x 1.\n",
    "    if T.ndim == 1:\n",
    "        T = T.reshape((-1,1))    \n",
    "    return (T == np.unique(T)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_train_label_t = makeIndicatorVars(c_train_label.reshape(c_train_label.shape[0]*c_train_label.shape[1], 1))\n",
    "v_test_label_t = makeIndicatorVars(c_test_label.reshape(c_test_label.shape[0]*c_test_label.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_train_label = v_train_label_t.reshape(c_train_label.shape[0], c_train_label.shape[1], 2)\n",
    "v_test_label = v_test_label_t.reshape(c_test_label.shape[0], c_test_label.shape[1], 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 70\n",
    "n_steps = 8\n",
    "n_labels = 2\n",
    "n_hidden = 140\n",
    "total_size = v_train_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-84-56ed361f1a03>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-84-56ed361f1a03>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    def acc(predict, label):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(\"float32\", [None, n_steps, n_features])\n",
    "    labels = tf.placeholder(\"float32\", [None, n_labels])\n",
    "    \n",
    "    weights = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_features, n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_labels]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_labels]))\n",
    "    }\n",
    "    \n",
    "    def acc(predict, label):\n",
    "        #correct_prediction = tf.equal(predicted_label, tf_train_label)\n",
    "        correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(label, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        predict_event = tf.reduce_sum(tf.argmax(predict, 1))\n",
    "        label_event = tf.reduce_sum(tf.argmax(label, 1))\n",
    "        true_positive = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 2), tf.int64))\n",
    "        true_negative = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 0), tf.int64))\n",
    "        false_positive = predict_event - true_positive \n",
    "        false_negative = label_event - true_positive\n",
    "        return accuracy, false_positive, false_negative, true_positive, true_negative\n",
    "    def ROC(FP, FN, TP, TN):\n",
    "        TP_percent = TP / (TP + FN)\n",
    "        FP_percent = FP / (FP + TN)\n",
    "        return TP_percent, FP_percent\n",
    "    \n",
    "    def PRC(FP, FN, TP, TN):\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f_score = 2 * precision * recall / (precision + recall)\n",
    "        return precision, recall, f_score\n",
    "    \n",
    "    def RNN(x, w, b):\n",
    "        # Prepare data shape to match `rnn` function requirements\n",
    "        # Current data input shape: (batch_size, n_steps, n_input)\n",
    "        # Required shape: 'n_steps' tensors list of shape (batch_size, n_hidden)\n",
    "    \n",
    "        # Permuting batch_size and n_steps\n",
    "        x = tf.transpose(x, [1, 0, 2])\n",
    "        # Reshaping to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, n_features])\n",
    "        \n",
    "        # Linear activation\n",
    "        x = tf.matmul(x, w['hidden']) + b['hidden']\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "        x = tf.split(0, n_steps, x)\n",
    "\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # Linear activation, using rnn inner loop last output\n",
    "        return tf.matmul(outputs[-1], w['out']) + b['out']\n",
    "    \n",
    "    pred = RNN(inputs, weights, biases)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, labels)) # Softmax loss\n",
    "    \n",
    "    # Learning rate decay\n",
    "    global_step = tf.Variable(0)\n",
    "    starter_learning_rate = 0.05\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 500, 0.90, staircase=True)\n",
    "    op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "    \n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    test_acc, FP, FN, TP, TN = acc(pred, labels)\n",
    "    t_p, f_p = ROC(FP, FN, TP, TN)\n",
    "    pre, rec, f_s = PRC(FP, FN, TP, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step: 0, LR = 0.050000, min batch loss = 1.667184, train acc = 1.000000\n",
      "test acc = 0.855233\n",
      "step: 10, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "step: 20, LR = 0.050000, min batch loss = 0.000011, train acc = 1.000000\n",
      "step: 30, LR = 0.050000, min batch loss = 0.000097, train acc = 1.000000\n",
      "step: 40, LR = 0.050000, min batch loss = 0.019471, train acc = 1.000000\n",
      "step: 50, LR = 0.050000, min batch loss = 0.025254, train acc = 1.000000\n",
      "step: 60, LR = 0.050000, min batch loss = 4.075491, train acc = 0.984375\n",
      "step: 70, LR = 0.050000, min batch loss = 0.000014, train acc = 1.000000\n",
      "step: 80, LR = 0.050000, min batch loss = 0.288553, train acc = 0.960938\n",
      "step: 90, LR = 0.050000, min batch loss = 0.000011, train acc = 1.000000\n",
      "step: 100, LR = 0.050000, min batch loss = 0.000001, train acc = 1.000000\n",
      "test acc = 0.984296\n",
      "step: 110, LR = 0.050000, min batch loss = 0.000577, train acc = 1.000000\n",
      "step: 120, LR = 0.050000, min batch loss = 0.002389, train acc = 1.000000\n",
      "step: 130, LR = 0.050000, min batch loss = 0.000629, train acc = 1.000000\n",
      "step: 140, LR = 0.050000, min batch loss = 0.374415, train acc = 0.859375\n",
      "step: 150, LR = 0.050000, min batch loss = 0.019960, train acc = 1.000000\n",
      "step: 160, LR = 0.050000, min batch loss = 0.000001, train acc = 1.000000\n",
      "step: 170, LR = 0.050000, min batch loss = 0.000033, train acc = 1.000000\n",
      "step: 180, LR = 0.050000, min batch loss = 0.001205, train acc = 1.000000\n",
      "step: 190, LR = 0.050000, min batch loss = 0.000004, train acc = 1.000000\n",
      "step: 200, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "test acc = 0.956957\n",
      "step: 210, LR = 0.050000, min batch loss = 0.000002, train acc = 1.000000\n",
      "step: 220, LR = 0.050000, min batch loss = 0.000022, train acc = 1.000000\n",
      "step: 230, LR = 0.050000, min batch loss = 0.012810, train acc = 1.000000\n",
      "step: 240, LR = 0.050000, min batch loss = 0.000032, train acc = 1.000000\n",
      "step: 250, LR = 0.050000, min batch loss = 0.000001, train acc = 1.000000\n",
      "step: 260, LR = 0.050000, min batch loss = 0.269614, train acc = 1.000000\n",
      "step: 270, LR = 0.050000, min batch loss = 0.002662, train acc = 1.000000\n",
      "step: 280, LR = 0.050000, min batch loss = 0.001172, train acc = 1.000000\n",
      "step: 290, LR = 0.050000, min batch loss = 0.049513, train acc = 0.992188\n",
      "step: 300, LR = 0.050000, min batch loss = 0.134159, train acc = 0.992188\n",
      "test acc = 0.976328\n",
      "step: 310, LR = 0.050000, min batch loss = 0.002210, train acc = 1.000000\n",
      "step: 320, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "step: 330, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "step: 340, LR = 0.050000, min batch loss = 0.383026, train acc = 0.968750\n",
      "step: 350, LR = 0.050000, min batch loss = 0.058729, train acc = 1.000000\n",
      "step: 360, LR = 0.050000, min batch loss = 0.000492, train acc = 1.000000\n",
      "step: 370, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "step: 380, LR = 0.050000, min batch loss = 0.000324, train acc = 1.000000\n",
      "step: 390, LR = 0.050000, min batch loss = 0.430994, train acc = 0.859375\n",
      "step: 400, LR = 0.050000, min batch loss = 0.609623, train acc = 0.914062\n",
      "test acc = 0.964058\n",
      "step: 410, LR = 0.050000, min batch loss = 0.069032, train acc = 0.984375\n",
      "step: 420, LR = 0.050000, min batch loss = 0.116540, train acc = 0.953125\n",
      "step: 430, LR = 0.050000, min batch loss = 0.026671, train acc = 1.000000\n",
      "step: 440, LR = 0.050000, min batch loss = 0.000000, train acc = 1.000000\n",
      "step: 450, LR = 0.050000, min batch loss = 0.002566, train acc = 1.000000\n",
      "step: 460, LR = 0.050000, min batch loss = 0.000194, train acc = 1.000000\n",
      "step: 470, LR = 0.050000, min batch loss = 0.056069, train acc = 0.984375\n",
      "step: 480, LR = 0.050000, min batch loss = 0.019312, train acc = 1.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-56b8f0ddc99e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_train_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0moff\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/htan/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/htan/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/htan/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/htan/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/htan/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    test_feed_dict = {inputs:test_data_n, labels:v_test_label[:,-1,:]}\n",
    "    for step in range(steps):\n",
    "        off = step * batch_size % (total_size - batch_size)\n",
    "        batch_data = train_data_n[off:off+batch_size, :, :]\n",
    "        batch_label = v_train_label[off:off+batch_size, -1, :]\n",
    "        feed_dict = {inputs:batch_data, labels:batch_label}\n",
    "        l, _, r = session.run([loss, op, learning_rate], feed_dict=feed_dict)\n",
    "        if step % 10 == 0:\n",
    "            acc = accuracy.eval(feed_dict=feed_dict)\n",
    "            print('step: %d, LR = %f, min batch loss = %f, train acc = %f' % (step, r, l, acc))\n",
    "        if step % 100 == 0:\n",
    "            print('test acc = %f' % (accuracy.eval(feed_dict=test_feed_dict)))\n",
    "            #print('batch_data = %d %d %d, batch_label = %d, predicate = %f' % (batch_data[0, 0, 0],batch_data[0, 1, 0],batch_data[0, 2, 0], batch_label[0, 0], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
