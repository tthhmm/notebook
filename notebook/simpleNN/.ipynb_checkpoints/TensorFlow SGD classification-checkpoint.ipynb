{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS_alone.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset= save['train_dataset']\n",
    "    validate_dataset = save['validate_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_old = save['test_dataset_evan']\n",
    "    train_old = save['train_dataset_evan']\n",
    "    del save\n",
    "\n",
    "train_time = train_dataset['time']\n",
    "train_data = train_dataset['data']\n",
    "train_label = train_dataset['label']\n",
    "validate_time = validate_dataset['time']\n",
    "validate_data = validate_dataset['data']\n",
    "validate_label = validate_dataset['label']\n",
    "test_time = test_dataset['time']\n",
    "test_data = test_dataset['data']\n",
    "test_label = test_dataset['label']\n",
    "test_old_data = test_old['data']\n",
    "test_old_label = test_old['label']\n",
    "train_old_data = train_old['data']\n",
    "train_old_label = train_old['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,) (70,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_data.mean(axis = 0)\n",
    "std = train_data.std(axis = 0)\n",
    "print(mean.shape, std.shape)\n",
    "train_data_n = (train_data - mean)/std\n",
    "validate_data_n = (validate_data - mean)/std\n",
    "test_data_n = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfering the regression problem to classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_label = pre.transform(train_label.reshape(1, -1))\n",
    "b_validate_label = pre.transform(validate_label.reshape(1, -1))\n",
    "b_test_label = pre.transform(test_label.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_train_label = 1 - b_train_label[0]\n",
    "c_validate_label = 1 - b_validate_label[0]\n",
    "c_test_old_label = 1 - b_test_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_validate_label.reshape(-1, 1)[:30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 174485, 1.0: 2502})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 2732 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#need to balanced the dataset\n",
    "from unbalanced_dataset.over_sampling import SMOTE\n",
    "sm = SMOTE(ratio = 0.03, kind='regular')\n",
    "train_data_n_resample, c_train_label_resample = sm.fit_transform(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle the data set\n",
    "arr = np.arange(c_train_label_resample.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "train_data_n_resample_s =  train_data_n_resample[arr]\n",
    "c_train_label_resample_s = c_train_label_resample[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_label_resample_s[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change from Indice to Vector\n",
    "''''''\n",
    "def makeIndicatorVars(T):\n",
    "    # Make sure T is two-dimensiona. Should be nSamples x 1.\n",
    "    if T.ndim == 1:\n",
    "        T = T.reshape((-1,1))    \n",
    "    return (T == np.unique(T)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_train_label = makeIndicatorVars(c_train_label.reshape(-1, 1))\n",
    "v_validate_label = makeIndicatorVars(c_validate_label.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_train_label_resample_s = makeIndicatorVars(c_train_label_resample_s.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write create simple linearLogistic Regression model\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(256, 70))\n",
    "    tf_train_label = tf.placeholder(tf.float32, shape=(256,2))\n",
    "    tf_validate_dataset = tf.constant(validate_data_n.astype(np.float32)[:, :])\n",
    "    tf_validate_label = tf.constant(v_validate_label.astype(np.float32)[:])\n",
    "    #tf_test_dataset1 = tf.constant(test_data_n.astype(np.float32)[:30000, :])\n",
    "    #tf_test_label1 = tf.constant(test_label.astype(np.float32)[:30000])\n",
    "    #tf_test_dataset2 = tf.constant(test_data_n.astype(np.float32)[30000:, :])\n",
    "    #tf_test_label2 = tf.constant(test_label.astype(np.float32)[30000:])\n",
    "    weights1 = tf.Variable(tf.truncated_normal([train_data_n.shape[1], 10]))\n",
    "    biases1 = tf.Variable(tf.zeros([10]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([10, 2]))\n",
    "    biases2 = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "    def acc(predict, label):\n",
    "        #correct_prediction = tf.equal(predicted_label, tf_train_label)\n",
    "        correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(label, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        predict_event = tf.reduce_sum(tf.argmax(predict, 1))\n",
    "        label_event = tf.reduce_sum(tf.argmax(label, 1))\n",
    "        true_positive = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 2), tf.int64))\n",
    "        true_negative = tf.reduce_sum(tf.cast(tf.equal((tf.argmax(predict, 1) + tf.argmax(label, 1)), 0), tf.int64))\n",
    "        false_positive = predict_event - true_positive \n",
    "        false_negative = label_event - true_positive\n",
    "        return accuracy, false_positive, false_negative, true_positive, true_negative\n",
    "    def ROC(FP, FN, TP, TN):\n",
    "        TP_percent = TP / (TP + FN)\n",
    "        FP_percent = FP / (FP + TN)\n",
    "        return TP_percent, FP_percent\n",
    "    \n",
    "    def PRC(FP, FN, TP, TN):\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f_score = 2 * precision * recall / (precision + recall)\n",
    "        return precision, recall, f_score\n",
    "    \n",
    "    def train_model(X):\n",
    "        hidden = tf.nn.relu6(tf.matmul(X, weights1) + biases1)\n",
    "        #hidden = tf.nn.dropout(hidden, 1.0)\n",
    "        return tf.nn.softmax(tf.matmul(hidden, weights2) + biases2)\n",
    "    \n",
    "    def eval_model(X):\n",
    "        hidden = tf.nn.relu6(tf.matmul(X, weights1) + biases1)\n",
    "        return tf.nn.softmax(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "    predicted_label = train_model(tf_train_dataset)\n",
    "    #loss = tf.reduce_mean(tf.square(predicted_label - tf_train_label))\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(tf_train_label * tf.log(predicted_label), reduction_indices=[1]))\n",
    "\n",
    "    # Learning rate decay\n",
    "    global_step = tf.Variable(0)\n",
    "    starter_learning_rate = 0.03\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 2500, 0.96, staircase=True)\n",
    "    op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "\n",
    "    \n",
    "    train_acc, _, _, _, _ = acc(predicted_label, tf_train_label)\n",
    "    validate_acc, FP, FN, TP, TN = acc(eval_model(tf_validate_dataset), tf_validate_label)\n",
    "    t_p, f_p = ROC(FP, FN, TP, TN)\n",
    "    pre, rec, f_s = PRC(FP, FN, TP, TN)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #train_loss = tf.reduce_mean(tf.abs(predicted_label - tf_train_label))\n",
    "    #test_loss1 = tf.reduce_mean(tf.abs(model(tf_test_dataset1, weights, biases) - tf_test_label1))\n",
    "    #test_loss2 = tf.reduce_mean(tf.abs(model(tf_test_dataset2, weights, biases) - tf_test_label2))\n",
    "    #test_loss = (test_loss1 * 30000 + test_loss2 * (test_size - 30000)) / test_size\n",
    "    #validate_loss = tf.reduce_mean(tf.abs(model(tf_validate_dataset, weights, biases) - tf_validate_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0 : train acc = 0.214844, validate acc = 0.160503\n",
      "183 21195 30 3875\n",
      "precision = 0.008560, recall = 0.859155, f_score = 0.016952\n",
      "Loss at step 1000 : train acc = 0.976562, validate acc = 0.989242\n",
      "32 91 181 24979\n",
      "precision = 0.260163, recall = 0.150235, f_score = 0.190476\n",
      "Loss at step 2000 : train acc = 0.941406, validate acc = 0.986908\n",
      "76 194 137 24876\n",
      "precision = 0.281481, recall = 0.356808, f_score = 0.314700\n",
      "Loss at step 3000 : train acc = 0.980469, validate acc = 0.990943\n",
      "8 24 205 25046\n",
      "precision = 0.250000, recall = 0.037559, f_score = 0.065306\n",
      "Loss at step 4000 : train acc = 0.976562, validate acc = 0.987422\n",
      "78 183 135 24887\n",
      "precision = 0.298851, recall = 0.366197, f_score = 0.329114\n",
      "Loss at step 5000 : train acc = 0.984375, validate acc = 0.987541\n",
      "41 143 172 24927\n",
      "precision = 0.222826, recall = 0.192488, f_score = 0.206549\n",
      "Loss at step 6000 : train acc = 0.964844, validate acc = 0.988332\n",
      "28 110 185 24960\n",
      "precision = 0.202899, recall = 0.131455, f_score = 0.159544\n",
      "Loss at step 7000 : train acc = 0.980469, validate acc = 0.988372\n",
      "62 143 151 24927\n",
      "precision = 0.302439, recall = 0.291080, f_score = 0.296651\n",
      "Loss at step 8000 : train acc = 0.976562, validate acc = 0.989044\n",
      "55 119 158 24951\n",
      "precision = 0.316092, recall = 0.258216, f_score = 0.284238\n",
      "Loss at step 9000 : train acc = 0.984375, validate acc = 0.989440\n",
      "67 121 146 24949\n",
      "precision = 0.356383, recall = 0.314554, f_score = 0.334165\n",
      "Loss at step 10000 : train acc = 0.984375, validate acc = 0.989875\n",
      "74 117 139 24953\n",
      "precision = 0.387435, recall = 0.347418, f_score = 0.366337\n",
      "Loss at step 11000 : train acc = 0.984375, validate acc = 0.990666\n",
      "82 105 131 24965\n",
      "precision = 0.438503, recall = 0.384977, f_score = 0.410000\n",
      "Loss at step 12000 : train acc = 0.988281, validate acc = 0.990745\n",
      "76 97 137 24973\n",
      "precision = 0.439306, recall = 0.356808, f_score = 0.393782\n",
      "Loss at step 13000 : train acc = 0.992188, validate acc = 0.990310\n",
      "97 129 116 24941\n",
      "precision = 0.429204, recall = 0.455399, f_score = 0.441913\n",
      "Loss at step 14000 : train acc = 0.980469, validate acc = 0.991457\n",
      "93 96 120 24974\n",
      "precision = 0.492063, recall = 0.436620, f_score = 0.462687\n",
      "Loss at step 15000 : train acc = 0.976562, validate acc = 0.990745\n",
      "103 124 110 24946\n",
      "precision = 0.453744, recall = 0.483568, f_score = 0.468182\n",
      "Loss at step 16000 : train acc = 0.972656, validate acc = 0.990982\n",
      "115 130 98 24940\n",
      "precision = 0.469388, recall = 0.539906, f_score = 0.502183\n",
      "Loss at step 17000 : train acc = 0.968750, validate acc = 0.991575\n",
      "118 118 95 24952\n",
      "precision = 0.500000, recall = 0.553991, f_score = 0.525612\n",
      "Loss at step 18000 : train acc = 0.984375, validate acc = 0.991813\n",
      "118 112 95 24958\n",
      "precision = 0.513043, recall = 0.553991, f_score = 0.532731\n",
      "Loss at step 19000 : train acc = 0.980469, validate acc = 0.992327\n",
      "113 94 100 24976\n",
      "precision = 0.545894, recall = 0.530516, f_score = 0.538095\n",
      "Loss at step 20000 : train acc = 0.984375, validate acc = 0.992446\n",
      "115 93 98 24977\n",
      "precision = 0.552885, recall = 0.539906, f_score = 0.546318\n",
      "Loss at step 21000 : train acc = 0.964844, validate acc = 0.992169\n",
      "119 104 94 24966\n",
      "precision = 0.533632, recall = 0.558685, f_score = 0.545872\n",
      "Loss at step 22000 : train acc = 0.976562, validate acc = 0.992327\n",
      "124 105 89 24965\n",
      "precision = 0.541485, recall = 0.582160, f_score = 0.561086\n",
      "Loss at step 23000 : train acc = 0.980469, validate acc = 0.993395\n",
      "113 67 100 25003\n",
      "precision = 0.627778, recall = 0.530516, f_score = 0.575064\n",
      "Loss at step 24000 : train acc = 0.968750, validate acc = 0.993237\n",
      "115 73 98 24997\n",
      "precision = 0.611702, recall = 0.539906, f_score = 0.573566\n",
      "Loss at step 25000 : train acc = 0.976562, validate acc = 0.993157\n",
      "115 75 98 24995\n",
      "precision = 0.605263, recall = 0.539906, f_score = 0.570720\n",
      "Loss at step 26000 : train acc = 0.972656, validate acc = 0.992801\n",
      "124 93 89 24977\n",
      "precision = 0.571429, recall = 0.582160, f_score = 0.576744\n",
      "Loss at step 27000 : train acc = 0.976562, validate acc = 0.993869\n",
      "113 55 100 25015\n",
      "precision = 0.672619, recall = 0.530516, f_score = 0.593176\n",
      "Loss at step 28000 : train acc = 0.980469, validate acc = 0.992446\n",
      "132 110 81 24960\n",
      "precision = 0.545455, recall = 0.619718, f_score = 0.580220\n",
      "Loss at step 29000 : train acc = 0.996094, validate acc = 0.993395\n",
      "124 78 89 24992\n",
      "precision = 0.613861, recall = 0.582160, f_score = 0.597590\n",
      "Loss at step 30000 : train acc = 0.988281, validate acc = 0.993395\n",
      "125 79 88 24991\n",
      "precision = 0.612745, recall = 0.586854, f_score = 0.599520\n",
      "Loss at step 31000 : train acc = 0.972656, validate acc = 0.993553\n",
      "120 70 93 25000\n",
      "precision = 0.631579, recall = 0.563380, f_score = 0.595533\n",
      "Loss at step 32000 : train acc = 0.996094, validate acc = 0.994344\n",
      "113 43 100 25027\n",
      "precision = 0.724359, recall = 0.530516, f_score = 0.612466\n",
      "Loss at step 33000 : train acc = 0.984375, validate acc = 0.993316\n",
      "130 86 83 24984\n",
      "precision = 0.601852, recall = 0.610329, f_score = 0.606061\n",
      "Loss at step 34000 : train acc = 0.968750, validate acc = 0.993790\n",
      "127 71 86 24999\n",
      "precision = 0.641414, recall = 0.596244, f_score = 0.618005\n",
      "Loss at step 35000 : train acc = 0.972656, validate acc = 0.993988\n",
      "127 66 86 25004\n",
      "precision = 0.658031, recall = 0.596244, f_score = 0.625616\n",
      "Loss at step 36000 : train acc = 0.964844, validate acc = 0.993869\n",
      "129 71 84 24999\n",
      "precision = 0.645000, recall = 0.605634, f_score = 0.624697\n",
      "Loss at step 37000 : train acc = 0.984375, validate acc = 0.994146\n",
      "123 58 90 25012\n",
      "precision = 0.679558, recall = 0.577465, f_score = 0.624365\n",
      "Loss at step 38000 : train acc = 0.964844, validate acc = 0.994344\n",
      "109 39 104 25031\n",
      "precision = 0.736486, recall = 0.511737, f_score = 0.603878\n",
      "Loss at step 39000 : train acc = 0.992188, validate acc = 0.993909\n",
      "130 71 83 24999\n",
      "precision = 0.646766, recall = 0.610329, f_score = 0.628019\n",
      "Loss at step 40000 : train acc = 0.972656, validate acc = 0.994423\n",
      "121 49 92 25021\n",
      "precision = 0.711765, recall = 0.568075, f_score = 0.631854\n",
      "Loss at step 41000 : train acc = 0.980469, validate acc = 0.994344\n",
      "126 56 87 25014\n",
      "precision = 0.692308, recall = 0.591549, f_score = 0.637975\n",
      "Loss at step 42000 : train acc = 0.984375, validate acc = 0.994186\n",
      "134 68 79 25002\n",
      "precision = 0.663366, recall = 0.629108, f_score = 0.645783\n",
      "Loss at step 43000 : train acc = 0.980469, validate acc = 0.994423\n",
      "123 51 90 25019\n",
      "precision = 0.706897, recall = 0.577465, f_score = 0.635659\n",
      "Loss at step 44000 : train acc = 0.984375, validate acc = 0.994304\n",
      "133 64 80 25006\n",
      "precision = 0.675127, recall = 0.624413, f_score = 0.648780\n",
      "Loss at step 45000 : train acc = 0.980469, validate acc = 0.994304\n",
      "134 65 79 25005\n",
      "precision = 0.673367, recall = 0.629108, f_score = 0.650485\n",
      "Loss at step 46000 : train acc = 0.996094, validate acc = 0.993988\n",
      "135 74 78 24996\n",
      "precision = 0.645933, recall = 0.633803, f_score = 0.639810\n",
      "Loss at step 47000 : train acc = 0.992188, validate acc = 0.994265\n",
      "135 67 78 25003\n",
      "precision = 0.668317, recall = 0.633803, f_score = 0.650602\n",
      "Loss at step 48000 : train acc = 0.992188, validate acc = 0.994542\n",
      "131 56 82 25014\n",
      "precision = 0.700535, recall = 0.615023, f_score = 0.655000\n",
      "Loss at step 49000 : train acc = 0.984375, validate acc = 0.994581\n",
      "131 55 82 25015\n",
      "precision = 0.704301, recall = 0.615023, f_score = 0.656642\n",
      "Loss at step 50000 : train acc = 0.984375, validate acc = 0.994028\n",
      "136 74 77 24996\n",
      "precision = 0.647619, recall = 0.638498, f_score = 0.643026\n",
      "Loss at step 51000 : train acc = 1.000000, validate acc = 0.993949\n",
      "135 75 78 24995\n",
      "precision = 0.642857, recall = 0.633803, f_score = 0.638298\n",
      "Loss at step 52000 : train acc = 0.988281, validate acc = 0.994502\n",
      "127 53 86 25017\n",
      "precision = 0.705556, recall = 0.596244, f_score = 0.646310\n",
      "Loss at step 53000 : train acc = 0.984375, validate acc = 0.994581\n",
      "135 59 78 25011\n",
      "precision = 0.695876, recall = 0.633803, f_score = 0.663391\n",
      "Loss at step 54000 : train acc = 0.992188, validate acc = 0.994225\n",
      "135 68 78 25002\n",
      "precision = 0.665025, recall = 0.633803, f_score = 0.649038\n",
      "Loss at step 55000 : train acc = 0.972656, validate acc = 0.993949\n",
      "141 81 72 24989\n",
      "precision = 0.635135, recall = 0.661972, f_score = 0.648276\n",
      "Loss at step 56000 : train acc = 0.984375, validate acc = 0.994621\n",
      "121 44 92 25026\n",
      "precision = 0.733333, recall = 0.568075, f_score = 0.640212\n",
      "Loss at step 57000 : train acc = 0.976562, validate acc = 0.994186\n",
      "138 72 75 24998\n",
      "precision = 0.657143, recall = 0.647887, f_score = 0.652482\n",
      "Loss at step 58000 : train acc = 0.988281, validate acc = 0.994621\n",
      "136 59 77 25011\n",
      "precision = 0.697436, recall = 0.638498, f_score = 0.666667\n",
      "Loss at step 59000 : train acc = 0.976562, validate acc = 0.994581\n",
      "135 59 78 25011\n",
      "precision = 0.695876, recall = 0.633803, f_score = 0.663391\n",
      "Loss at step 60000 : train acc = 0.964844, validate acc = 0.994621\n",
      "136 59 77 25011\n",
      "precision = 0.697436, recall = 0.638498, f_score = 0.666667\n",
      "Loss at step 61000 : train acc = 0.992188, validate acc = 0.994740\n",
      "133 53 80 25017\n",
      "precision = 0.715054, recall = 0.624413, f_score = 0.666667\n",
      "Loss at step 62000 : train acc = 0.996094, validate acc = 0.994700\n",
      "135 56 78 25014\n",
      "precision = 0.706806, recall = 0.633803, f_score = 0.668317\n",
      "Loss at step 63000 : train acc = 0.992188, validate acc = 0.994740\n",
      "138 58 75 25012\n",
      "precision = 0.704082, recall = 0.647887, f_score = 0.674817\n",
      "Loss at step 64000 : train acc = 0.988281, validate acc = 0.994384\n",
      "138 67 75 25003\n",
      "precision = 0.673171, recall = 0.647887, f_score = 0.660287\n",
      "Loss at step 65000 : train acc = 0.976562, validate acc = 0.994740\n",
      "132 52 81 25018\n",
      "precision = 0.717391, recall = 0.619718, f_score = 0.664987\n",
      "Loss at step 66000 : train acc = 0.984375, validate acc = 0.994779\n",
      "137 56 76 25014\n",
      "precision = 0.709845, recall = 0.643192, f_score = 0.674877\n",
      "Loss at step 67000 : train acc = 0.980469, validate acc = 0.994740\n",
      "117 37 96 25033\n",
      "precision = 0.759740, recall = 0.549296, f_score = 0.637602\n",
      "Loss at step 68000 : train acc = 0.988281, validate acc = 0.994542\n",
      "138 63 75 25007\n",
      "precision = 0.686567, recall = 0.647887, f_score = 0.666667\n",
      "Loss at step 69000 : train acc = 0.976562, validate acc = 0.994700\n",
      "137 58 76 25012\n",
      "precision = 0.702564, recall = 0.643192, f_score = 0.671569\n",
      "Loss at step 70000 : train acc = 0.976562, validate acc = 0.994858\n",
      "137 54 76 25016\n",
      "precision = 0.717277, recall = 0.643192, f_score = 0.678218\n",
      "Loss at step 71000 : train acc = 0.972656, validate acc = 0.994621\n",
      "137 60 76 25010\n",
      "precision = 0.695431, recall = 0.643192, f_score = 0.668293\n",
      "Loss at step 72000 : train acc = 0.976562, validate acc = 0.994779\n",
      "134 53 79 25017\n",
      "precision = 0.716578, recall = 0.629108, f_score = 0.670000\n",
      "Loss at step 73000 : train acc = 0.980469, validate acc = 0.994660\n",
      "138 60 75 25010\n",
      "precision = 0.696970, recall = 0.647887, f_score = 0.671533\n",
      "Loss at step 74000 : train acc = 0.984375, validate acc = 0.994740\n",
      "136 56 77 25014\n",
      "precision = 0.708333, recall = 0.638498, f_score = 0.671605\n",
      "Loss at step 75000 : train acc = 0.976562, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 76000 : train acc = 0.996094, validate acc = 0.994779\n",
      "134 53 79 25017\n",
      "precision = 0.716578, recall = 0.629108, f_score = 0.670000\n",
      "Loss at step 77000 : train acc = 0.996094, validate acc = 0.994660\n",
      "139 61 74 25009\n",
      "precision = 0.695000, recall = 0.652582, f_score = 0.673123\n",
      "Loss at step 78000 : train acc = 0.988281, validate acc = 0.994779\n",
      "136 55 77 25015\n",
      "precision = 0.712042, recall = 0.638498, f_score = 0.673267\n",
      "Loss at step 79000 : train acc = 0.980469, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 80000 : train acc = 0.980469, validate acc = 0.994660\n",
      "140 62 73 25008\n",
      "precision = 0.693069, recall = 0.657277, f_score = 0.674699\n",
      "Loss at step 81000 : train acc = 0.960938, validate acc = 0.994819\n",
      "134 52 79 25018\n",
      "precision = 0.720430, recall = 0.629108, f_score = 0.671679\n",
      "Loss at step 82000 : train acc = 0.984375, validate acc = 0.994700\n",
      "138 59 75 25011\n",
      "precision = 0.700508, recall = 0.647887, f_score = 0.673171\n",
      "Loss at step 83000 : train acc = 0.972656, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 84000 : train acc = 0.976562, validate acc = 0.994621\n",
      "140 63 73 25007\n",
      "precision = 0.689655, recall = 0.657277, f_score = 0.673077\n",
      "Loss at step 85000 : train acc = 0.972656, validate acc = 0.994858\n",
      "134 51 79 25019\n",
      "precision = 0.724324, recall = 0.629108, f_score = 0.673367\n",
      "Loss at step 86000 : train acc = 0.988281, validate acc = 0.994304\n",
      "143 74 70 24996\n",
      "precision = 0.658986, recall = 0.671362, f_score = 0.665116\n",
      "Loss at step 87000 : train acc = 0.996094, validate acc = 0.994700\n",
      "136 57 77 25013\n",
      "precision = 0.704663, recall = 0.638498, f_score = 0.669951\n",
      "Loss at step 88000 : train acc = 0.984375, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 89000 : train acc = 0.988281, validate acc = 0.994700\n",
      "137 58 76 25012\n",
      "precision = 0.702564, recall = 0.643192, f_score = 0.671569\n",
      "Loss at step 90000 : train acc = 0.976562, validate acc = 0.994858\n",
      "135 52 78 25018\n",
      "precision = 0.721925, recall = 0.633803, f_score = 0.675000\n",
      "Loss at step 91000 : train acc = 0.984375, validate acc = 0.994700\n",
      "138 59 75 25011\n",
      "precision = 0.700508, recall = 0.647887, f_score = 0.673171\n",
      "Loss at step 92000 : train acc = 0.960938, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 93000 : train acc = 0.972656, validate acc = 0.994700\n",
      "139 60 74 25010\n",
      "precision = 0.698492, recall = 0.652582, f_score = 0.674757\n",
      "Loss at step 94000 : train acc = 0.984375, validate acc = 0.994858\n",
      "135 52 78 25018\n",
      "precision = 0.721925, recall = 0.633803, f_score = 0.675000\n",
      "Loss at step 95000 : train acc = 0.992188, validate acc = 0.994660\n",
      "139 61 74 25009\n",
      "precision = 0.695000, recall = 0.652582, f_score = 0.673123\n",
      "Loss at step 96000 : train acc = 0.980469, validate acc = 0.994858\n",
      "130 47 83 25023\n",
      "precision = 0.734463, recall = 0.610329, f_score = 0.666667\n",
      "Loss at step 97000 : train acc = 0.984375, validate acc = 0.994700\n",
      "143 64 70 25006\n",
      "precision = 0.690821, recall = 0.671362, f_score = 0.680952\n",
      "Loss at step 98000 : train acc = 0.988281, validate acc = 0.994700\n",
      "139 60 74 25010\n",
      "precision = 0.698492, recall = 0.652582, f_score = 0.674757\n",
      "Loss at step 99000 : train acc = 0.984375, validate acc = 0.994937\n",
      "137 52 76 25018\n",
      "precision = 0.724868, recall = 0.643192, f_score = 0.681592\n",
      "Loss at step 100000 : train acc = 0.968750, validate acc = 0.994621\n",
      "139 62 74 25008\n",
      "precision = 0.691542, recall = 0.652582, f_score = 0.671498\n",
      "Loss at step 101000 : train acc = 0.976562, validate acc = 0.994898\n",
      "136 52 77 25018\n",
      "precision = 0.723404, recall = 0.638498, f_score = 0.678304\n",
      "Loss at step 102000 : train acc = 0.984375, validate acc = 0.994581\n",
      "139 63 74 25007\n",
      "precision = 0.688119, recall = 0.652582, f_score = 0.669880\n",
      "Loss at step 103000 : train acc = 0.976562, validate acc = 0.994581\n",
      "139 63 74 25007\n",
      "precision = 0.688119, recall = 0.652582, f_score = 0.669880\n",
      "Loss at step 104000 : train acc = 0.980469, validate acc = 0.994621\n",
      "144 67 69 25003\n",
      "precision = 0.682464, recall = 0.676056, f_score = 0.679245\n",
      "Loss at step 105000 : train acc = 0.980469, validate acc = 0.994858\n",
      "135 52 78 25018\n",
      "precision = 0.721925, recall = 0.633803, f_score = 0.675000\n",
      "Loss at step 106000 : train acc = 0.976562, validate acc = 0.994502\n",
      "144 70 69 25000\n",
      "precision = 0.672897, recall = 0.676056, f_score = 0.674473\n",
      "Loss at step 107000 : train acc = 0.992188, validate acc = 0.994819\n",
      "138 56 75 25014\n",
      "precision = 0.711340, recall = 0.647887, f_score = 0.678133\n",
      "Loss at step 108000 : train acc = 0.992188, validate acc = 0.994581\n",
      "139 63 74 25007\n",
      "precision = 0.688119, recall = 0.652582, f_score = 0.669880\n",
      "Loss at step 109000 : train acc = 0.996094, validate acc = 0.994621\n",
      "140 63 73 25007\n",
      "precision = 0.689655, recall = 0.657277, f_score = 0.673077\n",
      "Loss at step 110000 : train acc = 0.980469, validate acc = 0.994937\n",
      "137 52 76 25018\n",
      "precision = 0.724868, recall = 0.643192, f_score = 0.681592\n",
      "Loss at step 111000 : train acc = 0.984375, validate acc = 0.994660\n",
      "140 62 73 25008\n",
      "precision = 0.693069, recall = 0.657277, f_score = 0.674699\n",
      "Loss at step 112000 : train acc = 0.988281, validate acc = 0.994621\n",
      "139 62 74 25008\n",
      "precision = 0.691542, recall = 0.652582, f_score = 0.671498\n",
      "Loss at step 113000 : train acc = 0.980469, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 114000 : train acc = 0.988281, validate acc = 0.994858\n",
      "135 52 78 25018\n",
      "precision = 0.721925, recall = 0.633803, f_score = 0.675000\n",
      "Loss at step 115000 : train acc = 0.964844, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 116000 : train acc = 0.988281, validate acc = 0.994700\n",
      "139 60 74 25010\n",
      "precision = 0.698492, recall = 0.652582, f_score = 0.674757\n",
      "Loss at step 117000 : train acc = 0.996094, validate acc = 0.994660\n",
      "140 62 73 25008\n",
      "precision = 0.693069, recall = 0.657277, f_score = 0.674699\n",
      "Loss at step 118000 : train acc = 0.984375, validate acc = 0.994740\n",
      "138 58 75 25012\n",
      "precision = 0.704082, recall = 0.647887, f_score = 0.674817\n",
      "Loss at step 119000 : train acc = 0.988281, validate acc = 0.994858\n",
      "138 55 75 25015\n",
      "precision = 0.715026, recall = 0.647887, f_score = 0.679803\n",
      "Loss at step 120000 : train acc = 0.988281, validate acc = 0.994660\n",
      "140 62 73 25008\n",
      "precision = 0.693069, recall = 0.657277, f_score = 0.674699\n",
      "Loss at step 121000 : train acc = 0.976562, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 122000 : train acc = 0.984375, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 123000 : train acc = 0.984375, validate acc = 0.994898\n",
      "137 53 76 25017\n",
      "precision = 0.721053, recall = 0.643192, f_score = 0.679901\n",
      "Loss at step 124000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 125000 : train acc = 0.984375, validate acc = 0.994898\n",
      "137 53 76 25017\n",
      "precision = 0.721053, recall = 0.643192, f_score = 0.679901\n",
      "Loss at step 126000 : train acc = 0.980469, validate acc = 0.994542\n",
      "142 67 71 25003\n",
      "precision = 0.679426, recall = 0.666667, f_score = 0.672986\n",
      "Loss at step 127000 : train acc = 0.984375, validate acc = 0.994621\n",
      "140 63 73 25007\n",
      "precision = 0.689655, recall = 0.657277, f_score = 0.673077\n",
      "Loss at step 128000 : train acc = 0.980469, validate acc = 0.994740\n",
      "139 59 74 25011\n",
      "precision = 0.702020, recall = 0.652582, f_score = 0.676399\n",
      "Loss at step 129000 : train acc = 0.992188, validate acc = 0.994581\n",
      "140 64 73 25006\n",
      "precision = 0.686275, recall = 0.657277, f_score = 0.671463\n",
      "Loss at step 130000 : train acc = 0.984375, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 131000 : train acc = 0.964844, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 132000 : train acc = 0.988281, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 133000 : train acc = 0.992188, validate acc = 0.994463\n",
      "142 69 71 25001\n",
      "precision = 0.672986, recall = 0.666667, f_score = 0.669811\n",
      "Loss at step 134000 : train acc = 0.980469, validate acc = 0.994779\n",
      "137 56 76 25014\n",
      "precision = 0.709845, recall = 0.643192, f_score = 0.674877\n",
      "Loss at step 135000 : train acc = 1.000000, validate acc = 0.994502\n",
      "143 69 70 25001\n",
      "precision = 0.674528, recall = 0.671362, f_score = 0.672941\n",
      "Loss at step 136000 : train acc = 0.980469, validate acc = 0.994621\n",
      "140 63 73 25007\n",
      "precision = 0.689655, recall = 0.657277, f_score = 0.673077\n",
      "Loss at step 137000 : train acc = 0.988281, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 138000 : train acc = 0.968750, validate acc = 0.994542\n",
      "142 67 71 25003\n",
      "precision = 0.679426, recall = 0.666667, f_score = 0.672986\n",
      "Loss at step 139000 : train acc = 1.000000, validate acc = 0.994700\n",
      "137 58 76 25012\n",
      "precision = 0.702564, recall = 0.643192, f_score = 0.671569\n",
      "Loss at step 140000 : train acc = 0.988281, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 141000 : train acc = 0.992188, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 142000 : train acc = 0.980469, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 143000 : train acc = 0.992188, validate acc = 0.994700\n",
      "137 58 76 25012\n",
      "precision = 0.702564, recall = 0.643192, f_score = 0.671569\n",
      "Loss at step 144000 : train acc = 0.992188, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 145000 : train acc = 0.988281, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 146000 : train acc = 0.992188, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 147000 : train acc = 0.984375, validate acc = 0.994621\n",
      "140 63 73 25007\n",
      "precision = 0.689655, recall = 0.657277, f_score = 0.673077\n",
      "Loss at step 148000 : train acc = 0.992188, validate acc = 0.994700\n",
      "138 59 75 25011\n",
      "precision = 0.700508, recall = 0.647887, f_score = 0.673171\n",
      "Loss at step 149000 : train acc = 0.988281, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 150000 : train acc = 0.988281, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 151000 : train acc = 0.988281, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 152000 : train acc = 0.992188, validate acc = 0.994660\n",
      "137 59 76 25011\n",
      "precision = 0.698980, recall = 0.643192, f_score = 0.669927\n",
      "Loss at step 153000 : train acc = 0.984375, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 154000 : train acc = 0.992188, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 155000 : train acc = 0.984375, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 156000 : train acc = 0.976562, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 157000 : train acc = 0.964844, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 158000 : train acc = 0.984375, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 159000 : train acc = 0.984375, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 160000 : train acc = 0.976562, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 161000 : train acc = 0.980469, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 162000 : train acc = 0.972656, validate acc = 0.994621\n",
      "143 66 70 25004\n",
      "precision = 0.684211, recall = 0.671362, f_score = 0.677725\n",
      "Loss at step 163000 : train acc = 0.984375, validate acc = 0.994660\n",
      "138 60 75 25010\n",
      "precision = 0.696970, recall = 0.647887, f_score = 0.671533\n",
      "Loss at step 164000 : train acc = 0.976562, validate acc = 0.994621\n",
      "143 66 70 25004\n",
      "precision = 0.684211, recall = 0.671362, f_score = 0.677725\n",
      "Loss at step 165000 : train acc = 0.996094, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 166000 : train acc = 0.984375, validate acc = 0.994740\n",
      "141 61 72 25009\n",
      "precision = 0.698020, recall = 0.661972, f_score = 0.679518\n",
      "Loss at step 167000 : train acc = 0.980469, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 168000 : train acc = 0.988281, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 169000 : train acc = 0.976562, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 170000 : train acc = 0.972656, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 171000 : train acc = 0.976562, validate acc = 0.994621\n",
      "143 66 70 25004\n",
      "precision = 0.684211, recall = 0.671362, f_score = 0.677725\n",
      "Loss at step 172000 : train acc = 0.972656, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 173000 : train acc = 0.988281, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 174000 : train acc = 0.964844, validate acc = 0.994700\n",
      "140 61 73 25009\n",
      "precision = 0.696517, recall = 0.657277, f_score = 0.676329\n",
      "Loss at step 175000 : train acc = 0.992188, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 176000 : train acc = 0.980469, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 177000 : train acc = 0.988281, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 178000 : train acc = 0.980469, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 179000 : train acc = 0.980469, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 180000 : train acc = 0.984375, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 181000 : train acc = 0.980469, validate acc = 0.994740\n",
      "140 60 73 25010\n",
      "precision = 0.700000, recall = 0.657277, f_score = 0.677966\n",
      "Loss at step 182000 : train acc = 0.996094, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 183000 : train acc = 0.996094, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 184000 : train acc = 0.992188, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 185000 : train acc = 0.988281, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 186000 : train acc = 0.988281, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 187000 : train acc = 1.000000, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 188000 : train acc = 0.988281, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 189000 : train acc = 0.984375, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 190000 : train acc = 0.996094, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 191000 : train acc = 0.976562, validate acc = 0.994621\n",
      "143 66 70 25004\n",
      "precision = 0.684211, recall = 0.671362, f_score = 0.677725\n",
      "Loss at step 192000 : train acc = 0.980469, validate acc = 0.994700\n",
      "139 60 74 25010\n",
      "precision = 0.698492, recall = 0.652582, f_score = 0.674757\n",
      "Loss at step 193000 : train acc = 0.980469, validate acc = 0.994581\n",
      "142 66 71 25004\n",
      "precision = 0.682692, recall = 0.666667, f_score = 0.674584\n",
      "Loss at step 194000 : train acc = 0.988281, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 195000 : train acc = 0.980469, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 196000 : train acc = 0.964844, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 197000 : train acc = 1.000000, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 198000 : train acc = 0.996094, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 199000 : train acc = 0.992188, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 200000 : train acc = 0.992188, validate acc = 0.994621\n",
      "143 66 70 25004\n",
      "precision = 0.684211, recall = 0.671362, f_score = 0.677725\n",
      "Loss at step 201000 : train acc = 0.980469, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 202000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 203000 : train acc = 0.984375, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 204000 : train acc = 0.996094, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 205000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 206000 : train acc = 0.976562, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 207000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 208000 : train acc = 0.984375, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 209000 : train acc = 0.976562, validate acc = 0.994660\n",
      "143 65 70 25005\n",
      "precision = 0.687500, recall = 0.671362, f_score = 0.679335\n",
      "Loss at step 210000 : train acc = 0.984375, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 211000 : train acc = 0.980469, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 212000 : train acc = 0.992188, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 213000 : train acc = 0.996094, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 214000 : train acc = 0.988281, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 215000 : train acc = 0.988281, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 216000 : train acc = 0.980469, validate acc = 0.994660\n",
      "143 65 70 25005\n",
      "precision = 0.687500, recall = 0.671362, f_score = 0.679335\n",
      "Loss at step 217000 : train acc = 0.960938, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 218000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 219000 : train acc = 0.972656, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 220000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 221000 : train acc = 0.968750, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 222000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 223000 : train acc = 0.996094, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 224000 : train acc = 0.984375, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 225000 : train acc = 0.984375, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 226000 : train acc = 0.972656, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 227000 : train acc = 0.984375, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 228000 : train acc = 0.957031, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 229000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 230000 : train acc = 0.980469, validate acc = 0.994700\n",
      "141 62 72 25008\n",
      "precision = 0.694581, recall = 0.661972, f_score = 0.677885\n",
      "Loss at step 231000 : train acc = 0.992188, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 232000 : train acc = 0.976562, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 233000 : train acc = 0.984375, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 234000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 235000 : train acc = 0.988281, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 236000 : train acc = 0.968750, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 237000 : train acc = 0.976562, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 238000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 239000 : train acc = 0.976562, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 240000 : train acc = 0.976562, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 241000 : train acc = 0.984375, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 242000 : train acc = 0.972656, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 243000 : train acc = 0.992188, validate acc = 0.994581\n",
      "141 65 72 25005\n",
      "precision = 0.684466, recall = 0.661972, f_score = 0.673031\n",
      "Loss at step 244000 : train acc = 0.988281, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 245000 : train acc = 0.992188, validate acc = 0.994660\n",
      "143 65 70 25005\n",
      "precision = 0.687500, recall = 0.671362, f_score = 0.679335\n",
      "Loss at step 246000 : train acc = 0.984375, validate acc = 0.994660\n",
      "141 63 72 25007\n",
      "precision = 0.691176, recall = 0.661972, f_score = 0.676259\n",
      "Loss at step 247000 : train acc = 0.988281, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n",
      "Loss at step 248000 : train acc = 0.988281, validate acc = 0.994621\n",
      "141 64 72 25006\n",
      "precision = 0.687805, recall = 0.661972, f_score = 0.674641\n",
      "Loss at step 249000 : train acc = 0.980469, validate acc = 0.994621\n",
      "142 65 71 25005\n",
      "precision = 0.685990, recall = 0.666667, f_score = 0.676190\n"
     ]
    }
   ],
   "source": [
    "#train the model with stochastic gradient descent training\n",
    "batch_size = 256\n",
    "num_steps = 250000\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_label.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_data_n_resample_s[offset:(offset + batch_size), :]\n",
    "        #print(batch_data.shape)\n",
    "        batch_labels = v_train_label_resample_s[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_label : batch_labels}\n",
    "        #session.run(predicted_label, feed_dict=feed_dict)\n",
    "        _, l, _, r = session.run([predicted_label, loss, op, learning_rate], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 1000 == 0):\n",
    "            print('Loss at step %d : train acc = %f, validate acc = %f' % (step, train_acc.eval(feed_dict=feed_dict), validate_acc.eval()))\n",
    "            print(TP.eval(), FP.eval(), FN.eval(), TN.eval())\n",
    "            print(\"precision = %f, recall = %f, f_score = %f\" % (pre.eval(), rec.eval(), f_s.eval()))\n",
    "            #print('Loss at step %d: LR %f MSE %f MAE %f VALIDATE MAE %f' % (step, r, l, train_loss.eval(feed_dict=feed_dict), validate_loss.eval()))\n",
    "    #print(c_train_label_resample.reshape(-1, 1)[0:128, :])\n",
    "    #print('test1, test2, test MAE: %.3f, %.3f, %.3f' % (test_loss1.eval(), test_loss2.eval(), test_loss.eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_label_resample[0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
