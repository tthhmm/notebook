{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some function we can use later\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS+NWP.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset= save['t_v_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    del save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_time = train_dataset['time']\n",
    "train_data = np.hstack((train_dataset['data_ASOS'], train_dataset['data_NWP']))\n",
    "train_label = train_dataset['label']\n",
    "\n",
    "test_time = test_dataset['time']\n",
    "test_data = np.hstack((test_dataset['data_ASOS'], test_dataset['data_NWP']))\n",
    "test_label = test_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,) (70,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_data.mean(axis = 0)\n",
    "std = train_data.std(axis = 0)\n",
    "print(mean.shape, std.shape)\n",
    "train_data_n = (train_data - mean)/std\n",
    "validate_data_n = (validate_data - mean)/std\n",
    "test_old_data_n = (test_old_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.,  10.,  10.,   9.,   8.,   9.,   8.,   7.,   7.,   6.,   6.,\n",
       "         7.,   7.,   9.,   8.,   7.,   7.,   7.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "         9.,  10.,  10.,  10.,   9.,  10.,   8.,   9.,   9.,   8.,   7.,\n",
       "         7.,   8.,   9.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_label = pre.transform(train_label.reshape(1, -1))\n",
    "b_test_old_label = pre.transform(test_old_label.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train_label[:, :30][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = b_train_label.sum(axis = 1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c2 = b_train_label.shape[1] - c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174485.0 2502.0 1.4136631504\n"
     ]
    }
   ],
   "source": [
    "print(c1, c2, c2*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to balanced the dataset\n",
    "from unbalanced_dataset.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train_label = 1 - b_train_label[0]\n",
    "c_test_old_label = 1 - b_test_old_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 199556, 1.0: 2715})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 196841 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(kind='regular')\n",
    "train_data_n_resample, c_train_label_resample = sm.fit_transform(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 49846, 1.0: 722})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 49124 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "test_old_data_n_resample, c_test_old_label_resample = sm.fit_transform(test_old_data_n, c_test_old_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((399112, 70), (399112,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_n_resample.shape, c_train_label_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199556.0 199556.0 50.0\n"
     ]
    }
   ],
   "source": [
    "c1 = c_train_label_resample.sum()\n",
    "c2 = c_train_label_resample.shape[0] - c1\n",
    "print(c1, c2, c1*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=245, FP=72, FN=477, CSI=0.309, POD=0.339, FAR=0.227\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data_n_resample, c_train_label_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=44969, FP=2657, FN=4877, CSI=0.857, POD=0.902, FAR=0.056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_c = clf.predict(test_old_data_n_resample)\n",
    "TP = ((predict_c + c_test_old_label_resample)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label_resample.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=641, FP=2657, FN=81, CSI=0.190, POD=0.888, FAR=0.806\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50568,)\n",
      "TP=383, FP=247, FN=339, CSI=0.395, POD=0.530, FAR=0.392\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "print(predict_c.shape)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_data_n_resample, c_train_label_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=46467, FP=3552, FN=3379, CSI=0.870, POD=0.932, FAR=0.071\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n_resample)\n",
    "TP = ((predict_c + c_test_old_label_resample)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label_resample.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50568,)\n",
      "TP=667, FP=3552, FN=55, CSI=0.156, POD=0.924, FAR=0.842\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "print(predict_c.shape)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=292, FP=100, FN=430, CSI=0.355, POD=0.404, FAR=0.255\n",
      "depth=3, TP=422, FP=182, FN=300, CSI=0.467, POD=0.584, FAR=0.301\n",
      "depth=4, TP=418, FP=184, FN=304, CSI=0.461, POD=0.579, FAR=0.306\n",
      "depth=5, TP=386, FP=180, FN=336, CSI=0.428, POD=0.535, FAR=0.318\n",
      "depth=6, TP=377, FP=155, FN=345, CSI=0.430, POD=0.522, FAR=0.291\n",
      "depth=7, TP=366, FP=181, FN=356, CSI=0.405, POD=0.507, FAR=0.331\n",
      "depth=8, TP=341, FP=188, FN=381, CSI=0.375, POD=0.472, FAR=0.355\n",
      "depth=9, TP=325, FP=189, FN=397, CSI=0.357, POD=0.450, FAR=0.368\n",
      "depth=10, TP=350, FP=218, FN=372, CSI=0.372, POD=0.485, FAR=0.384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n, c_train_label)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=633, FP=1794, FN=89, CSI=0.252, POD=0.877, FAR=0.739\n",
      "depth=3, TP=647, FP=2101, FN=75, CSI=0.229, POD=0.896, FAR=0.765\n",
      "depth=4, TP=646, FP=2443, FN=76, CSI=0.204, POD=0.895, FAR=0.791\n",
      "depth=5, TP=628, FP=2725, FN=94, CSI=0.182, POD=0.870, FAR=0.813\n",
      "depth=6, TP=625, FP=2010, FN=97, CSI=0.229, POD=0.866, FAR=0.763\n",
      "depth=7, TP=613, FP=1876, FN=109, CSI=0.236, POD=0.849, FAR=0.754\n",
      "depth=8, TP=602, FP=1486, FN=120, CSI=0.273, POD=0.834, FAR=0.712\n",
      "depth=9, TP=574, FP=1339, FN=148, CSI=0.279, POD=0.795, FAR=0.700\n",
      "depth=10, TP=566, FP=1136, FN=156, CSI=0.305, POD=0.784, FAR=0.667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n_resample, c_train_label_resample)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/mjmu/haiming/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=0, FP=0, FN=935, CSI=0.000, POD=0.000, FAR=nan\n",
      "depth=3, TP=311, FP=53, FN=624, CSI=0.315, POD=0.333, FAR=0.146\n",
      "depth=4, TP=330, FP=76, FN=605, CSI=0.326, POD=0.353, FAR=0.187\n",
      "depth=5, TP=377, FP=79, FN=558, CSI=0.372, POD=0.403, FAR=0.173\n",
      "depth=6, TP=425, FP=99, FN=510, CSI=0.411, POD=0.455, FAR=0.189\n",
      "depth=7, TP=410, FP=122, FN=525, CSI=0.388, POD=0.439, FAR=0.229\n",
      "depth=8, TP=396, FP=114, FN=539, CSI=0.378, POD=0.424, FAR=0.224\n",
      "depth=9, TP=416, FP=122, FN=519, CSI=0.394, POD=0.445, FAR=0.227\n",
      "depth=10, TP=420, FP=115, FN=515, CSI=0.400, POD=0.449, FAR=0.215\n",
      "depth=11, TP=409, FP=133, FN=526, CSI=0.383, POD=0.437, FAR=0.245\n",
      "depth=12, TP=413, FP=147, FN=522, CSI=0.382, POD=0.442, FAR=0.262\n",
      "depth=13, TP=422, FP=142, FN=513, CSI=0.392, POD=0.451, FAR=0.252\n",
      "depth=14, TP=412, FP=144, FN=523, CSI=0.382, POD=0.441, FAR=0.259\n",
      "depth=15, TP=372, FP=130, FN=563, CSI=0.349, POD=0.398, FAR=0.259\n",
      "depth=16, TP=385, FP=115, FN=550, CSI=0.367, POD=0.412, FAR=0.230\n",
      "depth=17, TP=407, FP=144, FN=528, CSI=0.377, POD=0.435, FAR=0.261\n",
      "depth=18, TP=387, FP=135, FN=548, CSI=0.362, POD=0.414, FAR=0.259\n",
      "depth=19, TP=388, FP=124, FN=547, CSI=0.366, POD=0.415, FAR=0.242\n",
      "depth=20, TP=350, FP=90, FN=585, CSI=0.341, POD=0.374, FAR=0.205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for max_d in range(2, 21):\n",
    "    clf = RandomForestClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n, c_train_label)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TP=184, FP=41, FN=538, CSI=0.241, POD=0.255, FAR=0.182\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\" TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
