{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some function we can use later\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS_alone.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset= save['train_dataset']\n",
    "    validate_dataset = save['validate_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_old = save['test_dataset_evan']\n",
    "    train_old = save['train_dataset_evan']\n",
    "    del save\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_old_data = train_old['data']\n",
    "train_old_label = train_old['label']\n",
    "test_old_data = test_old['data']\n",
    "test_old_label = test_old['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,) (70,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_old_data.mean(axis = 0)\n",
    "std = train_old_data.std(axis = 0)\n",
    "print(mean.shape, std.shape)\n",
    "train_old_data_n = (train_old_data - mean)/std\n",
    "test_old_data_n = (test_old_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.,  10.,  10.,   9.,   8.,   9.,   8.,   7.,   7.,   6.,   6.,\n",
       "         7.,   7.,   9.,   8.,   7.,   7.,   7.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "         9.,  10.,  10.,  10.,   9.,  10.,   8.,   9.,   9.,   8.,   7.,\n",
       "         7.,   8.,   9.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_old_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_old_label = pre.transform(train_old_label.reshape(1, -1))\n",
    "b_test_old_label = pre.transform(test_old_label.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train_old_label[:, :30][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = b_train_old_label.sum(axis = 1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c2 = b_train_old_label.shape[1] - c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199555.0 2715.0 1.34226528897\n"
     ]
    }
   ],
   "source": [
    "print(c1, c2, c2*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to balanced the dataset\n",
    "from unbalanced_dataset.under_sampling import ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train_old_label = 1 - b_train_old_label[0]\n",
    "c_test_old_label = 1 - b_test_old_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 199555, 1.0: 2715})\n",
      "Under-sampling performed: Counter({0.0: 2715, 1.0: 2715})\n"
     ]
    }
   ],
   "source": [
    "CC = ClusterCentroids()\n",
    "train_data_n_resample, c_train_label_resample = CC.fit_transform(train_old_data_n, c_train_old_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = '/home/nfs/mjmu/haiming/data/visibility/' +  'CC_Under_sSample.pickle'\n",
    "\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    save = {\n",
    "        'train_data_n_resample': train_data_n_resample,\n",
    "        'c_train_label_resample': c_train_label_resample\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_old_data_n_resample, c_test_old_label_resample = sm.fit_transform(test_old_data_n, c_test_old_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5430, 70), (5430,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_n_resample.shape, c_train_label_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2715.0 2715.0 50.0\n"
     ]
    }
   ],
   "source": [
    "c1 = c_train_label_resample.sum()\n",
    "c2 = c_train_label_resample.shape[0] - c1\n",
    "print(c1, c2, c1*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-98e96d1a5e8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_train_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data_n' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data_n_resample, c_train_label_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=844, FP=3743, FN=91, CSI=0.180, POD=0.903, FAR=0.816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_c = clf.predict(test_old_data_n_resample)\n",
    "TP = ((predict_c + c_test_old_label_resample)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label_resample.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=844, FP=3743, FN=91, CSI=0.180, POD=0.903, FAR=0.816\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "print(predict_c.shape)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_data_n_resample, c_train_label_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_old_data_n_resample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-4d2c0a96536b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_old_data_n_resample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mTP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_c\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc_test_old_label_resample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_test_old_label_resample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_old_data_n_resample' is not defined"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n_resample)\n",
    "TP = ((predict_c + c_test_old_label_resample)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label_resample.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75852,)\n",
      "TP=792, FP=5162, FN=143, CSI=0.130, POD=0.847, FAR=0.867\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "print(predict_c.shape)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n, c_train_label)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=877, FP=17268, FN=58, CSI=0.048, POD=0.938, FAR=0.952\n",
      "depth=3, TP=900, FP=23415, FN=35, CSI=0.037, POD=0.963, FAR=0.963\n",
      "depth=4, TP=900, FP=24034, FN=35, CSI=0.036, POD=0.963, FAR=0.964\n",
      "depth=5, TP=900, FP=23263, FN=35, CSI=0.037, POD=0.963, FAR=0.963\n",
      "depth=6, TP=900, FP=23532, FN=35, CSI=0.037, POD=0.963, FAR=0.963\n",
      "depth=7, TP=903, FP=24335, FN=32, CSI=0.036, POD=0.966, FAR=0.964\n",
      "depth=8, TP=908, FP=24560, FN=27, CSI=0.036, POD=0.971, FAR=0.964\n",
      "depth=9, TP=907, FP=24445, FN=28, CSI=0.036, POD=0.970, FAR=0.964\n",
      "depth=10, TP=911, FP=24646, FN=24, CSI=0.036, POD=0.974, FAR=0.964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n_resample, c_train_label_resample)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for max_d in range(2, 21):\n",
    "    clf = RandomForestClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n, c_train_label)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\" TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
