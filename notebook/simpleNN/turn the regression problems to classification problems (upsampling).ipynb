{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some function we can use later\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data first\n",
    "pickle_file = '/home/htan/proj/TensorFlow/data/visibility/' +  'ASOS+NWP.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset= save['t_v_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    del save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_time = train_dataset['time']\n",
    "train_data = np.hstack((train_dataset['data_ASOS'], train_dataset['data_NWP']))\n",
    "train_label = train_dataset['label']\n",
    "\n",
    "test_time = test_dataset['time']\n",
    "test_data = np.hstack((test_dataset['data_ASOS'], test_dataset['data_NWP']))\n",
    "test_label = test_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82,) (82,)\n"
     ]
    }
   ],
   "source": [
    "#dataset normalize\n",
    "mean = train_data.mean(axis = 0)\n",
    "std = train_data.std(axis = 0)\n",
    "print(mean.shape, std.shape)\n",
    "train_data_n = (train_data - mean)/std\n",
    "test_old_data_n = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "         8.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
       "        10.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre = Binarizer(threshold = 1.01)\n",
    "b_train_label = pre.transform(train_label.reshape(1, -1))\n",
    "b_test_old_label = pre.transform(test_label.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train_label[:, :30][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = b_train_label.sum(axis = 1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c2 = b_train_label.shape[1] - c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114677.0 1980.0 1.6972834892\n"
     ]
    }
   ],
   "source": [
    "print(c1, c2, c2*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to balanced the dataset\n",
    "from unbalanced_dataset.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train_label = 1 - b_train_label[0]\n",
    "c_test_old_label = 1 - b_test_old_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 114677, 1.0: 1980})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 1460 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(ratio = 0.03, kind='regular')\n",
    "train_data_n_resample, c_train_label_resample = sm.fit_transform(train_data_n, c_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: Counter({0.0: 28744, 1.0: 421})\n",
      "Finding the 5 nearest neighbours...\n",
      "done!\n",
      "Creating synthetic samples...Generated 441 new samples ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "test_old_data_n_resample, c_test_old_label_resample = sm.fit_transform(test_old_data_n, c_test_old_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118117, 82), (118117,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_n_resample.shape, c_train_label_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3440.0 114677.0 2.91236655181\n"
     ]
    }
   ],
   "source": [
    "c1 = c_train_label_resample.sum()\n",
    "c2 = c_train_label_resample.shape[0] - c1\n",
    "print(c1, c2, c1*100/(c1+c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(train_data_n, c_train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=245, FP=72, FN=477, CSI=0.309, POD=0.339, FAR=0.227\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "s_t = time.time()\n",
    "clf.fit(train_data_n, c_train_label)\n",
    "e_t = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=208, FP=66, FN=213, CSI=0.427, POD=0.494, FAR=0.241\n",
      "28.2735159397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))\n",
    "print(e_t - s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=641, FP=2657, FN=81, CSI=0.190, POD=0.888, FAR=0.806\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "s_t = time.time()\n",
    "clf.fit(train_data_n, c_train_label)\n",
    "e_t = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=243, FP=156, FN=178, CSI=0.421, POD=0.577, FAR=0.391\n",
      "0.443342924118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))\n",
    "print(e_t - s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train_data_n_resample, c_train_label_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=46467, FP=3552, FN=3379, CSI=0.870, POD=0.932, FAR=0.071\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n_resample)\n",
    "TP = ((predict_c + c_test_old_label_resample)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label_resample.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50568,)\n",
      "TP=667, FP=3552, FN=55, CSI=0.156, POD=0.924, FAR=0.842\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "print(predict_c.shape)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\"TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=279, FP=146, FN=142, CSI=0.492, POD=0.663, FAR=0.344\n",
      "2.26705312729\n",
      "depth=3, TP=252, FP=92, FN=169, CSI=0.491, POD=0.599, FAR=0.267\n",
      "3.47003602982\n",
      "depth=4, TP=252, FP=92, FN=169, CSI=0.491, POD=0.599, FAR=0.267\n",
      "4.21723008156\n",
      "depth=5, TP=256, FP=112, FN=165, CSI=0.480, POD=0.608, FAR=0.304\n",
      "5.40498805046\n",
      "depth=6, TP=261, FP=141, FN=160, CSI=0.464, POD=0.620, FAR=0.351\n",
      "6.24978113174\n",
      "depth=7, TP=254, FP=133, FN=167, CSI=0.458, POD=0.603, FAR=0.344\n",
      "7.5666179657\n",
      "depth=8, TP=247, FP=155, FN=174, CSI=0.429, POD=0.587, FAR=0.386\n",
      "7.96973514557\n",
      "depth=9, TP=259, FP=177, FN=162, CSI=0.433, POD=0.615, FAR=0.406\n",
      "9.20372700691\n",
      "depth=10, TP=262, FP=202, FN=159, CSI=0.421, POD=0.622, FAR=0.435\n",
      "9.80379295349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    s_t = time.time()\n",
    "    clf.fit(train_data_n_resample, c_train_label_resample)\n",
    "    e_t = time.time()\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))\n",
    "    print(e_t - s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=633, FP=1794, FN=89, CSI=0.252, POD=0.877, FAR=0.739\n",
      "depth=3, TP=647, FP=2101, FN=75, CSI=0.229, POD=0.896, FAR=0.765\n",
      "depth=4, TP=646, FP=2443, FN=76, CSI=0.204, POD=0.895, FAR=0.791\n",
      "depth=5, TP=628, FP=2725, FN=94, CSI=0.182, POD=0.870, FAR=0.813\n",
      "depth=6, TP=625, FP=2010, FN=97, CSI=0.229, POD=0.866, FAR=0.763\n",
      "depth=7, TP=613, FP=1876, FN=109, CSI=0.236, POD=0.849, FAR=0.754\n",
      "depth=8, TP=602, FP=1486, FN=120, CSI=0.273, POD=0.834, FAR=0.712\n",
      "depth=9, TP=574, FP=1339, FN=148, CSI=0.279, POD=0.795, FAR=0.700\n",
      "depth=10, TP=566, FP=1136, FN=156, CSI=0.305, POD=0.784, FAR=0.667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for max_d in range(2, 11):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_d)\n",
    "    clf.fit(train_data_n_resample, c_train_label_resample)\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=2, TP=103, FP=3, FN=318, CSI=0.243, POD=0.245, FAR=0.028\n",
      "1.80295991898\n",
      "depth=3, TP=161, FP=25, FN=260, CSI=0.361, POD=0.382, FAR=0.134\n",
      "2.63570785522\n",
      "depth=4, TP=173, FP=27, FN=248, CSI=0.386, POD=0.411, FAR=0.135\n",
      "3.29041600227\n",
      "depth=5, TP=182, FP=40, FN=239, CSI=0.395, POD=0.432, FAR=0.180\n",
      "4.05445504189\n",
      "depth=6, TP=213, FP=54, FN=208, CSI=0.448, POD=0.506, FAR=0.202\n",
      "4.76007890701\n",
      "depth=7, TP=188, FP=52, FN=233, CSI=0.397, POD=0.447, FAR=0.217\n",
      "5.35415482521\n",
      "depth=8, TP=188, FP=52, FN=233, CSI=0.397, POD=0.447, FAR=0.217\n",
      "6.06815886497\n",
      "depth=9, TP=202, FP=62, FN=219, CSI=0.418, POD=0.480, FAR=0.235\n",
      "6.6959400177\n",
      "depth=10, TP=166, FP=56, FN=255, CSI=0.348, POD=0.394, FAR=0.252\n",
      "7.54036808014\n",
      "depth=11, TP=168, FP=58, FN=253, CSI=0.351, POD=0.399, FAR=0.257\n",
      "7.53257203102\n",
      "depth=12, TP=192, FP=68, FN=229, CSI=0.393, POD=0.456, FAR=0.262\n",
      "8.11895990372\n",
      "depth=13, TP=179, FP=54, FN=242, CSI=0.377, POD=0.425, FAR=0.232\n",
      "8.8984310627\n",
      "depth=14, TP=186, FP=74, FN=235, CSI=0.376, POD=0.442, FAR=0.285\n",
      "8.76477694511\n",
      "depth=15, TP=187, FP=51, FN=234, CSI=0.396, POD=0.444, FAR=0.214\n",
      "9.17038583755\n",
      "depth=16, TP=170, FP=56, FN=251, CSI=0.356, POD=0.404, FAR=0.248\n",
      "10.3804581165\n",
      "depth=17, TP=173, FP=46, FN=248, CSI=0.370, POD=0.411, FAR=0.210\n",
      "10.837321043\n",
      "depth=18, TP=184, FP=37, FN=237, CSI=0.402, POD=0.437, FAR=0.167\n",
      "10.9420449734\n",
      "depth=19, TP=157, FP=49, FN=264, CSI=0.334, POD=0.373, FAR=0.238\n",
      "9.50435090065\n",
      "depth=20, TP=174, FP=43, FN=247, CSI=0.375, POD=0.413, FAR=0.198\n",
      "9.96688294411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for max_d in range(2, 21):\n",
    "    clf = RandomForestClassifier(max_depth = max_d)\n",
    "    s_t = time.time()\n",
    "    clf.fit(train_data_n, c_train_label)\n",
    "    e_t = time.time()\n",
    "    predict_c = clf.predict(test_old_data_n)\n",
    "    TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "    FP = predict_c.sum() - TP\n",
    "    FN = c_test_old_label.sum() - TP\n",
    "    print(\"depth=%d, TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % (max_d, TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))\n",
    "    print(e_t - s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "s_t = time.time()\n",
    "clf.fit(train_data_n, c_train_label)\n",
    "e_t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TP=207, FP=63, FN=214, CSI=0.428, POD=0.492, FAR=0.233\n",
      "821.065064907\n"
     ]
    }
   ],
   "source": [
    "predict_c = clf.predict(test_old_data_n)\n",
    "TP = ((predict_c + c_test_old_label)>=2).astype(int).sum()\n",
    "FP = predict_c.sum() - TP\n",
    "FN = c_test_old_label.sum() - TP\n",
    "print(\" TP=%d, FP=%d, FN=%d, CSI=%.3f, POD=%.3f, FAR=%.3f\" % ( TP, FP, FN, TP/(TP + FP + FN), TP/(TP + FN), 1 - TP/(TP + FP)))\n",
    "print(e_t - s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
